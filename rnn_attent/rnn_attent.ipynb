{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, json, time, unittest, datetime, shutil\n",
    "import itertools, collections\n",
    "from importlib import reload\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The data below is only on the 10k datasets for now. This will be updated to leverage the full datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pd.read_json(\"../dataset/user_10k.json\", lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_stars</th>\n",
       "      <th>compliment_cool</th>\n",
       "      <th>compliment_cute</th>\n",
       "      <th>compliment_funny</th>\n",
       "      <th>compliment_hot</th>\n",
       "      <th>compliment_list</th>\n",
       "      <th>compliment_more</th>\n",
       "      <th>compliment_note</th>\n",
       "      <th>compliment_photos</th>\n",
       "      <th>compliment_plain</th>\n",
       "      <th>...</th>\n",
       "      <th>cool</th>\n",
       "      <th>elite</th>\n",
       "      <th>fans</th>\n",
       "      <th>friends</th>\n",
       "      <th>funny</th>\n",
       "      <th>name</th>\n",
       "      <th>review_count</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>yelping_since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[cvVMmlU1ouS3I5fhutaryQ, nj6UZ8tdGo8YJ9lUMTVWN...</td>\n",
       "      <td>0</td>\n",
       "      <td>Johnny</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>oMy_rEb0UBEmMlu-zcxnoQ</td>\n",
       "      <td>2014-11-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0njfJmB-7n84DlIgUByCNw, rFn3Xe3RqHxRSxWOU19Gp...</td>\n",
       "      <td>0</td>\n",
       "      <td>Chris</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>JJ-aSuM4pCFPdkfoZ34q0Q</td>\n",
       "      <td>2013-09-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>Tiffy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>uUzsFQn_6cXDh6rPNGbIFA</td>\n",
       "      <td>2017-03-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>Mark</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>mBneaEEH5EMyxaVyqS-72A</td>\n",
       "      <td>2015-03-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>Evelyn</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>W5mJGs-dcDWRGEhAzUYtoA</td>\n",
       "      <td>2016-09-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   average_stars  compliment_cool  compliment_cute  compliment_funny  \\\n",
       "0           4.67                0                0                 0   \n",
       "1           3.70                0                0                 0   \n",
       "2           2.00                0                0                 0   \n",
       "3           4.67                0                0                 0   \n",
       "4           4.67                0                0                 0   \n",
       "\n",
       "   compliment_hot  compliment_list  compliment_more  compliment_note  \\\n",
       "0               0                0                0                0   \n",
       "1               0                0                0                0   \n",
       "2               0                0                0                0   \n",
       "3               0                0                0                0   \n",
       "4               0                0                0                0   \n",
       "\n",
       "   compliment_photos  compliment_plain      ...        cool  elite  fans  \\\n",
       "0                  0                 1      ...           0     []     0   \n",
       "1                  0                 0      ...           0     []     0   \n",
       "2                  0                 0      ...           0     []     0   \n",
       "3                  0                 0      ...           0     []     0   \n",
       "4                  0                 0      ...           0     []     0   \n",
       "\n",
       "                                             friends  funny    name  \\\n",
       "0  [cvVMmlU1ouS3I5fhutaryQ, nj6UZ8tdGo8YJ9lUMTVWN...      0  Johnny   \n",
       "1  [0njfJmB-7n84DlIgUByCNw, rFn3Xe3RqHxRSxWOU19Gp...      0   Chris   \n",
       "2                                                 []      0   Tiffy   \n",
       "3                                                 []      0    Mark   \n",
       "4                                                 []      0  Evelyn   \n",
       "\n",
       "   review_count useful                 user_id  yelping_since  \n",
       "0             8      0  oMy_rEb0UBEmMlu-zcxnoQ     2014-11-03  \n",
       "1            10      0  JJ-aSuM4pCFPdkfoZ34q0Q     2013-09-24  \n",
       "2             1      0  uUzsFQn_6cXDh6rPNGbIFA     2017-03-02  \n",
       "3             6      0  mBneaEEH5EMyxaVyqS-72A     2015-03-13  \n",
       "4             3      0  W5mJGs-dcDWRGEhAzUYtoA     2016-09-08  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All types of reviews - 10K dataset\n",
    "# reviews_df = pd.read_json(\"../dataset/review_10k.json\", lines=True)\n",
    "\n",
    "# Just restaurant reviews - 10K dataset\n",
    "reviews_df = pd.read_json(\"../dataset/restaurant_reviews_10k.json\", lines=True)\n",
    "\n",
    "# All types of reviews\n",
    "# reviews_df = pd.read_json(\"../../../final_project/full_dataset/review.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>This is one of my top 3 places to get BBQ pork...</td>\n",
       "      <td>2</td>\n",
       "      <td>FEg8v92qx3kK4Hu4TF28Fg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>This restaurant is famous for their BBQ dishes...</td>\n",
       "      <td>0</td>\n",
       "      <td>HPtjvIrhzAUkKsiVkeT4MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-10-23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Roasted pork is one of my favorite things... A...</td>\n",
       "      <td>1</td>\n",
       "      <td>MpvqV7lQcl15rflTBEUhXA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-07-30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>I walked by the restaurant more than 5 years a...</td>\n",
       "      <td>1</td>\n",
       "      <td>x-Gbs8sVid3yhJIoHD6Gfw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-02-07</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>I came here to order a roast duck over rice to...</td>\n",
       "      <td>0</td>\n",
       "      <td>7Dykd1HolQx8mKPYhYDYSg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool       date  funny  stars  \\\n",
       "0  --6MefnULPED_I942VcFNA     0 2017-08-17      0      4   \n",
       "1  --6MefnULPED_I942VcFNA     0 2017-05-31      0      3   \n",
       "2  --6MefnULPED_I942VcFNA     0 2016-10-23      0      2   \n",
       "3  --6MefnULPED_I942VcFNA     0 2017-07-30      0      2   \n",
       "4  --6MefnULPED_I942VcFNA     0 2017-02-07      1      2   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  This is one of my top 3 places to get BBQ pork...       2   \n",
       "1  This restaurant is famous for their BBQ dishes...       0   \n",
       "2  Roasted pork is one of my favorite things... A...       1   \n",
       "3  I walked by the restaurant more than 5 years a...       1   \n",
       "4  I came here to order a roast duck over rice to...       0   \n",
       "\n",
       "                  user_id  \n",
       "0  FEg8v92qx3kK4Hu4TF28Fg  \n",
       "1  HPtjvIrhzAUkKsiVkeT4MA  \n",
       "2  MpvqV7lQcl15rflTBEUhXA  \n",
       "3  x-Gbs8sVid3yhJIoHD6Gfw  \n",
       "4  7Dykd1HolQx8mKPYhYDYSg  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cool</th>\n",
       "      <th>funny</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.535000</td>\n",
       "      <td>0.458000</td>\n",
       "      <td>3.76540</td>\n",
       "      <td>1.037900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.866849</td>\n",
       "      <td>1.656958</td>\n",
       "      <td>1.31937</td>\n",
       "      <td>2.324307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cool         funny        stars        useful\n",
       "count  10000.000000  10000.000000  10000.00000  10000.000000\n",
       "mean       0.535000      0.458000      3.76540      1.037900\n",
       "std        1.866849      1.656958      1.31937      2.324307\n",
       "min        0.000000      0.000000      1.00000      0.000000\n",
       "25%        0.000000      0.000000      3.00000      0.000000\n",
       "50%        0.000000      0.000000      4.00000      0.000000\n",
       "75%        0.000000      0.000000      5.00000      1.000000\n",
       "max       68.000000     52.000000      5.00000     72.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df = pd.read_json(\"../dataset/business_10k.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>attributes</th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>hours</th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4855 E Warner Rd, Ste B9</td>\n",
       "      <td>{'AcceptsInsurance': True, 'ByAppointmentOnly'...</td>\n",
       "      <td>FYWN1wneV18bWNgQjJ2GNg</td>\n",
       "      <td>[Dentists, General Dentistry, Health &amp; Medical...</td>\n",
       "      <td>Ahwatukee</td>\n",
       "      <td>{'Friday': '7:30-17:00', 'Tuesday': '7:30-17:0...</td>\n",
       "      <td>1</td>\n",
       "      <td>33.330690</td>\n",
       "      <td>-111.978599</td>\n",
       "      <td>Dental by Design</td>\n",
       "      <td></td>\n",
       "      <td>85044</td>\n",
       "      <td>22</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3101 Washington Rd</td>\n",
       "      <td>{'BusinessParking': {'garage': False, 'street'...</td>\n",
       "      <td>He-G7vWjzVUysIKrfNbPUQ</td>\n",
       "      <td>[Hair Stylists, Hair Salons, Men's Hair Salons...</td>\n",
       "      <td>McMurray</td>\n",
       "      <td>{'Monday': '9:00-20:00', 'Tuesday': '9:00-20:0...</td>\n",
       "      <td>1</td>\n",
       "      <td>40.291685</td>\n",
       "      <td>-80.104900</td>\n",
       "      <td>Stephen Szabo Salon</td>\n",
       "      <td></td>\n",
       "      <td>15317</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6025 N 27th Ave, Ste 1</td>\n",
       "      <td>{}</td>\n",
       "      <td>KQPW8lFf1y5BT2MxiSZ3QA</td>\n",
       "      <td>[Departments of Motor Vehicles, Public Service...</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>33.524903</td>\n",
       "      <td>-112.115310</td>\n",
       "      <td>Western Motor Vehicle</td>\n",
       "      <td></td>\n",
       "      <td>85017</td>\n",
       "      <td>18</td>\n",
       "      <td>1.5</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000 Arizona Mills Cr, Ste 435</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': True, 'Restaura...</td>\n",
       "      <td>8DShNS-LuFqpEWIp0HxijA</td>\n",
       "      <td>[Sporting Goods, Shopping]</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>{'Monday': '10:00-21:00', 'Tuesday': '10:00-21...</td>\n",
       "      <td>0</td>\n",
       "      <td>33.383147</td>\n",
       "      <td>-111.964725</td>\n",
       "      <td>Sports Authority</td>\n",
       "      <td></td>\n",
       "      <td>85282</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>581 Howe Ave</td>\n",
       "      <td>{'Alcohol': 'full_bar', 'HasTV': True, 'NoiseL...</td>\n",
       "      <td>PfOCPjBrlQAnz__NXj9h_w</td>\n",
       "      <td>[American (New), Nightlife, Bars, Sandwiches, ...</td>\n",
       "      <td>Cuyahoga Falls</td>\n",
       "      <td>{'Monday': '11:00-1:00', 'Tuesday': '11:00-1:0...</td>\n",
       "      <td>1</td>\n",
       "      <td>41.119535</td>\n",
       "      <td>-81.475690</td>\n",
       "      <td>Brick House Tavern + Tap</td>\n",
       "      <td></td>\n",
       "      <td>44221</td>\n",
       "      <td>116</td>\n",
       "      <td>3.5</td>\n",
       "      <td>OH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          address  \\\n",
       "0        4855 E Warner Rd, Ste B9   \n",
       "1              3101 Washington Rd   \n",
       "2          6025 N 27th Ave, Ste 1   \n",
       "3  5000 Arizona Mills Cr, Ste 435   \n",
       "4                    581 Howe Ave   \n",
       "\n",
       "                                          attributes             business_id  \\\n",
       "0  {'AcceptsInsurance': True, 'ByAppointmentOnly'...  FYWN1wneV18bWNgQjJ2GNg   \n",
       "1  {'BusinessParking': {'garage': False, 'street'...  He-G7vWjzVUysIKrfNbPUQ   \n",
       "2                                                 {}  KQPW8lFf1y5BT2MxiSZ3QA   \n",
       "3  {'BusinessAcceptsCreditCards': True, 'Restaura...  8DShNS-LuFqpEWIp0HxijA   \n",
       "4  {'Alcohol': 'full_bar', 'HasTV': True, 'NoiseL...  PfOCPjBrlQAnz__NXj9h_w   \n",
       "\n",
       "                                          categories            city  \\\n",
       "0  [Dentists, General Dentistry, Health & Medical...       Ahwatukee   \n",
       "1  [Hair Stylists, Hair Salons, Men's Hair Salons...        McMurray   \n",
       "2  [Departments of Motor Vehicles, Public Service...         Phoenix   \n",
       "3                         [Sporting Goods, Shopping]           Tempe   \n",
       "4  [American (New), Nightlife, Bars, Sandwiches, ...  Cuyahoga Falls   \n",
       "\n",
       "                                               hours  is_open   latitude  \\\n",
       "0  {'Friday': '7:30-17:00', 'Tuesday': '7:30-17:0...        1  33.330690   \n",
       "1  {'Monday': '9:00-20:00', 'Tuesday': '9:00-20:0...        1  40.291685   \n",
       "2                                                 {}        1  33.524903   \n",
       "3  {'Monday': '10:00-21:00', 'Tuesday': '10:00-21...        0  33.383147   \n",
       "4  {'Monday': '11:00-1:00', 'Tuesday': '11:00-1:0...        1  41.119535   \n",
       "\n",
       "    longitude                      name neighborhood postal_code  \\\n",
       "0 -111.978599          Dental by Design                    85044   \n",
       "1  -80.104900       Stephen Szabo Salon                    15317   \n",
       "2 -112.115310     Western Motor Vehicle                    85017   \n",
       "3 -111.964725          Sports Authority                    85282   \n",
       "4  -81.475690  Brick House Tavern + Tap                    44221   \n",
       "\n",
       "   review_count  stars state  \n",
       "0            22    4.0    AZ  \n",
       "1            11    3.0    PA  \n",
       "2            18    1.5    AZ  \n",
       "3             9    3.0    AZ  \n",
       "4           116    3.5    OH  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df = pd.read_json(\"../dataset/checkin_10k.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7KPBkxAOEtb3QeIL9PEErg</td>\n",
       "      <td>{'Thursday': {'21:00': 4, '1:00': 1, '4:00': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kREVIrSBbtqBhIYkTccQUg</td>\n",
       "      <td>{'Monday': {'13:00': 1}, 'Thursday': {'20:00':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tJRDll5yqpZwehenzE2cSg</td>\n",
       "      <td>{'Monday': {'12:00': 1, '1:00': 1}, 'Friday': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r1p7RAMzCV_6NPF0dNoR3g</td>\n",
       "      <td>{'Thursday': {'23:00': 1}, 'Saturday': {'21:00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mDdqgfrvROGAumcQdZ3HIg</td>\n",
       "      <td>{'Monday': {'12:00': 1, '21:00': 1}, 'Wednesda...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                                               time\n",
       "0  7KPBkxAOEtb3QeIL9PEErg  {'Thursday': {'21:00': 4, '1:00': 1, '4:00': 1...\n",
       "1  kREVIrSBbtqBhIYkTccQUg  {'Monday': {'13:00': 1}, 'Thursday': {'20:00':...\n",
       "2  tJRDll5yqpZwehenzE2cSg  {'Monday': {'12:00': 1, '1:00': 1}, 'Friday': ...\n",
       "3  r1p7RAMzCV_6NPF0dNoR3g  {'Thursday': {'23:00': 1}, 'Saturday': {'21:00...\n",
       "4  mDdqgfrvROGAumcQdZ3HIg  {'Monday': {'12:00': 1, '21:00': 1}, 'Wednesda..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos_df = pd.read_json(\"../dataset/photos_10k.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>caption</th>\n",
       "      <th>label</th>\n",
       "      <th>photo_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OnAzbTDn79W6CFZIriqLrA</td>\n",
       "      <td></td>\n",
       "      <td>inside</td>\n",
       "      <td>soK1szeyan202jnsGhUDmA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OnAzbTDn79W6CFZIriqLrA</td>\n",
       "      <td></td>\n",
       "      <td>inside</td>\n",
       "      <td>dU7AyRB_fHOZkflodEyN5A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OnAzbTDn79W6CFZIriqLrA</td>\n",
       "      <td></td>\n",
       "      <td>outside</td>\n",
       "      <td>6T1qlbBdKkXA1cDNqMjg2g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OnAzbTDn79W6CFZIriqLrA</td>\n",
       "      <td>Bakery area</td>\n",
       "      <td>inside</td>\n",
       "      <td>lHhMNhCA7rAZmi-MMfF3ZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XaeCGHZzsMwvFcHYq3q9sA</td>\n",
       "      <td></td>\n",
       "      <td>food</td>\n",
       "      <td>oHSCeyoK9oLIGaCZq-wRJw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id      caption    label                photo_id\n",
       "0  OnAzbTDn79W6CFZIriqLrA                inside  soK1szeyan202jnsGhUDmA\n",
       "1  OnAzbTDn79W6CFZIriqLrA                inside  dU7AyRB_fHOZkflodEyN5A\n",
       "2  OnAzbTDn79W6CFZIriqLrA               outside  6T1qlbBdKkXA1cDNqMjg2g\n",
       "3  OnAzbTDn79W6CFZIriqLrA  Bakery area   inside  lHhMNhCA7rAZmi-MMfF3ZA\n",
       "4  XaeCGHZzsMwvFcHYq3q9sA                  food  oHSCeyoK9oLIGaCZq-wRJw"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip_df = pd.read_json(\"../dataset/tip_10k.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>likes</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tJRDll5yqpZwehenzE2cSg</td>\n",
       "      <td>2012-07-15</td>\n",
       "      <td>0</td>\n",
       "      <td>Get here early enough to have dinner.</td>\n",
       "      <td>zcTZk7OG8ovAmh_fenH21g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jH19V2I9fIslnNhDzPmdkA</td>\n",
       "      <td>2015-08-12</td>\n",
       "      <td>0</td>\n",
       "      <td>Great breakfast large portions and friendly wa...</td>\n",
       "      <td>ZcLKXikTHYOnYt5VYRO5sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dAa0hB2yrnHzVmsCkN4YvQ</td>\n",
       "      <td>2014-06-20</td>\n",
       "      <td>0</td>\n",
       "      <td>Nice place. Great staff.  A fixture in the tow...</td>\n",
       "      <td>oaYhjqBbh18ZhU0bpyzSuw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dAa0hB2yrnHzVmsCkN4YvQ</td>\n",
       "      <td>2016-10-12</td>\n",
       "      <td>0</td>\n",
       "      <td>Happy hour 5-7 Monday - Friday</td>\n",
       "      <td>ulQ8Nyj7jCUR8M83SUMoRQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESzO3Av0b1_TzKOiqzbQYQ</td>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>0</td>\n",
       "      <td>Parking is a premium, keep circling, you will ...</td>\n",
       "      <td>ulQ8Nyj7jCUR8M83SUMoRQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id       date  likes  \\\n",
       "0  tJRDll5yqpZwehenzE2cSg 2012-07-15      0   \n",
       "1  jH19V2I9fIslnNhDzPmdkA 2015-08-12      0   \n",
       "2  dAa0hB2yrnHzVmsCkN4YvQ 2014-06-20      0   \n",
       "3  dAa0hB2yrnHzVmsCkN4YvQ 2016-10-12      0   \n",
       "4  ESzO3Av0b1_TzKOiqzbQYQ 2017-01-28      0   \n",
       "\n",
       "                                                text                 user_id  \n",
       "0              Get here early enough to have dinner.  zcTZk7OG8ovAmh_fenH21g  \n",
       "1  Great breakfast large portions and friendly wa...  ZcLKXikTHYOnYt5VYRO5sg  \n",
       "2  Nice place. Great staff.  A fixture in the tow...  oaYhjqBbh18ZhU0bpyzSuw  \n",
       "3                     Happy hour 5-7 Monday - Friday  ulQ8Nyj7jCUR8M83SUMoRQ  \n",
       "4  Parking is a premium, keep circling, you will ...  ulQ8Nyj7jCUR8M83SUMoRQ  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tip_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Count Vectorizer\n",
      "(10000, 24872)\n"
     ]
    }
   ],
   "source": [
    "n_features = 100000\n",
    "\n",
    "text = reviews_df[\"text\"]\n",
    "\n",
    "print(\"Fitting Count Vectorizer\")\n",
    "# vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "#                                 max_features=n_features,\n",
    "#                                 stop_words='english')\n",
    "# word_vector = vectorizer.fit_transform(text)\n",
    "\n",
    "# No setting of hyper-parameters\n",
    "vectorizer = CountVectorizer()\n",
    "word_vector = vectorizer.fit_transform(text)\n",
    "\n",
    "print(np.shape(word_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At ces trade show and looking for lunch. I show up at 2:03 and the host jokingly says we are closed. We laughed. But he meant it. Last year my burger ordered medium came out almost raw. I am never going back\n",
      "1\n",
      "  (0, 17650)\t1\n",
      "  (0, 3376)\t1\n",
      "  (0, 13684)\t1\n",
      "  (0, 12582)\t1\n",
      "  (0, 4549)\t1\n",
      "  (0, 19037)\t1\n",
      "  (0, 11962)\t1\n",
      "  (0, 22483)\t1\n",
      "  (0, 3953)\t1\n",
      "  (0, 10897)\t1\n",
      "  (0, 13729)\t1\n",
      "  (0, 24528)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 12556)\t1\n",
      "  (0, 13164)\t1\n",
      "  (0, 15363)\t1\n",
      "  (0, 13056)\t1\n",
      "  (0, 19747)\t2\n",
      "  (0, 1101)\t1\n",
      "  (0, 10472)\t1\n",
      "  (0, 1133)\t1\n",
      "  (0, 3582)\t1\n",
      "  (0, 15453)\t1\n",
      "  (0, 14751)\t1\n",
      "  (0, 2016)\t1\n",
      "  (0, 1762)\t2\n",
      "  (0, 9793)\t1\n",
      "  (0, 23190)\t1\n",
      "  (0, 23929)\t2\n",
      "  (0, 1555)\t1\n",
      "  (0, 1239)\t2\n",
      "  (0, 8885)\t1\n",
      "  (0, 3440)\t1\n",
      "  (0, 22022)\t1\n",
      "  (0, 11748)\t1\n",
      "  (0, 14510)\t1\n"
     ]
    }
   ],
   "source": [
    "#Print example text, stars, and embeddings\n",
    "\n",
    "print(reviews_df[\"text\"][102])\n",
    "print(reviews_df[\"stars\"][102])\n",
    "print(word_vector[102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB Training and Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_user_reviews = reviews_df[\"text\"][0:6000]\n",
    "# x_dev_user_reviews = reviews_df[\"text\"][6001:8000]\n",
    "# x_test_user_reviews = reviews_df[\"text\"][8001:10000]\n",
    "\n",
    "\n",
    "# x_train_user_reviews = word_vector[0:6000]\n",
    "# x_dev_user_reviews = word_vector[6001:8000]\n",
    "x_train_user_reviews = word_vector[0:8000]\n",
    "x_test_user_reviews = word_vector[8001:10000]\n",
    "\n",
    "# print(\"x_train_user_reviews\", x_train_user_reviews)\n",
    "# print(\"shape x_train_user_reviews\", np.shape(x_train_user_reviews))\n",
    "\n",
    "\n",
    "\n",
    "# y_train_user_stars = reviews_df[\"stars\"][0:6000]\n",
    "# y_dev_user_stars = reviews_df[\"stars\"][6001:8000]\n",
    "y_train_user_stars = reviews_df[\"stars\"][0:8000]\n",
    "y_test_user_stars = reviews_df[\"stars\"][8001:10000]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_file = x_train_user_reviews\n",
    "label_file = y_train_user_stars\n",
    "training_data = x_train_user_reviews\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> 133             self.config.input_dim = self.training_data.shape[2]\n",
    "#     134             self.config.step_size = self.training_data.shape[1]\n",
    "#     135             self.config.label_dim = self.training_label.shape[1]\n",
    "\n",
    "# # print(training_data.shape[2])\n",
    "# print(training_data.shape[1])\n",
    "# print(np.shape(training_data))\n",
    "# print(len(training_data))\n",
    "# print(\"hi\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 55.93%\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "\n",
    "nb.fit(x_train_user_reviews, y_train_user_stars)\n",
    "\n",
    "y_pred = nb.predict(x_test_user_reviews)\n",
    "\n",
    "acc = accuracy_score(y_pred, y_test_user_stars)\n",
    "print(\"Accuracy on test set: {:.02%}\".format(acc))\n",
    "# pred_proba = nb.predict_proba(y_pred)\n",
    "# log_loss_metric = log_loss(y_test_user_stars, pred_proba)\n",
    "# print(\"Log-loss on test set: {:.02%}\".format(log_loss_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# Print example prediction\n",
    "\n",
    "print(y_pred[400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create New Slices of Review JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reviews_path = \"../../full_dataset/review.json\"\n",
    "# full_df = pd.read_json(\"../../full_dataset/review.json\", lines=True)\n",
    "# full_df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_100k = full_df[0:100000]\n",
    "# df_100k.to_json('../../full_dataset/df_100k.json', orient='records', lines=True)\n",
    "# df_100k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternate: LSTM Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "\n",
    "# !pip install keras\n",
    "# !pip install pandas_ml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Embedding, Dropout, Dense, LSTM\n",
    "from keras.callbacks import CSVLogger, History, ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, accuracy_score, precision_recall_fscore_support\n",
    "from pandas_ml import ConfusionMatrix\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "class YelpLSTM(object):\n",
    "    def __init__(self, parms):\n",
    "        self._parms = parms\n",
    "#         self._tokenizer = Tokenizer(nb_words=self._parms['vocabulary_size'])\n",
    "        self._tokenizer = Tokenizer(num_words=self._parms['vocabulary_size'])\n",
    "\n",
    "        self._reviews = None\n",
    "        self._balanced = None\n",
    "        self._glove = None\n",
    "        self._embedding_matrix = None\n",
    "        self._model = None\n",
    "        self._verbose = True\n",
    "        self._predicted_classes = None\n",
    "        self._predicted_proba = None\n",
    "        self._eval_actual = None\n",
    "        self._eval_predicted_proba = None\n",
    "        self._eval_predicted_classes = None\n",
    "        self._logs = None\n",
    "        self._tpr = None\n",
    "        self._fpr = None\n",
    "        self._thresholds = None\n",
    "        self._auc = None\n",
    "        self._target_range = None\n",
    "        \n",
    "    def console(self, message):\n",
    "        if self._verbose:\n",
    "            print(message)\n",
    "            \n",
    "    def update_parms(self, parms):\n",
    "        if parms['vocabulary_size'] != self._parms['vocabulary_size']:\n",
    "            self._tokenizer = Tokenizer(nb_words=parms['vocabulary_size'])\n",
    "        self._parms = parms\n",
    "\n",
    "    def load_reviews(self, reviews_path):\n",
    "        self.console('Loading reviews...')\n",
    "        \n",
    "        self._reviews = pd.read_json(reviews_path, lines=True)\n",
    "\n",
    "        self.console('%d reviews loaded.' % len(self._reviews))\n",
    "        \n",
    "#     def load_glove(self, glove_folder):\n",
    "    def load_glove(self, gloveFile):\n",
    "        self.console('Loading GloVe embeddings...')\n",
    "        glove = {}\n",
    "        count = 0\n",
    "#         with open(os.path.join(glove_folder, 'glove.6B.' + str(self._parms['embedding_dim']) + 'd.txt'), 'r') as f:\n",
    "\n",
    "        with open(gloveFile, 'r') as f:\n",
    "            while True:\n",
    "                line = f.readline()\n",
    "                if not line:\n",
    "                    break\n",
    "                line = line.split(' ')\n",
    "                word = line[0]\n",
    "                vector = np.asarray(line[1:], dtype='float32')\n",
    "                glove[word] = vector\n",
    "        self._glove = glove\n",
    "        self.console('%d embeddings loaded.' % len(self._glove))\n",
    "        \n",
    "    @property\n",
    "    def training(self):\n",
    "        return self._X_train, self._y_train\n",
    "    \n",
    "    @property\n",
    "    def test(self):\n",
    "        return self._X_test, self._y_test\n",
    "    \n",
    "    @property\n",
    "    def best_model(self):\n",
    "        return self._model\n",
    "    \n",
    "    @property\n",
    "    def predicted_classes(self):\n",
    "        return self._predicted_classes\n",
    "    \n",
    "    @property\n",
    "    def predicted_proba(self):\n",
    "        return self._predicted_proba\n",
    "    \n",
    "    @property\n",
    "    def tokenizer(self):\n",
    "        return self._tokenizer\n",
    "    \n",
    "    @property\n",
    "    def logs(self):\n",
    "        return self._logs\n",
    "        \n",
    "    @property\n",
    "    def confusion_matrix(self):\n",
    "        return self._cm\n",
    "    \n",
    "    @property\n",
    "    def prfs(self):\n",
    "        return self._prfs\n",
    "    \n",
    "    @property\n",
    "    def fpr(self):\n",
    "        return self._fpr\n",
    "    \n",
    "    @property\n",
    "    def tpr(self):\n",
    "        return self._tpr\n",
    "    \n",
    "    @property\n",
    "    def thresholds(self):\n",
    "        return self._thresholds\n",
    "    \n",
    "    @property\n",
    "    def auc(self):\n",
    "        return self._auc\n",
    "        \n",
    "    def _balance_dataset(self):\n",
    "        categories = []\n",
    "        samples = []\n",
    "                \n",
    "        self._target_range = range(2)\n",
    "        \n",
    "        if self._parms['target']['feature'] == 'stars':\n",
    "            prefix = ''\n",
    "            self._target_range = range(1,6)\n",
    "            \n",
    "        else:\n",
    "            prefix = 'is_'\n",
    "            self._reviews['is_' + self._parms['target']['feature']] = self._reviews[self._parms['target']['feature']].apply(lambda v: v > self._parms['target']['threshold']).astype(int)            \n",
    "        for i in self._target_range:\n",
    "            categories.append(self._reviews[self._reviews[prefix + self._parms['target']['feature']] == i])\n",
    "        \n",
    "        sizes = list(map(lambda s: len(s), categories))\n",
    "        \n",
    "        nb_samples = min(self._parms['samples'], np.min(sizes))\n",
    "        self.console('Using %s samples per category' % str(nb_samples))\n",
    "        \n",
    "        for category in categories:\n",
    "            samples.append(category.sample(n=nb_samples, random_state=32))\n",
    "        self._balanced = pd.concat(samples)\n",
    "       \n",
    "    def _build_datasets(self):\n",
    "        self._tokenizer.fit_on_texts(self._balanced.text.values)\n",
    "        \n",
    "        sequences = self._tokenizer.texts_to_sequences(self._balanced.text)\n",
    "        padded_seq = pad_sequences(sequences, maxlen=self._parms['seq_size'])\n",
    "        \n",
    "        if self._parms['target']['feature'] == 'stars':\n",
    "            target = to_categorical(self._balanced[self._parms['target']['feature']])\n",
    "        else:\n",
    "            target = self._balanced['is_' + self._parms['target']['feature']].values\n",
    "\n",
    "        self._X_train, self._X_test, self._y_train, self._y_test = train_test_split(padded_seq, target, test_size=0.2, random_state=42)\n",
    "            \n",
    "    def _build_embeddings(self):\n",
    "        tokenized_words = map(lambda t: t[0], sorted(self._tokenizer.word_index.items(), key=lambda t: t[1])[:self._parms['vocabulary_size']])\n",
    "\n",
    "        embedding_matrix = np.zeros((self._parms['vocabulary_size'], self._parms['embedding_dim']))\n",
    "        for idx, word in enumerate(tokenized_words):\n",
    "            try:\n",
    "                embedding_matrix[idx] = self._glove[word]\n",
    "            except:\n",
    "                pass\n",
    "        self._embedding_matrix = embedding_matrix\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Embedding(input_dim=self._parms['vocabulary_size'],\n",
    "                            output_dim=self._parms['embedding_dim'],\n",
    "                            input_length=self._parms['seq_size'],\n",
    "                            weights=[self._embedding_matrix],\n",
    "                            trainable=False))\n",
    "\n",
    "        model.add(LSTM(self._parms['memory_neurons']))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        activation = 'sigmoid'\n",
    "        loss = 'binary_crossentropy'        \n",
    "        \n",
    "        outputs = 1\n",
    "        \n",
    "        if len(self._y_train.shape) > 1:\n",
    "            activation = 'softmax'\n",
    "            loss = 'categorical_crossentropy'\n",
    "            outputs = self._y_train.shape[1]\n",
    "            \n",
    "        model.add(Dense(outputs, activation=activation))        \n",
    "        \n",
    "        model.compile(loss=loss, optimizer='nadam', metrics=['accuracy'])    \n",
    "    \n",
    "        self._model = model\n",
    "        self.console(self._model.summary())\n",
    "\n",
    "    def fit(self, model_name, folder='./', verbose=True):\n",
    "        self._verbose = verbose\n",
    "        \n",
    "        assert self._reviews is not None, 'Reviews file was not loaded'\n",
    "        assert len(self._reviews) > 0, 'Reviews file is empty'\n",
    "        assert self._glove is not None, 'GloVe file was not loaded'\n",
    "        assert len(self._glove) > 0, 'GloVe file is empty'\n",
    "        \n",
    "        self.console('Balancing dataset...')\n",
    "        self._balance_dataset()\n",
    "        self.console('Building training and test datasets...')\n",
    "        self._build_datasets()\n",
    "        self.console('Building word embeddings from GloVe...')\n",
    "        self._build_embeddings()\n",
    "        self.console('Building model...')\n",
    "        self._build_model()\n",
    "        self.console('Fitting model...')\n",
    "        \n",
    "        parms_desc = model_name + '_%ddim_%dvoc_%dseq' % (self._parms['embedding_dim'],\n",
    "                                                          self._parms['vocabulary_size'],\n",
    "                                                          self._parms['seq_size'])      \n",
    "        \n",
    "        hist = History()        \n",
    "        \n",
    "        logger = CSVLogger(os.path.join(folder, parms_desc) + '_training_logs.csv')     \n",
    "        \n",
    "        checks = ModelCheckpoint(os.path.join(folder, parms_desc) + '_model-{epoch:02d}_{val_acc:.2f}',\n",
    "                                 monitor='val_acc',\n",
    "                                 verbose=int(self._verbose),\n",
    "                                 save_best_only=True,\n",
    "                                 mode='max')\n",
    "        early_stopping = EarlyStopping(monitor='val_acc', patience=2)\n",
    "        \n",
    "        self._model.fit(self._X_train\n",
    "                        , self._y_train\n",
    "#                        , nb_epoch=self._parms['nb_epochs']\n",
    "                        , epochs=self._parms['epochs']\n",
    "                        , batch_size=self._parms['batch_size']\n",
    "                        , validation_data=(self._X_test, self._y_test)\n",
    "                        , callbacks=[checks, hist, logger, early_stopping]\n",
    "                        )\n",
    "        \n",
    "        self._logs = pd.read_csv(os.path.join(folder, parms_desc) + '_training_logs.csv')\n",
    "        best_epoch = self._logs['val_acc'].argmax()\n",
    "    \n",
    "        best_val_acc = '{:.2f}'.format(self._logs['val_acc'].iloc[best_epoch])\n",
    "        \n",
    "        best_model = (os.path.join(folder, parms_desc) + '_model-%02d_%s') % (best_epoch + 1, best_val_acc)\n",
    "        \n",
    "        with open(os.path.join(folder, parms_desc + '_tokenizer'), 'wb') as tok:\n",
    "            pickle.dump(self._tokenizer, tok)\n",
    "        \n",
    "        self.console('Calculating predictions for the best model...')\n",
    "        self._model = load_model(best_model)       \n",
    "        \n",
    "        self._predicted_proba = self.predict_proba()\n",
    "        if len(self._y_train.shape) > 1:\n",
    "            self._predicted_classes = np.argmax(self._predicted_proba, axis=1)\n",
    "            \n",
    "        else:\n",
    "            self._predicted_classes = (self._predicted_proba > 0.5).astype(int)\n",
    "        \n",
    "        self.console('Calculating metrics for the best model...')\n",
    "        self.evaluate()\n",
    "        self.console('Finished!')\n",
    "        \n",
    "        return self._model\n",
    "\n",
    "    def load(self, tokenizer, model):\n",
    "        error_msg = ''\n",
    "        try:\n",
    "            self._model = load_model(model)\n",
    "        except:\n",
    "            error_msg = 'Error loading model!'\n",
    "            \n",
    "        try:\n",
    "            with open(tokenizer, 'rb') as tok:\n",
    "                self._tokenizer = pickle.load(tok)\n",
    "        except:\n",
    "            error_msg = 'Error loading tokenizer!'\n",
    "            \n",
    "        return (error_msg == ''), error_msg\n",
    "    \n",
    "    def make_prediction(self, sentence):\n",
    "        sequence = self._tokenizer.texts_to_sequences([sentence])\n",
    "        padded_seq = pad_sequences(sequence, maxlen=self._parms['seq_size'])\n",
    "        return self.predict_classes(padded_seq)[0]\n",
    "    \n",
    "    def predict_classes(self, X=None, threshold=0.5):\n",
    "        if len(self._y_train.shape) > 1:\n",
    "            predictions = np.argmax(self.predict_proba(X), axis=1)\n",
    "        else:\n",
    "            predictions = (self.predict_proba(X) > threshold).astype(int)\n",
    "            \n",
    "        return predictions\n",
    "        \n",
    "    def predict_proba(self, X=None):\n",
    "        if X is None:\n",
    "            X = self._X_test\n",
    "        predictions = self._model.predict_proba(X)\n",
    "        return predictions\n",
    "    \n",
    "    def evaluate(self, actual=None, predicted_proba=None, threshold=0.5):\n",
    "        if actual is None:\n",
    "            eval_actual = self._y_test[:]\n",
    "        else:\n",
    "            eval_actual = actual[:]\n",
    "            \n",
    "        if predicted_proba is None:\n",
    "            eval_predicted_proba = self._predicted_proba[:]\n",
    "        else:\n",
    "            eval_predicted_proba = predicted_proba[:]\n",
    "            \n",
    "        if len(eval_actual.shape) == 1:\n",
    "            binary = True\n",
    "            eval_predicted_classes = (eval_predicted_proba > threshold).astype(int).ravel()\n",
    "            eval_predicted_proba = eval_predicted_proba.ravel()\n",
    "        else:\n",
    "            binary = False\n",
    "            eval_predicted_classes = eval_predicted_proba.argmax(axis=1)\n",
    "            eval_actual = eval_actual.argmax(axis=1)\n",
    "        \n",
    "        self._eval_actual = eval_actual\n",
    "        self._eval_predicted_proba = eval_predicted_proba\n",
    "        self._eval_predicted_classes = eval_predicted_classes\n",
    "    \n",
    "        self._cm = ConfusionMatrix(self._eval_actual, self._eval_predicted_classes)\n",
    "        \n",
    "        prfs = precision_recall_fscore_support(y_true=self._eval_actual, y_pred=self._eval_predicted_classes)\n",
    "        prfs = pd.DataFrame.from_dict(dict(zip(['precision', 'recall', 'fscore', 'support'], prfs)))\n",
    "        \n",
    "#         prfs.set_index([self._target_range], inplace=True)\n",
    "        \n",
    "        self._prfs = prfs\n",
    "        \n",
    "        if binary:\n",
    "            self._fpr, self._tpr, self._thresholds = roc_curve(self._eval_actual, self._eval_predicted_proba)\n",
    "            self._auc = auc(self._fpr, self._tpr)\n",
    "        else:\n",
    "            self._fpr, self._tpr, self._thresholds, self._auc = None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "parms = {\n",
    "#          'embedding_dim': 100,\n",
    "         'embedding_dim': 300,\n",
    "        \n",
    "         'vocabulary_size': 10000,\n",
    "         'seq_size': 400,\n",
    "\n",
    "         'epochs': 30,         \n",
    "#          'epochs': 2,\n",
    "         \n",
    "         'batch_size': 128,\n",
    "         'memory_neurons': 100,\n",
    "         'target': {\n",
    "             'feature': 'stars'\n",
    "             , 'threshold': None\n",
    "             },\n",
    "         'samples': 62500\n",
    "         }\n",
    "\n",
    "lstm = YelpLSTM(parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reviews...\n",
      "100000 reviews loaded.\n"
     ]
    }
   ],
   "source": [
    "# reviews_path = \"../dataset/review_10k.json\"\n",
    "\n",
    "# reviews_path = \"../dataset/restaurant_reviews_10k.json\"\n",
    "\n",
    "# reviews_path = \"../../full_dataset/review.json\"\n",
    "\n",
    "reviews_path = \"../../full_dataset/df_100k.json\"\n",
    "\n",
    "lstm.load_reviews(reviews_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time:  2018-08-03 17:35:01.331892\n",
      "Loading GloVe embeddings...\n",
      "400000 embeddings loaded.\n",
      "End time:  2018-08-03 17:35:30.773887\n",
      "Time taken:  0:00:29.441995\n"
     ]
    }
   ],
   "source": [
    "# # Small GloVe file\n",
    "gloveFile = \"../../glove/glove.6B.300d.txt\"\n",
    "\n",
    "# # Primary GloVe file\n",
    "# gloveFile = \"../../glove/glove.42B.300d.txt\"\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "print(\"Start time: \", start_time)\n",
    "\n",
    "lstm.load_glove(gloveFile)\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(\"End time: \", end_time)\n",
    "\n",
    "time_taken = end_time - start_time\n",
    "print(\"Time taken: \", time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing dataset...\n",
      "Using 8309 samples per category\n",
      "Building training and test datasets...\n",
      "Building word embeddings from GloVe...\n",
      "Building model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 400, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 3,161,006\n",
      "Trainable params: 161,006\n",
      "Non-trainable params: 3,000,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fitting model...\n",
      "Train on 33236 samples, validate on 8309 samples\n",
      "Epoch 1/30\n",
      "33236/33236 [==============================] - 279s 8ms/step - loss: 1.5098 - acc: 0.3223 - val_loss: 1.3319 - val_acc: 0.4164\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.41642, saving model to ./models/stars/stars_100neurons_300dim_10000voc_400seq_model-01_0.42\n",
      "Epoch 2/30\n",
      "33236/33236 [==============================] - 271s 8ms/step - loss: 1.2030 - acc: 0.4835 - val_loss: 1.1958 - val_acc: 0.4782\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.41642 to 0.47816, saving model to ./models/stars/stars_100neurons_300dim_10000voc_400seq_model-02_0.48\n",
      "Epoch 3/30\n",
      "33236/33236 [==============================] - 276s 8ms/step - loss: 1.0685 - acc: 0.5412 - val_loss: 1.1070 - val_acc: 0.5137\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.47816 to 0.51366, saving model to ./models/stars/stars_100neurons_300dim_10000voc_400seq_model-03_0.51\n",
      "Epoch 4/30\n",
      "33236/33236 [==============================] - 270s 8ms/step - loss: 0.9837 - acc: 0.5801 - val_loss: 1.0597 - val_acc: 0.5356\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.51366 to 0.53556, saving model to ./models/stars/stars_100neurons_300dim_10000voc_400seq_model-04_0.54\n",
      "Epoch 5/30\n",
      "33236/33236 [==============================] - 269s 8ms/step - loss: 0.9098 - acc: 0.6103 - val_loss: 1.0648 - val_acc: 0.5419\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.53556 to 0.54194, saving model to ./models/stars/stars_100neurons_300dim_10000voc_400seq_model-05_0.54\n",
      "Epoch 6/30\n",
      "33236/33236 [==============================] - 268s 8ms/step - loss: 0.8396 - acc: 0.6423 - val_loss: 1.0742 - val_acc: 0.5453\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.54194 to 0.54531, saving model to ./models/stars/stars_100neurons_300dim_10000voc_400seq_model-06_0.55\n",
      "Epoch 7/30\n",
      "33236/33236 [==============================] - 270s 8ms/step - loss: 0.7722 - acc: 0.6744 - val_loss: 1.1378 - val_acc: 0.5405\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.54531\n",
      "Epoch 8/30\n",
      "33236/33236 [==============================] - 270s 8ms/step - loss: 0.7068 - acc: 0.7038 - val_loss: 1.2500 - val_acc: 0.5182\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.54531\n",
      "Calculating predictions for the best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexanderherring/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:252: FutureWarning: 'argmax' is deprecated. Use 'idxmax' instead. The behavior of 'argmax' will be corrected to return the positional maximum in the future. Use 'series.values.argmax' to get the position of the maximum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self._predicted_classes [3 5 5 ..., 4 2 3]\n",
      "Calculating metrics for the best model...\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "model = lstm.fit(model_name='stars_100neurons', folder='./models/stars')\n",
    "# model = lstm.fit(model_name='stars_100neurons', folder='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4b77d199e8>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4b979ad208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lstm.confusion_matrix.plot(normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fscore</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.668693</td>\n",
       "      <td>0.710594</td>\n",
       "      <td>0.631458</td>\n",
       "      <td>1742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.478576</td>\n",
       "      <td>0.472024</td>\n",
       "      <td>0.485312</td>\n",
       "      <td>1634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.439636</td>\n",
       "      <td>0.452842</td>\n",
       "      <td>0.427179</td>\n",
       "      <td>1641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.468647</td>\n",
       "      <td>0.466269</td>\n",
       "      <td>0.471049</td>\n",
       "      <td>1658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.662085</td>\n",
       "      <td>0.622174</td>\n",
       "      <td>0.707466</td>\n",
       "      <td>1634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fscore  precision    recall  support\n",
       "0  0.668693   0.710594  0.631458     1742\n",
       "1  0.478576   0.472024  0.485312     1634\n",
       "2  0.439636   0.452842  0.427179     1641\n",
       "3  0.468647   0.466269  0.471049     1658\n",
       "4  0.662085   0.622174  0.707466     1634"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.prfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.make_prediction('i will never go there again, food was awful')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.make_prediction('most wonderful place i have ever been, food is amazing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.make_prediction('food is amazing and service is good')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.make_prediction('well, i am not sure, food was ok, but service was good')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.make_prediction('well, i am not sure, food was ok, but service was awful')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

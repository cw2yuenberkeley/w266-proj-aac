{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, json, time, unittest, datetime, shutil\n",
    "import itertools, collections\n",
    "from importlib import reload\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The data below is only on the 10k datasets for now. This will be updated to leverage the full datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pd.read_json(\"../dataset/user_10k.json\", lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_stars</th>\n",
       "      <th>compliment_cool</th>\n",
       "      <th>compliment_cute</th>\n",
       "      <th>compliment_funny</th>\n",
       "      <th>compliment_hot</th>\n",
       "      <th>compliment_list</th>\n",
       "      <th>compliment_more</th>\n",
       "      <th>compliment_note</th>\n",
       "      <th>compliment_photos</th>\n",
       "      <th>compliment_plain</th>\n",
       "      <th>...</th>\n",
       "      <th>cool</th>\n",
       "      <th>elite</th>\n",
       "      <th>fans</th>\n",
       "      <th>friends</th>\n",
       "      <th>funny</th>\n",
       "      <th>name</th>\n",
       "      <th>review_count</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>yelping_since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[cvVMmlU1ouS3I5fhutaryQ, nj6UZ8tdGo8YJ9lUMTVWN...</td>\n",
       "      <td>0</td>\n",
       "      <td>Johnny</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>oMy_rEb0UBEmMlu-zcxnoQ</td>\n",
       "      <td>2014-11-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0njfJmB-7n84DlIgUByCNw, rFn3Xe3RqHxRSxWOU19Gp...</td>\n",
       "      <td>0</td>\n",
       "      <td>Chris</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>JJ-aSuM4pCFPdkfoZ34q0Q</td>\n",
       "      <td>2013-09-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>Tiffy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>uUzsFQn_6cXDh6rPNGbIFA</td>\n",
       "      <td>2017-03-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>Mark</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>mBneaEEH5EMyxaVyqS-72A</td>\n",
       "      <td>2015-03-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>Evelyn</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>W5mJGs-dcDWRGEhAzUYtoA</td>\n",
       "      <td>2016-09-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   average_stars  compliment_cool  compliment_cute  compliment_funny  \\\n",
       "0           4.67                0                0                 0   \n",
       "1           3.70                0                0                 0   \n",
       "2           2.00                0                0                 0   \n",
       "3           4.67                0                0                 0   \n",
       "4           4.67                0                0                 0   \n",
       "\n",
       "   compliment_hot  compliment_list  compliment_more  compliment_note  \\\n",
       "0               0                0                0                0   \n",
       "1               0                0                0                0   \n",
       "2               0                0                0                0   \n",
       "3               0                0                0                0   \n",
       "4               0                0                0                0   \n",
       "\n",
       "   compliment_photos  compliment_plain      ...        cool  elite  fans  \\\n",
       "0                  0                 1      ...           0     []     0   \n",
       "1                  0                 0      ...           0     []     0   \n",
       "2                  0                 0      ...           0     []     0   \n",
       "3                  0                 0      ...           0     []     0   \n",
       "4                  0                 0      ...           0     []     0   \n",
       "\n",
       "                                             friends  funny    name  \\\n",
       "0  [cvVMmlU1ouS3I5fhutaryQ, nj6UZ8tdGo8YJ9lUMTVWN...      0  Johnny   \n",
       "1  [0njfJmB-7n84DlIgUByCNw, rFn3Xe3RqHxRSxWOU19Gp...      0   Chris   \n",
       "2                                                 []      0   Tiffy   \n",
       "3                                                 []      0    Mark   \n",
       "4                                                 []      0  Evelyn   \n",
       "\n",
       "   review_count useful                 user_id  yelping_since  \n",
       "0             8      0  oMy_rEb0UBEmMlu-zcxnoQ     2014-11-03  \n",
       "1            10      0  JJ-aSuM4pCFPdkfoZ34q0Q     2013-09-24  \n",
       "2             1      0  uUzsFQn_6cXDh6rPNGbIFA     2017-03-02  \n",
       "3             6      0  mBneaEEH5EMyxaVyqS-72A     2015-03-13  \n",
       "4             3      0  W5mJGs-dcDWRGEhAzUYtoA     2016-09-08  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All types of reviews - 10K dataset\n",
    "# reviews_df = pd.read_json(\"../dataset/review_10k.json\", lines=True)\n",
    "\n",
    "# Just restaurant reviews - 10K dataset\n",
    "reviews_df = pd.read_json(\"../dataset/restaurant_reviews_10k.json\", lines=True)\n",
    "\n",
    "# All types of reviews\n",
    "# reviews_df = pd.read_json(\"../../../final_project/full_dataset/review.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>This is one of my top 3 places to get BBQ pork...</td>\n",
       "      <td>2</td>\n",
       "      <td>FEg8v92qx3kK4Hu4TF28Fg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>This restaurant is famous for their BBQ dishes...</td>\n",
       "      <td>0</td>\n",
       "      <td>HPtjvIrhzAUkKsiVkeT4MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-10-23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Roasted pork is one of my favorite things... A...</td>\n",
       "      <td>1</td>\n",
       "      <td>MpvqV7lQcl15rflTBEUhXA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-07-30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>I walked by the restaurant more than 5 years a...</td>\n",
       "      <td>1</td>\n",
       "      <td>x-Gbs8sVid3yhJIoHD6Gfw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-02-07</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>I came here to order a roast duck over rice to...</td>\n",
       "      <td>0</td>\n",
       "      <td>7Dykd1HolQx8mKPYhYDYSg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool       date  funny  stars  \\\n",
       "0  --6MefnULPED_I942VcFNA     0 2017-08-17      0      4   \n",
       "1  --6MefnULPED_I942VcFNA     0 2017-05-31      0      3   \n",
       "2  --6MefnULPED_I942VcFNA     0 2016-10-23      0      2   \n",
       "3  --6MefnULPED_I942VcFNA     0 2017-07-30      0      2   \n",
       "4  --6MefnULPED_I942VcFNA     0 2017-02-07      1      2   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  This is one of my top 3 places to get BBQ pork...       2   \n",
       "1  This restaurant is famous for their BBQ dishes...       0   \n",
       "2  Roasted pork is one of my favorite things... A...       1   \n",
       "3  I walked by the restaurant more than 5 years a...       1   \n",
       "4  I came here to order a roast duck over rice to...       0   \n",
       "\n",
       "                  user_id  \n",
       "0  FEg8v92qx3kK4Hu4TF28Fg  \n",
       "1  HPtjvIrhzAUkKsiVkeT4MA  \n",
       "2  MpvqV7lQcl15rflTBEUhXA  \n",
       "3  x-Gbs8sVid3yhJIoHD6Gfw  \n",
       "4  7Dykd1HolQx8mKPYhYDYSg  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cool</th>\n",
       "      <th>funny</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.535000</td>\n",
       "      <td>0.458000</td>\n",
       "      <td>3.76540</td>\n",
       "      <td>1.037900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.866849</td>\n",
       "      <td>1.656958</td>\n",
       "      <td>1.31937</td>\n",
       "      <td>2.324307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cool         funny        stars        useful\n",
       "count  10000.000000  10000.000000  10000.00000  10000.000000\n",
       "mean       0.535000      0.458000      3.76540      1.037900\n",
       "std        1.866849      1.656958      1.31937      2.324307\n",
       "min        0.000000      0.000000      1.00000      0.000000\n",
       "25%        0.000000      0.000000      3.00000      0.000000\n",
       "50%        0.000000      0.000000      4.00000      0.000000\n",
       "75%        0.000000      0.000000      5.00000      1.000000\n",
       "max       68.000000     52.000000      5.00000     72.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df = pd.read_json(\"../dataset/business_10k.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>attributes</th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>hours</th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4855 E Warner Rd, Ste B9</td>\n",
       "      <td>{'AcceptsInsurance': True, 'ByAppointmentOnly'...</td>\n",
       "      <td>FYWN1wneV18bWNgQjJ2GNg</td>\n",
       "      <td>[Dentists, General Dentistry, Health &amp; Medical...</td>\n",
       "      <td>Ahwatukee</td>\n",
       "      <td>{'Friday': '7:30-17:00', 'Tuesday': '7:30-17:0...</td>\n",
       "      <td>1</td>\n",
       "      <td>33.330690</td>\n",
       "      <td>-111.978599</td>\n",
       "      <td>Dental by Design</td>\n",
       "      <td></td>\n",
       "      <td>85044</td>\n",
       "      <td>22</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3101 Washington Rd</td>\n",
       "      <td>{'BusinessParking': {'garage': False, 'street'...</td>\n",
       "      <td>He-G7vWjzVUysIKrfNbPUQ</td>\n",
       "      <td>[Hair Stylists, Hair Salons, Men's Hair Salons...</td>\n",
       "      <td>McMurray</td>\n",
       "      <td>{'Monday': '9:00-20:00', 'Tuesday': '9:00-20:0...</td>\n",
       "      <td>1</td>\n",
       "      <td>40.291685</td>\n",
       "      <td>-80.104900</td>\n",
       "      <td>Stephen Szabo Salon</td>\n",
       "      <td></td>\n",
       "      <td>15317</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6025 N 27th Ave, Ste 1</td>\n",
       "      <td>{}</td>\n",
       "      <td>KQPW8lFf1y5BT2MxiSZ3QA</td>\n",
       "      <td>[Departments of Motor Vehicles, Public Service...</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>33.524903</td>\n",
       "      <td>-112.115310</td>\n",
       "      <td>Western Motor Vehicle</td>\n",
       "      <td></td>\n",
       "      <td>85017</td>\n",
       "      <td>18</td>\n",
       "      <td>1.5</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000 Arizona Mills Cr, Ste 435</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': True, 'Restaura...</td>\n",
       "      <td>8DShNS-LuFqpEWIp0HxijA</td>\n",
       "      <td>[Sporting Goods, Shopping]</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>{'Monday': '10:00-21:00', 'Tuesday': '10:00-21...</td>\n",
       "      <td>0</td>\n",
       "      <td>33.383147</td>\n",
       "      <td>-111.964725</td>\n",
       "      <td>Sports Authority</td>\n",
       "      <td></td>\n",
       "      <td>85282</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>581 Howe Ave</td>\n",
       "      <td>{'Alcohol': 'full_bar', 'HasTV': True, 'NoiseL...</td>\n",
       "      <td>PfOCPjBrlQAnz__NXj9h_w</td>\n",
       "      <td>[American (New), Nightlife, Bars, Sandwiches, ...</td>\n",
       "      <td>Cuyahoga Falls</td>\n",
       "      <td>{'Monday': '11:00-1:00', 'Tuesday': '11:00-1:0...</td>\n",
       "      <td>1</td>\n",
       "      <td>41.119535</td>\n",
       "      <td>-81.475690</td>\n",
       "      <td>Brick House Tavern + Tap</td>\n",
       "      <td></td>\n",
       "      <td>44221</td>\n",
       "      <td>116</td>\n",
       "      <td>3.5</td>\n",
       "      <td>OH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          address  \\\n",
       "0        4855 E Warner Rd, Ste B9   \n",
       "1              3101 Washington Rd   \n",
       "2          6025 N 27th Ave, Ste 1   \n",
       "3  5000 Arizona Mills Cr, Ste 435   \n",
       "4                    581 Howe Ave   \n",
       "\n",
       "                                          attributes             business_id  \\\n",
       "0  {'AcceptsInsurance': True, 'ByAppointmentOnly'...  FYWN1wneV18bWNgQjJ2GNg   \n",
       "1  {'BusinessParking': {'garage': False, 'street'...  He-G7vWjzVUysIKrfNbPUQ   \n",
       "2                                                 {}  KQPW8lFf1y5BT2MxiSZ3QA   \n",
       "3  {'BusinessAcceptsCreditCards': True, 'Restaura...  8DShNS-LuFqpEWIp0HxijA   \n",
       "4  {'Alcohol': 'full_bar', 'HasTV': True, 'NoiseL...  PfOCPjBrlQAnz__NXj9h_w   \n",
       "\n",
       "                                          categories            city  \\\n",
       "0  [Dentists, General Dentistry, Health & Medical...       Ahwatukee   \n",
       "1  [Hair Stylists, Hair Salons, Men's Hair Salons...        McMurray   \n",
       "2  [Departments of Motor Vehicles, Public Service...         Phoenix   \n",
       "3                         [Sporting Goods, Shopping]           Tempe   \n",
       "4  [American (New), Nightlife, Bars, Sandwiches, ...  Cuyahoga Falls   \n",
       "\n",
       "                                               hours  is_open   latitude  \\\n",
       "0  {'Friday': '7:30-17:00', 'Tuesday': '7:30-17:0...        1  33.330690   \n",
       "1  {'Monday': '9:00-20:00', 'Tuesday': '9:00-20:0...        1  40.291685   \n",
       "2                                                 {}        1  33.524903   \n",
       "3  {'Monday': '10:00-21:00', 'Tuesday': '10:00-21...        0  33.383147   \n",
       "4  {'Monday': '11:00-1:00', 'Tuesday': '11:00-1:0...        1  41.119535   \n",
       "\n",
       "    longitude                      name neighborhood postal_code  \\\n",
       "0 -111.978599          Dental by Design                    85044   \n",
       "1  -80.104900       Stephen Szabo Salon                    15317   \n",
       "2 -112.115310     Western Motor Vehicle                    85017   \n",
       "3 -111.964725          Sports Authority                    85282   \n",
       "4  -81.475690  Brick House Tavern + Tap                    44221   \n",
       "\n",
       "   review_count  stars state  \n",
       "0            22    4.0    AZ  \n",
       "1            11    3.0    PA  \n",
       "2            18    1.5    AZ  \n",
       "3             9    3.0    AZ  \n",
       "4           116    3.5    OH  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df = pd.read_json(\"../dataset/checkin_10k.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7KPBkxAOEtb3QeIL9PEErg</td>\n",
       "      <td>{'Thursday': {'21:00': 4, '1:00': 1, '4:00': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kREVIrSBbtqBhIYkTccQUg</td>\n",
       "      <td>{'Monday': {'13:00': 1}, 'Thursday': {'20:00':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tJRDll5yqpZwehenzE2cSg</td>\n",
       "      <td>{'Monday': {'12:00': 1, '1:00': 1}, 'Friday': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r1p7RAMzCV_6NPF0dNoR3g</td>\n",
       "      <td>{'Thursday': {'23:00': 1}, 'Saturday': {'21:00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mDdqgfrvROGAumcQdZ3HIg</td>\n",
       "      <td>{'Monday': {'12:00': 1, '21:00': 1}, 'Wednesda...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                                               time\n",
       "0  7KPBkxAOEtb3QeIL9PEErg  {'Thursday': {'21:00': 4, '1:00': 1, '4:00': 1...\n",
       "1  kREVIrSBbtqBhIYkTccQUg  {'Monday': {'13:00': 1}, 'Thursday': {'20:00':...\n",
       "2  tJRDll5yqpZwehenzE2cSg  {'Monday': {'12:00': 1, '1:00': 1}, 'Friday': ...\n",
       "3  r1p7RAMzCV_6NPF0dNoR3g  {'Thursday': {'23:00': 1}, 'Saturday': {'21:00...\n",
       "4  mDdqgfrvROGAumcQdZ3HIg  {'Monday': {'12:00': 1, '21:00': 1}, 'Wednesda..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos_df = pd.read_json(\"../dataset/photos_10k.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>caption</th>\n",
       "      <th>label</th>\n",
       "      <th>photo_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OnAzbTDn79W6CFZIriqLrA</td>\n",
       "      <td></td>\n",
       "      <td>inside</td>\n",
       "      <td>soK1szeyan202jnsGhUDmA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OnAzbTDn79W6CFZIriqLrA</td>\n",
       "      <td></td>\n",
       "      <td>inside</td>\n",
       "      <td>dU7AyRB_fHOZkflodEyN5A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OnAzbTDn79W6CFZIriqLrA</td>\n",
       "      <td></td>\n",
       "      <td>outside</td>\n",
       "      <td>6T1qlbBdKkXA1cDNqMjg2g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OnAzbTDn79W6CFZIriqLrA</td>\n",
       "      <td>Bakery area</td>\n",
       "      <td>inside</td>\n",
       "      <td>lHhMNhCA7rAZmi-MMfF3ZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XaeCGHZzsMwvFcHYq3q9sA</td>\n",
       "      <td></td>\n",
       "      <td>food</td>\n",
       "      <td>oHSCeyoK9oLIGaCZq-wRJw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id      caption    label                photo_id\n",
       "0  OnAzbTDn79W6CFZIriqLrA                inside  soK1szeyan202jnsGhUDmA\n",
       "1  OnAzbTDn79W6CFZIriqLrA                inside  dU7AyRB_fHOZkflodEyN5A\n",
       "2  OnAzbTDn79W6CFZIriqLrA               outside  6T1qlbBdKkXA1cDNqMjg2g\n",
       "3  OnAzbTDn79W6CFZIriqLrA  Bakery area   inside  lHhMNhCA7rAZmi-MMfF3ZA\n",
       "4  XaeCGHZzsMwvFcHYq3q9sA                  food  oHSCeyoK9oLIGaCZq-wRJw"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip_df = pd.read_json(\"../dataset/tip_10k.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>likes</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tJRDll5yqpZwehenzE2cSg</td>\n",
       "      <td>2012-07-15</td>\n",
       "      <td>0</td>\n",
       "      <td>Get here early enough to have dinner.</td>\n",
       "      <td>zcTZk7OG8ovAmh_fenH21g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jH19V2I9fIslnNhDzPmdkA</td>\n",
       "      <td>2015-08-12</td>\n",
       "      <td>0</td>\n",
       "      <td>Great breakfast large portions and friendly wa...</td>\n",
       "      <td>ZcLKXikTHYOnYt5VYRO5sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dAa0hB2yrnHzVmsCkN4YvQ</td>\n",
       "      <td>2014-06-20</td>\n",
       "      <td>0</td>\n",
       "      <td>Nice place. Great staff.  A fixture in the tow...</td>\n",
       "      <td>oaYhjqBbh18ZhU0bpyzSuw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dAa0hB2yrnHzVmsCkN4YvQ</td>\n",
       "      <td>2016-10-12</td>\n",
       "      <td>0</td>\n",
       "      <td>Happy hour 5-7 Monday - Friday</td>\n",
       "      <td>ulQ8Nyj7jCUR8M83SUMoRQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESzO3Av0b1_TzKOiqzbQYQ</td>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>0</td>\n",
       "      <td>Parking is a premium, keep circling, you will ...</td>\n",
       "      <td>ulQ8Nyj7jCUR8M83SUMoRQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id       date  likes  \\\n",
       "0  tJRDll5yqpZwehenzE2cSg 2012-07-15      0   \n",
       "1  jH19V2I9fIslnNhDzPmdkA 2015-08-12      0   \n",
       "2  dAa0hB2yrnHzVmsCkN4YvQ 2014-06-20      0   \n",
       "3  dAa0hB2yrnHzVmsCkN4YvQ 2016-10-12      0   \n",
       "4  ESzO3Av0b1_TzKOiqzbQYQ 2017-01-28      0   \n",
       "\n",
       "                                                text                 user_id  \n",
       "0              Get here early enough to have dinner.  zcTZk7OG8ovAmh_fenH21g  \n",
       "1  Great breakfast large portions and friendly wa...  ZcLKXikTHYOnYt5VYRO5sg  \n",
       "2  Nice place. Great staff.  A fixture in the tow...  oaYhjqBbh18ZhU0bpyzSuw  \n",
       "3                     Happy hour 5-7 Monday - Friday  ulQ8Nyj7jCUR8M83SUMoRQ  \n",
       "4  Parking is a premium, keep circling, you will ...  ulQ8Nyj7jCUR8M83SUMoRQ  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tip_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Count Vectorizer\n",
      "(10000, 24872)\n"
     ]
    }
   ],
   "source": [
    "n_features = 100000\n",
    "\n",
    "text = reviews_df[\"text\"]\n",
    "\n",
    "print(\"Fitting Count Vectorizer\")\n",
    "# vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "#                                 max_features=n_features,\n",
    "#                                 stop_words='english')\n",
    "# word_vector = vectorizer.fit_transform(text)\n",
    "\n",
    "# No setting of hyper-parameters\n",
    "vectorizer = CountVectorizer()\n",
    "word_vector = vectorizer.fit_transform(text)\n",
    "\n",
    "print(np.shape(word_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At ces trade show and looking for lunch. I show up at 2:03 and the host jokingly says we are closed. We laughed. But he meant it. Last year my burger ordered medium came out almost raw. I am never going back\n",
      "1\n",
      "  (0, 17650)\t1\n",
      "  (0, 3376)\t1\n",
      "  (0, 13684)\t1\n",
      "  (0, 12582)\t1\n",
      "  (0, 4549)\t1\n",
      "  (0, 19037)\t1\n",
      "  (0, 11962)\t1\n",
      "  (0, 22483)\t1\n",
      "  (0, 3953)\t1\n",
      "  (0, 10897)\t1\n",
      "  (0, 13729)\t1\n",
      "  (0, 24528)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 12556)\t1\n",
      "  (0, 13164)\t1\n",
      "  (0, 15363)\t1\n",
      "  (0, 13056)\t1\n",
      "  (0, 19747)\t2\n",
      "  (0, 1101)\t1\n",
      "  (0, 10472)\t1\n",
      "  (0, 1133)\t1\n",
      "  (0, 3582)\t1\n",
      "  (0, 15453)\t1\n",
      "  (0, 14751)\t1\n",
      "  (0, 2016)\t1\n",
      "  (0, 1762)\t2\n",
      "  (0, 9793)\t1\n",
      "  (0, 23190)\t1\n",
      "  (0, 23929)\t2\n",
      "  (0, 1555)\t1\n",
      "  (0, 1239)\t2\n",
      "  (0, 8885)\t1\n",
      "  (0, 3440)\t1\n",
      "  (0, 22022)\t1\n",
      "  (0, 11748)\t1\n",
      "  (0, 14510)\t1\n"
     ]
    }
   ],
   "source": [
    "#Print example text, stars, and embeddings\n",
    "\n",
    "print(reviews_df[\"text\"][102])\n",
    "print(reviews_df[\"stars\"][102])\n",
    "print(word_vector[102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB Training and Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_user_reviews = reviews_df[\"text\"][0:6000]\n",
    "# x_dev_user_reviews = reviews_df[\"text\"][6001:8000]\n",
    "# x_test_user_reviews = reviews_df[\"text\"][8001:10000]\n",
    "\n",
    "\n",
    "# x_train_user_reviews = word_vector[0:6000]\n",
    "# x_dev_user_reviews = word_vector[6001:8000]\n",
    "x_train_user_reviews = word_vector[0:8000]\n",
    "x_test_user_reviews = word_vector[8001:10000]\n",
    "\n",
    "# print(\"x_train_user_reviews\", x_train_user_reviews)\n",
    "# print(\"shape x_train_user_reviews\", np.shape(x_train_user_reviews))\n",
    "\n",
    "\n",
    "\n",
    "# y_train_user_stars = reviews_df[\"stars\"][0:6000]\n",
    "# y_dev_user_stars = reviews_df[\"stars\"][6001:8000]\n",
    "y_train_user_stars = reviews_df[\"stars\"][0:8000]\n",
    "y_test_user_stars = reviews_df[\"stars\"][8001:10000]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_file = x_train_user_reviews\n",
    "label_file = y_train_user_stars\n",
    "training_data = x_train_user_reviews\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> 133             self.config.input_dim = self.training_data.shape[2]\n",
    "#     134             self.config.step_size = self.training_data.shape[1]\n",
    "#     135             self.config.label_dim = self.training_label.shape[1]\n",
    "\n",
    "# # print(training_data.shape[2])\n",
    "# print(training_data.shape[1])\n",
    "# print(np.shape(training_data))\n",
    "# print(len(training_data))\n",
    "# print(\"hi\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 55.93%\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "\n",
    "nb.fit(x_train_user_reviews, y_train_user_stars)\n",
    "\n",
    "y_pred = nb.predict(x_test_user_reviews)\n",
    "\n",
    "acc = accuracy_score(y_pred, y_test_user_stars)\n",
    "print(\"Accuracy on test set: {:.02%}\".format(acc))\n",
    "# pred_proba = nb.predict_proba(y_pred)\n",
    "# log_loss_metric = log_loss(y_test_user_stars, pred_proba)\n",
    "# print(\"Log-loss on test set: {:.02%}\".format(log_loss_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# Print example prediction\n",
    "\n",
    "print(y_pred[400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create New Slices of Review JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reviews_path = \"../../full_dataset/review.json\"\n",
    "# full_df = pd.read_json(\"../../full_dataset/review.json\", lines=True)\n",
    "# full_df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_100k = full_df[0:100000]\n",
    "# df_100k.to_json('../../full_dataset/df_100k.json', orient='records', lines=True)\n",
    "# df_100k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternate: LSTM Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "\n",
    "# !pip install keras\n",
    "# !pip install pandas_ml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Embedding, Dropout, Dense, LSTM\n",
    "from keras.callbacks import CSVLogger, History, ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, accuracy_score, precision_recall_fscore_support\n",
    "from pandas_ml import ConfusionMatrix\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "class YelpLSTM(object):\n",
    "    def __init__(self, parms):\n",
    "        self._parms = parms\n",
    "#         self._tokenizer = Tokenizer(nb_words=self._parms['vocabulary_size'])\n",
    "        self._tokenizer = Tokenizer(num_words=self._parms['vocabulary_size'])\n",
    "\n",
    "        self._reviews = None\n",
    "        self._balanced = None\n",
    "        self._glove = None\n",
    "        self._embedding_matrix = None\n",
    "        self._model = None\n",
    "        self._verbose = True\n",
    "        self._predicted_classes = None\n",
    "        self._predicted_proba = None\n",
    "        self._eval_actual = None\n",
    "        self._eval_predicted_proba = None\n",
    "        self._eval_predicted_classes = None\n",
    "        self._logs = None\n",
    "        self._tpr = None\n",
    "        self._fpr = None\n",
    "        self._thresholds = None\n",
    "        self._auc = None\n",
    "        self._target_range = None\n",
    "        \n",
    "    def console(self, message):\n",
    "        if self._verbose:\n",
    "            print(message)\n",
    "            \n",
    "    def update_parms(self, parms):\n",
    "        if parms['vocabulary_size'] != self._parms['vocabulary_size']:\n",
    "            self._tokenizer = Tokenizer(nb_words=parms['vocabulary_size'])\n",
    "        self._parms = parms\n",
    "\n",
    "    def load_reviews(self, reviews_path):\n",
    "        self.console('Loading reviews...')\n",
    "        \n",
    "        self._reviews = pd.read_json(reviews_path, lines=True)\n",
    "\n",
    "        self.console('%d reviews loaded.' % len(self._reviews))\n",
    "        \n",
    "#     def load_glove(self, glove_folder):\n",
    "    # Changing to only load single file\n",
    "    def load_glove(self, gloveFile):\n",
    "        self.console('Loading GloVe embeddings...')\n",
    "        glove = {}\n",
    "        count = 0\n",
    "#         with open(os.path.join(glove_folder, 'glove.6B.' + str(self._parms['embedding_dim']) + 'd.txt'), 'r') as f:\n",
    "\n",
    "        with open(gloveFile, 'r') as f:\n",
    "            while True:\n",
    "                line = f.readline()\n",
    "                if not line:\n",
    "                    break\n",
    "                line = line.split(' ')\n",
    "                word = line[0]\n",
    "                vector = np.asarray(line[1:], dtype='float32')\n",
    "                glove[word] = vector\n",
    "        self._glove = glove\n",
    "        self.console('%d embeddings loaded.' % len(self._glove))\n",
    "        \n",
    "    @property\n",
    "    def training(self):\n",
    "        return self._X_train, self._y_train\n",
    "    \n",
    "    @property\n",
    "    def test(self):\n",
    "        return self._X_test, self._y_test\n",
    "    \n",
    "    @property\n",
    "    def best_model(self):\n",
    "        return self._model\n",
    "    \n",
    "    @property\n",
    "    def predicted_classes(self):\n",
    "        return self._predicted_classes\n",
    "    \n",
    "    @property\n",
    "    def predicted_proba(self):\n",
    "        return self._predicted_proba\n",
    "    \n",
    "    @property\n",
    "    def tokenizer(self):\n",
    "        return self._tokenizer\n",
    "    \n",
    "    @property\n",
    "    def logs(self):\n",
    "        return self._logs\n",
    "        \n",
    "    @property\n",
    "    def confusion_matrix(self):\n",
    "        return self._cm\n",
    "    \n",
    "    @property\n",
    "    def prfs(self):\n",
    "        return self._prfs\n",
    "    \n",
    "    @property\n",
    "    def fpr(self):\n",
    "        return self._fpr\n",
    "    \n",
    "    @property\n",
    "    def tpr(self):\n",
    "        return self._tpr\n",
    "    \n",
    "    @property\n",
    "    def thresholds(self):\n",
    "        return self._thresholds\n",
    "    \n",
    "    @property\n",
    "    def auc(self):\n",
    "        return self._auc\n",
    "        \n",
    "    def _balance_dataset(self):\n",
    "        categories = []\n",
    "        samples = []\n",
    "                \n",
    "        self._target_range = range(2)\n",
    "        \n",
    "        if self._parms['target']['feature'] == 'stars':\n",
    "            prefix = ''\n",
    "            self._target_range = range(1,6)\n",
    "            \n",
    "        else:\n",
    "            prefix = 'is_'\n",
    "            self._reviews['is_' + self._parms['target']['feature']] = self._reviews[self._parms['target']['feature']].apply(lambda v: v > self._parms['target']['threshold']).astype(int)            \n",
    "        for i in self._target_range:\n",
    "            categories.append(self._reviews[self._reviews[prefix + self._parms['target']['feature']] == i])\n",
    "        \n",
    "        sizes = list(map(lambda s: len(s), categories))\n",
    "        \n",
    "        nb_samples = min(self._parms['samples'], np.min(sizes))\n",
    "        self.console('Using %s samples per category' % str(nb_samples))\n",
    "        \n",
    "        for category in categories:\n",
    "            samples.append(category.sample(n=nb_samples, random_state=32))\n",
    "        self._balanced = pd.concat(samples)\n",
    "       \n",
    "    def _build_datasets(self):\n",
    "        self._tokenizer.fit_on_texts(self._balanced.text.values)\n",
    "        \n",
    "        sequences = self._tokenizer.texts_to_sequences(self._balanced.text)\n",
    "        padded_seq = pad_sequences(sequences, maxlen=self._parms['seq_size'])\n",
    "        \n",
    "        if self._parms['target']['feature'] == 'stars':\n",
    "            target = to_categorical(self._balanced[self._parms['target']['feature']])\n",
    "        else:\n",
    "            target = self._balanced['is_' + self._parms['target']['feature']].values\n",
    "\n",
    "        # Original\n",
    "#         self._X_train, self._X_test, self._y_train, self._y_test = train_test_split(padded_seq, target, test_size=0.2, random_state=42)\n",
    "        # Updates to randomization to replicate shared restaurant_reviews_final.JSON\n",
    "        self._X_train, self._X_test, self._y_train, self._y_test = train_test_split(padded_seq, target, test_size=0.2, random_state=123)\n",
    "            \n",
    "    def _build_embeddings(self):\n",
    "        tokenized_words = map(lambda t: t[0], sorted(self._tokenizer.word_index.items(), key=lambda t: t[1])[:self._parms['vocabulary_size']])\n",
    "\n",
    "        embedding_matrix = np.zeros((self._parms['vocabulary_size'], self._parms['embedding_dim']))\n",
    "        for idx, word in enumerate(tokenized_words):\n",
    "            try:\n",
    "                embedding_matrix[idx] = self._glove[word]\n",
    "            except:\n",
    "                pass\n",
    "        self._embedding_matrix = embedding_matrix\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Embedding(input_dim=self._parms['vocabulary_size'],\n",
    "                            output_dim=self._parms['embedding_dim'],\n",
    "                            input_length=self._parms['seq_size'],\n",
    "                            weights=[self._embedding_matrix],\n",
    "                            trainable=False))\n",
    "\n",
    "        model.add(LSTM(self._parms['memory_neurons']))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        activation = 'sigmoid'\n",
    "        loss = 'binary_crossentropy'        \n",
    "        \n",
    "        outputs = 1\n",
    "        \n",
    "        if len(self._y_train.shape) > 1:\n",
    "            activation = 'softmax'\n",
    "            loss = 'categorical_crossentropy'\n",
    "            outputs = self._y_train.shape[1]\n",
    "            \n",
    "        model.add(Dense(outputs, activation=activation))        \n",
    "        \n",
    "        model.compile(loss=loss, optimizer='nadam', metrics=['accuracy'])    \n",
    "    \n",
    "        self._model = model\n",
    "        self.console(self._model.summary())\n",
    "\n",
    "    def fit(self, model_name, folder='./', verbose=True):\n",
    "        self._verbose = verbose\n",
    "        \n",
    "        assert self._reviews is not None, 'Reviews file was not loaded'\n",
    "        assert len(self._reviews) > 0, 'Reviews file is empty'\n",
    "        assert self._glove is not None, 'GloVe file was not loaded'\n",
    "        assert len(self._glove) > 0, 'GloVe file is empty'\n",
    "        \n",
    "        self.console('Balancing dataset...')\n",
    "        self._balance_dataset()\n",
    "        self.console('Building training and test datasets...')\n",
    "        self._build_datasets()\n",
    "        self.console('Building word embeddings from GloVe...')\n",
    "        self._build_embeddings()\n",
    "        self.console('Building model...')\n",
    "        self._build_model()\n",
    "        self.console('Fitting model...')\n",
    "        \n",
    "        parms_desc = model_name + '_%ddim_%dvoc_%dseq' % (self._parms['embedding_dim'],\n",
    "                                                          self._parms['vocabulary_size'],\n",
    "                                                          self._parms['seq_size'])      \n",
    "        \n",
    "        hist = History()        \n",
    "        \n",
    "        logger = CSVLogger(os.path.join(folder, parms_desc) + '_training_logs.csv')     \n",
    "        \n",
    "        checks = ModelCheckpoint(os.path.join(folder, parms_desc) + '_model-{epoch:02d}_{val_acc:.2f}',\n",
    "                                 monitor='val_acc',\n",
    "                                 verbose=int(self._verbose),\n",
    "                                 save_best_only=True,\n",
    "                                 mode='max')\n",
    "        early_stopping = EarlyStopping(monitor='val_acc', patience=2)\n",
    "        \n",
    "        self._model.fit(self._X_train\n",
    "                        , self._y_train\n",
    "#                        , nb_epoch=self._parms['nb_epochs']\n",
    "                        , epochs=self._parms['epochs']\n",
    "                        , batch_size=self._parms['batch_size']\n",
    "                        , validation_data=(self._X_test, self._y_test)\n",
    "                        , callbacks=[checks, hist, logger, early_stopping]\n",
    "                        )\n",
    "        \n",
    "        self._logs = pd.read_csv(os.path.join(folder, parms_desc) + '_training_logs.csv')\n",
    "        best_epoch = self._logs['val_acc'].argmax()\n",
    "    \n",
    "        best_val_acc = '{:.2f}'.format(self._logs['val_acc'].iloc[best_epoch])\n",
    "        \n",
    "        best_model = (os.path.join(folder, parms_desc) + '_model-%02d_%s') % (best_epoch + 1, best_val_acc)\n",
    "        \n",
    "        with open(os.path.join(folder, parms_desc + '_tokenizer'), 'wb') as tok:\n",
    "            pickle.dump(self._tokenizer, tok)\n",
    "        \n",
    "        self.console('Calculating predictions for the best model...')\n",
    "        self._model = load_model(best_model)       \n",
    "        \n",
    "        self._predicted_proba = self.predict_proba()\n",
    "        if len(self._y_train.shape) > 1:\n",
    "            self._predicted_classes = np.argmax(self._predicted_proba, axis=1)\n",
    "            \n",
    "        else:\n",
    "            self._predicted_classes = (self._predicted_proba > 0.5).astype(int)\n",
    "        \n",
    "        self.console('Calculating metrics for the best model...')\n",
    "        self.evaluate()\n",
    "        self.console('Finished!')\n",
    "        \n",
    "        return self._model\n",
    "\n",
    "    def load(self, tokenizer, model):\n",
    "        error_msg = ''\n",
    "        try:\n",
    "            self._model = load_model(model)\n",
    "        except:\n",
    "            error_msg = 'Error loading model!'\n",
    "            \n",
    "        try:\n",
    "            with open(tokenizer, 'rb') as tok:\n",
    "                self._tokenizer = pickle.load(tok)\n",
    "        except:\n",
    "            error_msg = 'Error loading tokenizer!'\n",
    "            \n",
    "        return (error_msg == ''), error_msg\n",
    "    \n",
    "    def make_prediction(self, sentence):\n",
    "        sequence = self._tokenizer.texts_to_sequences([sentence])\n",
    "        padded_seq = pad_sequences(sequence, maxlen=self._parms['seq_size'])\n",
    "        return self.predict_classes(padded_seq)[0]\n",
    "    \n",
    "    def predict_classes(self, X=None, threshold=0.5):\n",
    "        if len(self._y_train.shape) > 1:\n",
    "            predictions = np.argmax(self.predict_proba(X), axis=1)\n",
    "        else:\n",
    "            predictions = (self.predict_proba(X) > threshold).astype(int)\n",
    "            \n",
    "        return predictions\n",
    "        \n",
    "    def predict_proba(self, X=None):\n",
    "        if X is None:\n",
    "            X = self._X_test\n",
    "        predictions = self._model.predict_proba(X)\n",
    "        return predictions\n",
    "    \n",
    "    def evaluate(self, actual=None, predicted_proba=None, threshold=0.5):\n",
    "        if actual is None:\n",
    "            eval_actual = self._y_test[:]\n",
    "        else:\n",
    "            eval_actual = actual[:]\n",
    "            \n",
    "        if predicted_proba is None:\n",
    "            eval_predicted_proba = self._predicted_proba[:]\n",
    "        else:\n",
    "            eval_predicted_proba = predicted_proba[:]\n",
    "            \n",
    "        if len(eval_actual.shape) == 1:\n",
    "            binary = True\n",
    "            eval_predicted_classes = (eval_predicted_proba > threshold).astype(int).ravel()\n",
    "            eval_predicted_proba = eval_predicted_proba.ravel()\n",
    "        else:\n",
    "            binary = False\n",
    "            eval_predicted_classes = eval_predicted_proba.argmax(axis=1)\n",
    "            eval_actual = eval_actual.argmax(axis=1)\n",
    "        \n",
    "        self._eval_actual = eval_actual\n",
    "        self._eval_predicted_proba = eval_predicted_proba\n",
    "        self._eval_predicted_classes = eval_predicted_classes\n",
    "    \n",
    "        self._cm = ConfusionMatrix(self._eval_actual, self._eval_predicted_classes)\n",
    "        \n",
    "        prfs = precision_recall_fscore_support(y_true=self._eval_actual, y_pred=self._eval_predicted_classes)\n",
    "        prfs = pd.DataFrame.from_dict(dict(zip(['precision', 'recall', 'fscore', 'support'], prfs)))\n",
    "        \n",
    "#         prfs.set_index([self._target_range], inplace=True)\n",
    "        \n",
    "        self._prfs = prfs\n",
    "        \n",
    "        if binary:\n",
    "            self._fpr, self._tpr, self._thresholds = roc_curve(self._eval_actual, self._eval_predicted_proba)\n",
    "            self._auc = auc(self._fpr, self._tpr)\n",
    "        else:\n",
    "            self._fpr, self._tpr, self._thresholds, self._auc = None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "parms = {\n",
    "#          'embedding_dim': 100,\n",
    "         'embedding_dim': 300,\n",
    "        \n",
    "         'vocabulary_size': 10000,\n",
    "         'seq_size': 400,\n",
    "\n",
    "         'epochs': 30,         \n",
    "#          'epochs': 2,\n",
    "         \n",
    "         'batch_size': 128,\n",
    "         'memory_neurons': 100,\n",
    "         'target': {\n",
    "             'feature': 'stars'\n",
    "             , 'threshold': None\n",
    "             },\n",
    "#          'samples': 62500\n",
    "         'samples': 1000000\n",
    "         }\n",
    "\n",
    "lstm = YelpLSTM(parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reviews...\n",
      "3221419 reviews loaded.\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "print(\"Start time: \", start_time)\n",
    "\n",
    "# reviews_path = \"../dataset/review_10k.json\"\n",
    "\n",
    "# reviews_path = \"../dataset/restaurant_reviews_10k.json\"\n",
    "\n",
    "# reviews_path = \"../../full_dataset/review.json\"\n",
    "\n",
    "# reviews_path = \"../../full_dataset/df_100k.json\"\n",
    "\n",
    "reviews_path = \"../../full_dataset/restaurant_reviews.json\"\n",
    "\n",
    "lstm.load_reviews(reviews_path)\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(\"End time: \", end_time)\n",
    "\n",
    "time_taken = end_time - start_time\n",
    "print(\"Time taken: \", time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time:  2018-08-05 19:28:22.612616\n",
      "Loading GloVe embeddings...\n",
      "400000 embeddings loaded.\n",
      "End time:  2018-08-05 19:28:51.133753\n",
      "Time taken:  0:00:28.521137\n"
     ]
    }
   ],
   "source": [
    "# Primary GloVe file\n",
    "gloveFile = \"../../glove/glove.6B.300d.txt\"\n",
    "\n",
    "# Large GloVe file\n",
    "# gloveFile = \"../../glove/glove.42B.300d.txt\"\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "print(\"Start time: \", start_time)\n",
    "\n",
    "lstm.load_glove(gloveFile)\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(\"End time: \", end_time)\n",
    "\n",
    "time_taken = end_time - start_time\n",
    "print(\"Time taken: \", time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing dataset...\n",
      "Using 310257 samples per category\n",
      "Building training and test datasets...\n",
      "Building word embeddings from GloVe...\n",
      "Building model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 400, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 3,161,006\n",
      "Trainable params: 161,006\n",
      "Non-trainable params: 3,000,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fitting model...\n",
      "Train on 1241028 samples, validate on 310257 samples\n",
      "Epoch 1/30\n",
      "1241028/1241028 [==============================] - 9055s 7ms/step - loss: 0.9350 - acc: 0.5874 - val_loss: 0.8448 - val_acc: 0.6290\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.62896, saving model to ./models/stars/stars_100neurons_300dim_10000voc_400seq_model-01_0.63\n",
      "Epoch 2/30\n",
      "1241028/1241028 [==============================] - 9065s 7ms/step - loss: 0.8381 - acc: 0.6313 - val_loss: 0.8312 - val_acc: 0.6333\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.62896 to 0.63326, saving model to ./models/stars/stars_100neurons_300dim_10000voc_400seq_model-02_0.63\n",
      "Epoch 3/30\n",
      "1241028/1241028 [==============================] - 9066s 7ms/step - loss: 0.8161 - acc: 0.6409 - val_loss: 0.8139 - val_acc: 0.6412\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.63326 to 0.64116, saving model to ./models/stars/stars_100neurons_300dim_10000voc_400seq_model-03_0.64\n",
      "Epoch 4/30\n",
      "1241028/1241028 [==============================] - 9060s 7ms/step - loss: 0.8035 - acc: 0.6463 - val_loss: 0.8084 - val_acc: 0.6425\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.64116 to 0.64251, saving model to ./models/stars/stars_100neurons_300dim_10000voc_400seq_model-04_0.64\n",
      "Epoch 5/30\n",
      "1241028/1241028 [==============================] - 9107s 7ms/step - loss: 0.7947 - acc: 0.6503 - val_loss: 0.8049 - val_acc: 0.6458\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.64251 to 0.64582, saving model to ./models/stars/stars_100neurons_300dim_10000voc_400seq_model-05_0.65\n",
      "Epoch 6/30\n",
      "1241028/1241028 [==============================] - 9092s 7ms/step - loss: 0.7881 - acc: 0.6535 - val_loss: 0.8016 - val_acc: 0.6464\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.64582 to 0.64645, saving model to ./models/stars/stars_100neurons_300dim_10000voc_400seq_model-06_0.65\n",
      "Epoch 7/30\n",
      "1241028/1241028 [==============================] - 9094s 7ms/step - loss: 0.7842 - acc: 0.6550 - val_loss: 0.8044 - val_acc: 0.6456\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.64645\n",
      "Epoch 8/30\n",
      "1241028/1241028 [==============================] - 9099s 7ms/step - loss: 0.7802 - acc: 0.6571 - val_loss: 0.8051 - val_acc: 0.6446\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.64645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexanderherring/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:255: FutureWarning: 'argmax' is deprecated. Use 'idxmax' instead. The behavior of 'argmax' will be corrected to return the positional maximum in the future. Use 'series.values.argmax' to get the position of the maximum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating predictions for the best model...\n",
      "Calculating metrics for the best model...\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "print(\"Start time: \", start_time)\n",
    "\n",
    "model = lstm.fit(model_name='stars_100neurons', folder='./models/stars')\n",
    "# model = lstm.fit(model_name='stars_100neurons', folder='./')\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(\"End time: \", end_time)\n",
    "\n",
    "time_taken = end_time - start_time\n",
    "print(\"Time taken: \", time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f033cc9f5c0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgEAAAHUCAYAAACj/ftgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XmYZHV97/H3Z0Y2YVxBUBgRw+IlGllGNBoXXAhEheSqEVAjRINGMQpKgsaLiBqNGjELMaJiTBTRaExGHUVjxC3gnUERZdMJwmVEhQFZo8Dg9/5Rp7Fse7rrTHdNdZ16v56nHvpUnf6db50eur79+Z36VaoKSZI0eZaMugBJkjQaNgGSJE0omwBJkiaUTYAkSRPKJkCSpAllEyBJ0oSyCZAkaULZBEiSNKFsAiRJmlB3G3UBkiSNiyTDWmb37Ko6eEhjb5RJgBa1JNsk+WSSG5P8yzzGeU6Szy1kbaOS5LFJLpvH9785ySsWsqZhSPKgJJXkbs32Z5I8f4GPcXKSDzZf75jkkiRbLeQxpAFtP4qD2gRoQSQ5MsmaJLck+WHzC/u3FmDoZwI7Avetqmdt6iBV9aGqOmgB6hmq5kVv99n2qaqvVNVemzj+DsAfAO/elO8fpao6pKo+MMTxfwx8EThmWMdQNyRZ8Nuo2ARo3pIcD7wT+At6L9gPBP4eOGwBht8V+G5VbViAscbe1F/F83AUsKqqfroA5fySBahtMfgQ8KJRFyFtLjYBmpck9wROAV5aVf9aVbdW1R1V9cmqOqHZZ6sk70xydXN751TkmuQJSdYleWWSa5oU4ejmsdcDJwHPbhKGF/THt80+0yPjo5JcnuTmJN9P8py++7/a932PTrK6mWZYneTRfY+dk+QNSb7WjPO5JDNGdX31/2lf/b+b5HeSfDfJ9Ule07f/AUnOTXJDs+/fJdmyeezLzW7fap7vs/vG/7MkPwLeP3Vf8z2/1hxjv2b7AUnWJ3nCRn5khwBfmqH+Xzn/Uz/fJP+U5NokVyZ5bZIlfef0a0lOTXI9cPK0+25ofhaPbu6/qjnG8/vGf2qSbya5qXn85I3UPfVzeWHz9dQ5mrrV1HNO8qgk/9Uc/1v95yLJbkm+1PxcP8+vRrBfBx6cZNeN1SHFJEC6y28CWwOfmGWfPwceBewDPBw4AHht3+M7AfcEdgZeAJyW5N5V9Tp66cJHqmq7qnrfbIUk2Rb4G+CQqloGPBq4YIb97gN8utn3vsA7gE8nuW/fbkcCRwP3A7YEXjXLoXeidw52pte0vAd4LrA/8FjgpCQPbva9EziO3ovPbwJPAl4CUFWPa/Z5ePN8P9I3/n3opSK/FFVX1X8DfwZ8KMndgfcD/1hV52yk1ocB068nmPH8N4/9bfPYg4HH05tKOLrvex8JXE7vPL2p774L6Z3bM4GzgEcAuzfn5e+SbNfse2sz5r2ApwJ/nOR3N1J7//OeOkfbAcc3z+kbSXam97N9I71z9irg4+lNg9DUcz698/8G4PnTxt0ArKX371SakU2A9Av3BdbPEdc/Bzilqq6pqmuB1wPP63v8jubxO6pqFXALsElz3sDPgYcm2aaqflhVF82wz1OB71XVP1fVhqr6MHAp8PS+fd5fVd9tYvOP0mtgNuYO4E1VdQe9F7ztgb+uqpub418E/AZAVZ1fVec1x72C3tz84wd4Tq+rqttmivGr6j3A9+j9FXt/ek3XxtwLuHmG+n/l/CdZCjwbeHXzXK4A/opf/tldXVV/2zyfqdq+X1Xvr6o7gY8Ay5vxb6uqzwG302sIqKpzqurbVfXzqroQ+PAA5+Mu6V138kbg0Kq6iV6TsaqqVjVjfh5YA/xOkgfSa0b+T1PLl4FPzjDszc15kjrPJkDzdR2wfWafD34AcGXf9pXNfXeNMa2J+B9gO1qqqlvpvWi9GPhhkk8necgA9UzVtHPf9o9a1HNd84IHMPVC+OO+x3869f1J9kzyqSQ/SnITvaRjrquCr62qn82xz3uAhwJ/W1W3zbLfT4BlM9Q/0/nfnl4KMv1n13+erprhGNOf+9RFd/33TZ2PRyb5YjPdcCO9n91AV0knWU6vQXt+VX23uXtX4FnNVMANSW4Afotec/QA4CfNv5P+5zPdMuCGQWrQZDIJkH7hXOBnwGwR7tX0fjlPeWBz36a4Fbh73/ZO/Q9W1dlV9RR6v/QvpffiOFc9UzX9YBNrauNd9Orao6ruAbwGmOs3wKzvS26i9XcC76M3L3+fWXa/ENhzwFrX00sJpv/s+s/TfN8zfSawElheVfcE/oG5zwdJtgH+DXhnVX2m76GrgH+uqnv13batqrcAPwTu3Uwb9T+f/nHvRi+l+Na8npU0JmwCNC9VdSO9efDT0rsg7u5JtkhySJK3Nrt9GHhtkh3Su8DuJOCDGxtzDhcAj0vywPQuSnz11APpvc/70OaX/G30Yu07ZxhjFbBnem9rvFuSZwN7A5/axJraWAbcBNzSpBR/PO3xH9Obf2/jr4Hzq+qF9ObD/2GWfVcxYNzepBsfBd6UZFlzsdzxbPrPbibLgOur6mdJDqB3LcYgzgAuraq3Trv/g8DTk/x2kqVJtk7v4sddqupKelMDr0+yZTOV8PRp338AcEWzr/QrhpECmARorFXVO+i9OLwWuJbeX2PH0vtLDXpztmvo/RX6beAbzX2bcqzP05tnvpDeBV79L9xLgFfS+0v/enovdi+ZYYzrgKc1+14H/CnwtKpavyk1tfQqei90N9NLKT4y7fGTgQ80UfbvzzVYksOAg+nF6ND7OeyX5l0RM/gnevPj2wxY78vopS+XA1+l95f7GQN+7yBeApyS5GZ6zeFHB/y+w4Hfyy+/Q+CxVXUVvbemvoZf/Fs8gV/8rjuS3oWL1wOvo3c++j2H2ZsoqVNSNawVECUtRkn+Arimqt456loWkyT3o/f2yX0HuAZDE2rJkiW1xRZbLPi4t99++/lVtWLBB56DTYAkSQNasmRJbbnllgs+7m233TaSJsDpAEmSJlQXlvmUJGmzGeWFfAvNJECSpAm1qJKADO9zmifCXntt6iJ7mrLtttvOvZM2qkt/IWn8XHHFFaxfv37o/wi79O98UTUBmp/3vve9oy5h7D3qUY8adQljbenSpaMuYax16cVlFFasGP51daN+X/9CczpAkqQJZRIgSVILJgGSJGnsmQRIktRCl5IAmwBJklroUhPgdIAkSRPKJECSpBZMAiRJ0tgzCZAkaUAuFiRJkjrBJECSpBa6lATYBEiS1EKXmgCnAyRJmlAmAZIktWASIEmSxp5JgCRJLXQpCbAJkCRpQK4TIEmSOsEkQJKkFkwCJEnS2DMJkCSphS4lATYBkiS10KUmwOkASZImlEmAJEktmARIkqSxZxIgSdKAXCxIkiRtdkkOTnJZkrVJTpzh8VOTXNDcvpvkhrnGNAmQJKmFUSQBSZYCpwFPAdYBq5OsrKqLp/apquP69n8ZsO9c45oESJLUwtSUwELeBnAAsLaqLq+q24GzgMNm2f8I4MNzDWoTIEnS6G2fZE3f7Zhpj+8MXNW3va6571ck2RXYDfjPuQ7qdIAkSS0MaTpgfVWtmO2wM9xXG9n3cOBjVXXnXAc1CZAkafFbByzv294FuHoj+x7OAFMBYBIgSVIrI3qL4GpgjyS7AT+g90J/5PSdkuwF3Bs4d5BBbQIkSRrQqNYJqKoNSY4FzgaWAmdU1UVJTgHWVNXKZtcjgLOqamNTBb/EJkCSpDFQVauAVdPuO2na9sltxhzaNQFJzkhyTZLvDOsYkiRtbiN6i+BQDPPCwH8EDh7i+JIkaR6GNh1QVV9O8qBhjS9J0ih06bMDvCZAkqQWbAIWULMq0vSVkSRJ0pCNvAmoqtOB0wGSDPSWBkmSRqVLSYArBkqSNKGG+RbBD9NbsWivJOuSvGBYx5IkaXMYxtsDR5ksDPPdAUcMa2xJkjR/I78mQJKkcdKlawJsAiRJaqFLTYAXBkqSNKFMAiRJasEkQJIkjT2TAEmSWuhSEmATIEnSgEb9vv6F5nSAJEkTyiRAkqQWTAIkSdLYMwmQJKmFLiUBNgGSJLXQpSbA6QBJkiaUSYAkSS2YBEiSpLFnEiBJ0oBcLEiSJHWCSYAkSS10KQmwCZAkqYUuNQFOB0iSNKFMAiRJasEkQJIkjT2TAEmSWuhSEmATIEnSgFwnQJIkdYJJgCRJLZgESJKksWcSIElSC11KAmwCJElqoUtNgNMBkiRNKJMASZJaMAmQJEljzyRAkqQBuViQJEnqhEWVBOy+++6ceuqpoy5jbJ100kmjLmHsvf3tbx91CWPtYQ972KhLGGtbbLHFqEvQALqUBCyqJkCSpMWuS02A0wGSJE0okwBJklowCZAkSZtVkoOTXJZkbZITN7LP7ye5OMlFSc6ca0yTAEmSWhhFEpBkKXAa8BRgHbA6ycqqurhvnz2AVwOPqaqfJLnfXOPaBEiSNKARrhNwALC2qi5v6jgLOAy4uG+fPwJOq6qfAFTVNXMN6nSAJEmjt32SNX23Y6Y9vjNwVd/2uua+fnsCeyb5WpLzkhw810FNAiRJamFIScD6qlox22FnuK+mbd8N2AN4ArAL8JUkD62qGzY2qEmAJEmL3zpged/2LsDVM+zz71V1R1V9H7iMXlOwUTYBkiS1MHVdwELeBrAa2CPJbkm2BA4HVk7b59+AA5sat6c3PXD5bIM6HSBJUgujuDCwqjYkORY4G1gKnFFVFyU5BVhTVSubxw5KcjFwJ3BCVV0327g2AZIkjYGqWgWsmnbfSX1fF3B8cxuITYAkSS24YqAkSRp7JgGSJA1ohIsFDYVJgCRJE8okQJKkFrqUBNgESJLUQpeaAKcDJEmaUCYBkiS1YBIgSZLGnkmAJEktdCkJsAmQJGlArhMgSZI6wSRAkqQWTAIkSdLYMwmQJKmFLiUBNgGSJLXQpSbA6QBJkiaUSYAkSS2YBEiSpLFnEiBJ0oBcLEiSJHWCSYAkSS10KQmwCZAkqYUuNQFOB0iSNKFMAiRJasEkYABJlif5YpJLklyU5OXDOpYkSWpvmEnABuCVVfWNJMuA85N8vqouHuIxJUkaqi4lAUNrAqrqh8APm69vTnIJsDNgEyBJGkuuE7AJkjwI2Bf4+gyPHZNkTZI1N9544+YoR5IksRkuDEyyHfBx4BVVddP0x6vqdOB0gD322KOGXY8kSfNhEjCgJFvQawA+VFX/OsxjSZKkdoaWBKTXKr0PuKSq3jGs40iStDl1KQkY5nTAY4DnAd9OckFz32uqatUQjylJ0lDZBAygqr4KdOdMSZLUMa4YKEnSgHyLoCRJ6gSTAEmSWuhSEmATIElSC11qApwOkCRpQpkESJLUgkmAJEkaeyYBkiS1YBIgSZLGnkmAJEkD6tpiQTYBkiS10KUmwOkASZImlE2AJEktTE0JLORtwOMenOSyJGuTnDjD40cluTbJBc3thXON6XSAJEmLXJKlwGnAU4B1wOokK6vq4mm7fqSqjh10XJsASZJaGNE1AQcAa6vq8qaGs4DDgOlNQCtOB0iS1MKIpgN2Bq7q217X3DfdM5JcmORjSZbPNahNgCRJo7d9kjV9t2OmPT5Tp1DTtj8JPKiqfgP4D+ADcx3U6QBJkgY0xHUC1lfVilkeXwf0/2W/C3B1/w5VdV3f5nuAv5zroCYBkiQtfquBPZLslmRL4HBgZf8OSe7ft3kocMlcg5oESJLUwiguDKyqDUmOBc4GlgJnVNVFSU4B1lTVSuBPkhwKbACuB46aa1ybAEmSWhjVioFVtQpYNe2+k/q+fjXw6jZjOh0gSdKEMgmQJKkFPztAkiSNPZMASZJaMAmQJEljzyRAkqQBDXGxoJGwCZAkqYUuNQFOB0iSNKFMAiRJasEkQJIkjT2TAEmSWuhSEmATIElSC11qApwOkCRpQi2qJGDZsmU86UlPGnUZY2urrbYadQlj7+STTx51CWPtxBNPHHUJY+0Rj3jEqEsYa1U19GN0bZ0AkwBJkibUokoCJEla7LqUBNgESJLUQpeaAKcDJEmaUCYBkiS1YBIgSZLGnkmAJEktmARIkqSxZxIgSdKAurZYkE2AJEktdKkJcDpAkqQJZRIgSVILJgGSJGnsmQRIktRCl5IAmwBJklroUhPgdIAkSRPKJECSpAF1bZ0AkwBJkiaUSYAkSS10KQmwCZAkqYUuNQFOB0iSNKFMAiRJasEkQJIkjT2TAEmSWjAJkCRJY88kQJKkAXVtsSCbAEmSWpiIJiDJJ4Ha2ONVdehQKpIkSZvFbEnA2zdbFZIkjYmJSAKq6kubsxBJkrR5zXlNQJI9gDcDewNbT91fVQ8eYl2SJC1KE5EE9Hk/8DrgVOBA4GigO2dAkqQWutQEDLJOwDZV9QUgVXVlVZ0MPHG4ZUmSpGEbpAn4WZIlwPeSHJvk94D7DbkuSZIWnal1Ahb6NuCxD05yWZK1SU6cZb9nJqkkK+Yac5Am4BXA3YE/AfYHngc8f6CKJUnSvCVZCpwGHELvGr0jkuw9w37L6L1ef32Qcee8JqCqVjdf3kLvegBJkibWiK4JOABYW1WXNzWcBRwGXDxtvzcAbwVeNcigg7w74IvMsGhQVc16XUCSrYEvA1s1x/lYVb1ukKIkSVqshtQEbJ9kTd/26VV1et/2zsBVfdvrgEdOq2tfYHlVfSrJwjQB/HI3sTXwDGDDAN93G/DEqrolyRbAV5N8pqrOG6QwSZImyPqqmm0Of6bO464/0Jtr904Fjmpz0EGmA86fdtfXksy5kFBVFb0pBIAtmttGlyGWJGkcjGg6YB2wvG97F+Dqvu1lwEOBc5r6dgJWJjm0qvoThl8yyHTAffo2l9C7OHCnQSpuLmQ4H9gdOK2qfuVChSTHAMcALF++fPrDkiQJVgN7JNkN+AFwOHDk1INVdSOw/dR2knOAV83WAMBg0wHn0/sLPvSmAb4PvGCQiqvqTmCfJPcCPpHkoVX1nWn7nA6cDrDffvuZFEiSFrVRJAFVtSHJscDZwFLgjKq6KMkpwJqqWrkp4w7SBPyvqvpZ/x1JtmpzkKq6oelKDga+M8fukiRpmqpaBayadt9JG9n3CYOMOcg6Af81w33nzvVNSXZoEgCSbAM8Gbh0kKIkSVqMRrlY0DBsNAlIshO9tyRs07ztYKrKe9BbPGgu9wc+0FwXsAT4aFV9ap71SpI0Ul367IDZpgN+m95bDXYB/opfNAE3Aa+Za+CquhDYd571SZKkIdloE1BVH6D3l/wzqurjm7EmSZIWrS4lAYNcE7D/1Nw+QJJ7J3njEGuSJEmbwSBNwCFVdcPURlX9BPid4ZUkSdLiNREXBvZZmmSrqroN7rrSv9VbBCVJ6oouTQcM0gR8EPhCkvc320cDHxheSZIkaXMY5LMD3prkQnrv8w/wWWDXYRcmSdJiM+r4fqENck0AwI+An9P7BMEnAZcMrSJJkrRZzLZY0J70PqDgCOA64CNAqurAzVSbJEmLTpeSgNmmAy4FvgI8varWAiQ5brNUJUnSItWlJmC26YBn0JsG+GKS9yR5Er9YNVCSJI25jTYBVfWJqno28BDgHOA4YMck70py0GaqT5KkRaVL6wTMeWFgVd1aVR+qqqfR+xyBC4ATh16ZJEkaqkHWCbhLVV0PvLu5SZI0cSblmgBJktRhrZIASZIm2ajn8BeaTYAkSS10qQlwOkCSpAllEiBJUgsmAZIkaeyZBEiS1EKXkgCbAEmSWuhSE+B0gCRJE8okQJKkAXVtnQCTAEmSJpRJgCRJLXQpCbAJkCSphS41AU4HSJI0oUwCJElqwSRAkiSNPZMASZJaMAmQJEljzyRAkqQBdW2xIJsASZJa6FIT4HSAJEkTalElAUuWLGHrrbcedRlj64lPfOKoSxh7O+6446hLGGsve9nLRl3CWDvhhBNGXcJYu+mmmzbLcUwCJEnS2FtUSYAkSYtdl5IAmwBJklroUhPgdIAkSRPKJECSpAF1bZ0AkwBJkiaUSYAkSS10KQmwCZAkqYUuNQFOB0iSNKFsAiRJamHq4sCFvA143IOTXJZkbZITZ3j8xUm+neSCJF9NsvdcY9oESJK0yCVZCpwGHALsDRwxw4v8mVX1sKraB3gr8I65xvWaAEmSWhjRNQEHAGur6vKmhrOAw4CLp3aoqv4PT9gWqLkGtQmQJGn0tk+ypm/79Ko6vW97Z+Cqvu11wCOnD5LkpcDxwJbAnJ8qZxMgSdKAhrhY0PqqWjHboWe471f+0q+q04DTkhwJvBZ4/mwHtQmQJKmFEU0HrAOW923vAlw9y/5nAe+aa1AvDJQkafFbDeyRZLckWwKHAyv7d0iyR9/mU4HvzTWoSYAkSS2MIgmoqg1JjgXOBpYCZ1TVRUlOAdZU1Urg2CRPBu4AfsIcUwFgEyBJ0lioqlXAqmn3ndT39cvbjmkTIElSC11aNtgmQJKkAflRwpIkqRNMAiRJasEkQJIkjT2TAEmSWuhSEmATIElSC11qApwOkCRpQpkESJLUgkmAJEkaeyYBkiQNqGuLBdkESJLUQpeaAKcDJEmaUCYBkiS1YBIgSZLGnkmAJEktmARIkqSxZxIgSVILXUoCht4EJFkKrAF+UFVPG/bxJEkalq6tE7A5pgNeDlyyGY4jSZJaGGoTkGQX4KnAe4d5HEmSNpepNGAhb6My7CTgncCfAj8f8nEkSVJLQ2sCkjwNuKaqzp9jv2OSrEmy5tprrx1WOZIkLQiTgME8Bjg0yRXAWcATk3xw+k5VdXpVraiqFTvssMMQy5Ekaf5sAgZQVa+uql2q6kHA4cB/VtVzh3U8SZLUjusESJLUQpfeIrhZmoCqOgc4Z3McS5IkDcYkQJKkAY16Dn+h2QRIktRCl5oAP0BIkqQJZRIgSVILJgGSJGnsmQRIktSCSYAkSRp7JgGSJLXQpSTAJkCSpAF1bZ0ApwMkSZpQJgGSJLVgEiBJksaeSYAkSS10KQmwCZAkqYUuNQFOB0iSNKFMAiRJasEkQJIkjT2TAEmSBtS1xYJsAiRJaqFLTYDTAZIkjYEkBye5LMnaJCfO8PjxSS5OcmGSLyTZda4xbQIkSWphakpgIW8DHHMpcBpwCLA3cESSvaft9k1gRVX9BvAx4K1zjWsTIEnS4ncAsLaqLq+q24GzgMP6d6iqL1bV/zSb5wG7zDWo1wRIktTCiK4J2Bm4qm97HfDIWfZ/AfCZuQa1CZAkafS2T7Kmb/v0qjq9b3umzqNmGijJc4EVwOPnOqhNgCRJLQwpCVhfVStmeXwdsLxvexfg6uk7JXky8OfA46vqtrkOahMgSdKARrhOwGpgjyS7AT8ADgeOnFbbvsC7gYOr6ppBBvXCQEmSFrmq2gAcC5wNXAJ8tKouSnJKkkOb3d4GbAf8S5ILkqyca1yTAEmSWhjVYkFVtQpYNe2+k/q+fnLbMU0CJEmaUCYBkiS10KVlg20CJElqoUtNgNMBkiRNKJMASZJaMAmQJEljzySgQ5YuXTrqEsbe3ntP/1AutXHccceNuoSxdvTRR4+6hLF2ww03DP0YI1wsaChsAiRJaqFLTYDTAZIkTSiTAEmSWjAJkCRJY88kQJKkFkwCJEnS2DMJkCSphS4lATYBkiQNqGvrBDgdIEnShDIJkCSpBZMASZI09kwCJElqoUtJgE2AJEktdKkJcDpAkqQJZRIgSVILJgGSJGnsmQRIkjSgri0WZBMgSVILXWoCnA6QJGlCmQRIktSCSYAkSRp7JgGSJLVgEiBJksaeSYAkSS10KQmwCZAkaUBdWyfA6QBJkiaUSYAkSS2YBEiSpLFnEiBJUgtdSgJsAiRJaqFLTYDTAZIkTSiTAEmSWjAJkCRJY88kQJKkAXVtsSCbAEmSWuhSE+B0gCRJE8okQJKkFrqUBAy1CUhyBXAzcCewoapWDPN4kiRpcJsjCTiwqtZvhuNIkjR0XUoCvCZAkqQJNewmoIDPJTk/yTEz7ZDkmCRrkqy59tprh1yOJEnzM/U2wYW8DXjcg5NclmRtkhNnePxxSb6RZEOSZw4y5rCbgMdU1X7AIcBLkzxu+g5VdXpVraiqFTvssMOQy5EkadMNowEYpAlIshQ4jd7r6d7AEUn2nrbb/wOOAs4c9PkMtQmoqqub/14DfAI4YJjHkySpow4A1lbV5VV1O3AWcFj/DlV1RVVdCPx80EGH1gQk2TbJsqmvgYOA7wzreJIkbQ5DSgK2n5oab27Tp9B3Bq7q217X3Dcvw3x3wI7AJ5ondzfgzKr67BCPJ0nSuFo/x9voZ5ozqPkedGhNQFVdDjx8WONLkjQKI3qL4Dpged/2LsDV8x3UFQMlSWphRE3AamCPJLsBPwAOB46c76CuEyBJ0iJXVRuAY4GzgUuAj1bVRUlOSXIoQJJHJFkHPAt4d5KL5hrXJECSpBZGtWJgVa0CVk2776S+r1fTmyYYmEmAJEkTyiRAkqQBtVnhbxzYBEiS1EKXmgCnAyRJmlAmAZIktWASIEmSxp5JgCRJLZgESJKksWcSIElSC11KAmwCJEkaUNfWCXA6QJKkCWUSIElSCyYBkiRp7JkESJLUQpeSAJsASZJa6FIT4HSAJEkTyiRAkqQWTAIkSdLYMwmQJGlAXVssyCZAkqQWutQEOB0gSdKEMgmQJKkFkwBJkjT2TAIkSWqhS0mATYAkSQPq2rsDnA6QJGlCmQRIktSCSYAkSRp7JgGSJLVgEiBJksaeSYAkSS10KQlYVE3A+eefv37JkiVXjrqOWWwPrB91EWPM8zc/nr/58xzOz2I/f7tujoPYBAxJVe0w6hpmk2RNVa0YdR3jyvM3P56/+fMczo/nr3sWVRMgSdJi5mJBkiSpE0wC2jl91AWMOc/f/Hj+5s9zOD+eP7p1TUCqatQ1SJI0Fvbff/8699xzF3zcrbba6vxRXG/hdIAkSRPK6QBJklro0nSASYCkTkmXfkNLQ2YT0CfJ0lHXMK6S7J5kRZKtRl3LOEry60ken+S+o65lHCX5rSTPA6iqshFoL8nTk7x81HWMg6m3CS7kbVScDgCS7FlV362qO5Msrao7R13TOEnyNOAvgOuAHyV5XVV9d8RljY0khwB/CVwObJFgyO/aAAAFX0lEQVTkBVX1oxGXNRaSLAHuDry7t5ltq+ofmkZgSVX9fMQljoUkBwFvAE4YdS2L3ahftBfaxCcBzQvYBUnOBJhqBEZc1thI8mjg7cDzq+pA4CfAiaOtanwkeQLw18ALq+p3gduBh460qDFSVT+vqluADwDvAx6d5Lipx0Za3Jho/h/+Z+CYqvp8knsm2TXJ3Uddm4ZvopuAJNsCxwKvAG5P8kGwEdgEb6mqbzZfvw64j9MCA/sx8KKq+r9JdgIeCRyb5N1JnmmsPbANwHJ6zcABSd6R5M3pmejfcwO4DrgDuH8zHfVvwLuAf/Tf4My6NB0w0f9zVNWtwB8CZwKvArbubwRGWdsY+Trwr3DXNRVb0fsQj3s09znHPYuquqSqvthsvgD4+yYROA94Fr0PbNHc/h34UVV9AVgDvBi4R/WYCMyiqi4DngqcCnyL3u/DpwGfBZ4B3Ht01WnYJroJAKiqq6vqlqpaD7wI2GaqEUiyX5KHjLbCxa2q7qyqm5rNADcA11fVtUmeA7wxyTajq3B8VNWbquqNzdfvB5bR++tWc/spsFeSP6LXALwFeGCSF422rPFQVd+i98L/5qp6TzPNcga9BuCBo61u8elSEuCFgX2q6rrml8bbklwKLAUOHHFZY6OqNgC3JLkqyZuBg4CjquqnIy5t0UuS6lu+M8kzgB2Bq0dX1fioqquTXAX8H+ClVfXJJAcCa0dc2tioqouBi6e2m3+DOwA/HFlRGjqbgGmqan2SC4FDgKdU1bpR1zQumrnDLYDHNv99UlV9b7RVjYepBqC5luK5wPHAs32XQCvvAf69qs5vtr/kVEB7zf/HR9ObIn1WVf14xCUtOl26TMLPDpgmyb2BjwKvrKoLR13POEpyFLC6qi4adS3jJskWwFOA/27matXS9FRF7TRNwOPpXWNx6ajrWWySfJbhXKuzvqoOHsK4s7IJmEGSravqZ6OuY1z5S1iSxoNNgCRJE2ri3x0gSdKksgmQJGlC2QRIkjShbAIkSZpQNgHSAktyZ5ILknwnyb/M54NYkjwhyaearw9NstEPZ0pyryQv2YRjnJzkVZtao6TxZRMgLbyfVtU+VfVQep8K+OL+Bzf1Q22qamVVvWWWXe4FtG4CJE0umwBpuL4C7J7kQUkuSfL3wDeA5UkOSnJukm80icF2AEkOTnJpkq8C/3tqoCRHJfm75usdk3wiybea26PprZf/a00K8bZmvxOSrE5yYZLX943150kuS/IfwF6b7WxIWlRsAqQhSXI3estPf7u5ay/gn6pqX+BW4LXAk6tqP3qffHd8kq3pLX/7dHrLL++0keH/ht6yuA8H9gMuAk6kt9LgPlV1QpKDgD2AA4B9gP2TPC7J/sDhwL70moxHLPBTlzQm/OwAaeFtk+SC5uuvAO8DHgBcWVXnNfc/Ctgb+FqzDvmWwLnAQ4DvT33mQvOJlsfMcIwnAn8Ad33s9Y3Nktf9Dmpu32y2t6PXFCwDPlFV/9McY+W8nq2ksWUTIC28n1bVPv13NC/0t/bfBXy+qo6Ytt8+wEIt4xl6Hw377mnHeMUCHkPSGHM6QBqN84DHJNkdIMndk+wJXArsluTXmv2O2Mj3fwH44+Z7lya5B3Azvb/yp5wN/GHftQY7J7kf8GXg95Jsk2QZvakHSRPIJkAagaq6FjgK+HDz0dXnAQ9pPrjqGODTzYWBV25kiJcDByb5NnA+8OtVdR296YXvJHlbVX0OOBM4t9nvY8CyqvoG8BHgAuDj9KYsJE0gP0BIkqQJZRIgSdKEsgmQJGlC2QRIkjShbAIkSZpQNgGSJE0omwBJkiaUTYAkSRPq/wPXD+jM1KuPwQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f036ba4aeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lstm.confusion_matrix.plot(normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fscore</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.759183</td>\n",
       "      <td>0.735031</td>\n",
       "      <td>0.784976</td>\n",
       "      <td>61914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.582589</td>\n",
       "      <td>0.582908</td>\n",
       "      <td>0.582270</td>\n",
       "      <td>62143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.580067</td>\n",
       "      <td>0.615852</td>\n",
       "      <td>0.548213</td>\n",
       "      <td>61923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.578245</td>\n",
       "      <td>0.563456</td>\n",
       "      <td>0.593830</td>\n",
       "      <td>62144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.727152</td>\n",
       "      <td>0.731223</td>\n",
       "      <td>0.723126</td>\n",
       "      <td>62133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fscore  precision    recall  support\n",
       "0  0.759183   0.735031  0.784976    61914\n",
       "1  0.582589   0.582908  0.582270    62143\n",
       "2  0.580067   0.615852  0.548213    61923\n",
       "3  0.578245   0.563456  0.593830    62144\n",
       "4  0.727152   0.731223  0.723126    62133"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.prfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.make_prediction('i will never go there again, food was awful')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.make_prediction('most wonderful place i have ever been, food is amazing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.make_prediction('food is amazing and service is good')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.make_prediction('well, i am not sure, food was ok, but service was good')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.make_prediction('well, i am not sure, food was ok, but service was awful')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

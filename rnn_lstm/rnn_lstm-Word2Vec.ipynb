{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, json, time, unittest, datetime, shutil\n",
    "import itertools, collections\n",
    "import random\n",
    "from importlib import reload\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The data below is only on the 10k datasets for now. This will be updated to leverage the full datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pd.read_json(\"../dataset/user_10k.json\", lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_stars</th>\n",
       "      <th>compliment_cool</th>\n",
       "      <th>compliment_cute</th>\n",
       "      <th>compliment_funny</th>\n",
       "      <th>compliment_hot</th>\n",
       "      <th>compliment_list</th>\n",
       "      <th>compliment_more</th>\n",
       "      <th>compliment_note</th>\n",
       "      <th>compliment_photos</th>\n",
       "      <th>compliment_plain</th>\n",
       "      <th>...</th>\n",
       "      <th>cool</th>\n",
       "      <th>elite</th>\n",
       "      <th>fans</th>\n",
       "      <th>friends</th>\n",
       "      <th>funny</th>\n",
       "      <th>name</th>\n",
       "      <th>review_count</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>yelping_since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[cvVMmlU1ouS3I5fhutaryQ, nj6UZ8tdGo8YJ9lUMTVWN...</td>\n",
       "      <td>0</td>\n",
       "      <td>Johnny</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>oMy_rEb0UBEmMlu-zcxnoQ</td>\n",
       "      <td>2014-11-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0njfJmB-7n84DlIgUByCNw, rFn3Xe3RqHxRSxWOU19Gp...</td>\n",
       "      <td>0</td>\n",
       "      <td>Chris</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>JJ-aSuM4pCFPdkfoZ34q0Q</td>\n",
       "      <td>2013-09-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>Tiffy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>uUzsFQn_6cXDh6rPNGbIFA</td>\n",
       "      <td>2017-03-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>Mark</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>mBneaEEH5EMyxaVyqS-72A</td>\n",
       "      <td>2015-03-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>Evelyn</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>W5mJGs-dcDWRGEhAzUYtoA</td>\n",
       "      <td>2016-09-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   average_stars  compliment_cool  compliment_cute  compliment_funny  \\\n",
       "0           4.67                0                0                 0   \n",
       "1           3.70                0                0                 0   \n",
       "2           2.00                0                0                 0   \n",
       "3           4.67                0                0                 0   \n",
       "4           4.67                0                0                 0   \n",
       "\n",
       "   compliment_hot  compliment_list  compliment_more  compliment_note  \\\n",
       "0               0                0                0                0   \n",
       "1               0                0                0                0   \n",
       "2               0                0                0                0   \n",
       "3               0                0                0                0   \n",
       "4               0                0                0                0   \n",
       "\n",
       "   compliment_photos  compliment_plain      ...        cool  elite  fans  \\\n",
       "0                  0                 1      ...           0     []     0   \n",
       "1                  0                 0      ...           0     []     0   \n",
       "2                  0                 0      ...           0     []     0   \n",
       "3                  0                 0      ...           0     []     0   \n",
       "4                  0                 0      ...           0     []     0   \n",
       "\n",
       "                                             friends  funny    name  \\\n",
       "0  [cvVMmlU1ouS3I5fhutaryQ, nj6UZ8tdGo8YJ9lUMTVWN...      0  Johnny   \n",
       "1  [0njfJmB-7n84DlIgUByCNw, rFn3Xe3RqHxRSxWOU19Gp...      0   Chris   \n",
       "2                                                 []      0   Tiffy   \n",
       "3                                                 []      0    Mark   \n",
       "4                                                 []      0  Evelyn   \n",
       "\n",
       "   review_count useful                 user_id  yelping_since  \n",
       "0             8      0  oMy_rEb0UBEmMlu-zcxnoQ     2014-11-03  \n",
       "1            10      0  JJ-aSuM4pCFPdkfoZ34q0Q     2013-09-24  \n",
       "2             1      0  uUzsFQn_6cXDh6rPNGbIFA     2017-03-02  \n",
       "3             6      0  mBneaEEH5EMyxaVyqS-72A     2015-03-13  \n",
       "4             3      0  W5mJGs-dcDWRGEhAzUYtoA     2016-09-08  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All types of reviews - 10K dataset\n",
    "# reviews_df = pd.read_json(\"../dataset/review_10k.json\", lines=True)\n",
    "\n",
    "# Just restaurant reviews - 10K dataset\n",
    "reviews_df = pd.read_json(\"../dataset/restaurant_reviews_10k.json\", lines=True)\n",
    "\n",
    "# All types of reviews\n",
    "# reviews_df = pd.read_json(\"../../../final_project/full_dataset/review.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>This is one of my top 3 places to get BBQ pork...</td>\n",
       "      <td>2</td>\n",
       "      <td>FEg8v92qx3kK4Hu4TF28Fg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>This restaurant is famous for their BBQ dishes...</td>\n",
       "      <td>0</td>\n",
       "      <td>HPtjvIrhzAUkKsiVkeT4MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-10-23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Roasted pork is one of my favorite things... A...</td>\n",
       "      <td>1</td>\n",
       "      <td>MpvqV7lQcl15rflTBEUhXA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-07-30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>I walked by the restaurant more than 5 years a...</td>\n",
       "      <td>1</td>\n",
       "      <td>x-Gbs8sVid3yhJIoHD6Gfw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-02-07</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>I came here to order a roast duck over rice to...</td>\n",
       "      <td>0</td>\n",
       "      <td>7Dykd1HolQx8mKPYhYDYSg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool       date  funny  stars  \\\n",
       "0  --6MefnULPED_I942VcFNA     0 2017-08-17      0      4   \n",
       "1  --6MefnULPED_I942VcFNA     0 2017-05-31      0      3   \n",
       "2  --6MefnULPED_I942VcFNA     0 2016-10-23      0      2   \n",
       "3  --6MefnULPED_I942VcFNA     0 2017-07-30      0      2   \n",
       "4  --6MefnULPED_I942VcFNA     0 2017-02-07      1      2   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  This is one of my top 3 places to get BBQ pork...       2   \n",
       "1  This restaurant is famous for their BBQ dishes...       0   \n",
       "2  Roasted pork is one of my favorite things... A...       1   \n",
       "3  I walked by the restaurant more than 5 years a...       1   \n",
       "4  I came here to order a roast duck over rice to...       0   \n",
       "\n",
       "                  user_id  \n",
       "0  FEg8v92qx3kK4Hu4TF28Fg  \n",
       "1  HPtjvIrhzAUkKsiVkeT4MA  \n",
       "2  MpvqV7lQcl15rflTBEUhXA  \n",
       "3  x-Gbs8sVid3yhJIoHD6Gfw  \n",
       "4  7Dykd1HolQx8mKPYhYDYSg  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cool</th>\n",
       "      <th>funny</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.535000</td>\n",
       "      <td>0.458000</td>\n",
       "      <td>3.76540</td>\n",
       "      <td>1.037900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.866849</td>\n",
       "      <td>1.656958</td>\n",
       "      <td>1.31937</td>\n",
       "      <td>2.324307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cool         funny        stars        useful\n",
       "count  10000.000000  10000.000000  10000.00000  10000.000000\n",
       "mean       0.535000      0.458000      3.76540      1.037900\n",
       "std        1.866849      1.656958      1.31937      2.324307\n",
       "min        0.000000      0.000000      1.00000      0.000000\n",
       "25%        0.000000      0.000000      3.00000      0.000000\n",
       "50%        0.000000      0.000000      4.00000      0.000000\n",
       "75%        0.000000      0.000000      5.00000      1.000000\n",
       "max       68.000000     52.000000      5.00000     72.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df = pd.read_json(\"../dataset/business_10k.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>attributes</th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>hours</th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4855 E Warner Rd, Ste B9</td>\n",
       "      <td>{'AcceptsInsurance': True, 'ByAppointmentOnly'...</td>\n",
       "      <td>FYWN1wneV18bWNgQjJ2GNg</td>\n",
       "      <td>[Dentists, General Dentistry, Health &amp; Medical...</td>\n",
       "      <td>Ahwatukee</td>\n",
       "      <td>{'Friday': '7:30-17:00', 'Tuesday': '7:30-17:0...</td>\n",
       "      <td>1</td>\n",
       "      <td>33.330690</td>\n",
       "      <td>-111.978599</td>\n",
       "      <td>Dental by Design</td>\n",
       "      <td></td>\n",
       "      <td>85044</td>\n",
       "      <td>22</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3101 Washington Rd</td>\n",
       "      <td>{'BusinessParking': {'garage': False, 'street'...</td>\n",
       "      <td>He-G7vWjzVUysIKrfNbPUQ</td>\n",
       "      <td>[Hair Stylists, Hair Salons, Men's Hair Salons...</td>\n",
       "      <td>McMurray</td>\n",
       "      <td>{'Monday': '9:00-20:00', 'Tuesday': '9:00-20:0...</td>\n",
       "      <td>1</td>\n",
       "      <td>40.291685</td>\n",
       "      <td>-80.104900</td>\n",
       "      <td>Stephen Szabo Salon</td>\n",
       "      <td></td>\n",
       "      <td>15317</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6025 N 27th Ave, Ste 1</td>\n",
       "      <td>{}</td>\n",
       "      <td>KQPW8lFf1y5BT2MxiSZ3QA</td>\n",
       "      <td>[Departments of Motor Vehicles, Public Service...</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>33.524903</td>\n",
       "      <td>-112.115310</td>\n",
       "      <td>Western Motor Vehicle</td>\n",
       "      <td></td>\n",
       "      <td>85017</td>\n",
       "      <td>18</td>\n",
       "      <td>1.5</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000 Arizona Mills Cr, Ste 435</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': True, 'Restaura...</td>\n",
       "      <td>8DShNS-LuFqpEWIp0HxijA</td>\n",
       "      <td>[Sporting Goods, Shopping]</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>{'Monday': '10:00-21:00', 'Tuesday': '10:00-21...</td>\n",
       "      <td>0</td>\n",
       "      <td>33.383147</td>\n",
       "      <td>-111.964725</td>\n",
       "      <td>Sports Authority</td>\n",
       "      <td></td>\n",
       "      <td>85282</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>581 Howe Ave</td>\n",
       "      <td>{'Alcohol': 'full_bar', 'HasTV': True, 'NoiseL...</td>\n",
       "      <td>PfOCPjBrlQAnz__NXj9h_w</td>\n",
       "      <td>[American (New), Nightlife, Bars, Sandwiches, ...</td>\n",
       "      <td>Cuyahoga Falls</td>\n",
       "      <td>{'Monday': '11:00-1:00', 'Tuesday': '11:00-1:0...</td>\n",
       "      <td>1</td>\n",
       "      <td>41.119535</td>\n",
       "      <td>-81.475690</td>\n",
       "      <td>Brick House Tavern + Tap</td>\n",
       "      <td></td>\n",
       "      <td>44221</td>\n",
       "      <td>116</td>\n",
       "      <td>3.5</td>\n",
       "      <td>OH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          address  \\\n",
       "0        4855 E Warner Rd, Ste B9   \n",
       "1              3101 Washington Rd   \n",
       "2          6025 N 27th Ave, Ste 1   \n",
       "3  5000 Arizona Mills Cr, Ste 435   \n",
       "4                    581 Howe Ave   \n",
       "\n",
       "                                          attributes             business_id  \\\n",
       "0  {'AcceptsInsurance': True, 'ByAppointmentOnly'...  FYWN1wneV18bWNgQjJ2GNg   \n",
       "1  {'BusinessParking': {'garage': False, 'street'...  He-G7vWjzVUysIKrfNbPUQ   \n",
       "2                                                 {}  KQPW8lFf1y5BT2MxiSZ3QA   \n",
       "3  {'BusinessAcceptsCreditCards': True, 'Restaura...  8DShNS-LuFqpEWIp0HxijA   \n",
       "4  {'Alcohol': 'full_bar', 'HasTV': True, 'NoiseL...  PfOCPjBrlQAnz__NXj9h_w   \n",
       "\n",
       "                                          categories            city  \\\n",
       "0  [Dentists, General Dentistry, Health & Medical...       Ahwatukee   \n",
       "1  [Hair Stylists, Hair Salons, Men's Hair Salons...        McMurray   \n",
       "2  [Departments of Motor Vehicles, Public Service...         Phoenix   \n",
       "3                         [Sporting Goods, Shopping]           Tempe   \n",
       "4  [American (New), Nightlife, Bars, Sandwiches, ...  Cuyahoga Falls   \n",
       "\n",
       "                                               hours  is_open   latitude  \\\n",
       "0  {'Friday': '7:30-17:00', 'Tuesday': '7:30-17:0...        1  33.330690   \n",
       "1  {'Monday': '9:00-20:00', 'Tuesday': '9:00-20:0...        1  40.291685   \n",
       "2                                                 {}        1  33.524903   \n",
       "3  {'Monday': '10:00-21:00', 'Tuesday': '10:00-21...        0  33.383147   \n",
       "4  {'Monday': '11:00-1:00', 'Tuesday': '11:00-1:0...        1  41.119535   \n",
       "\n",
       "    longitude                      name neighborhood postal_code  \\\n",
       "0 -111.978599          Dental by Design                    85044   \n",
       "1  -80.104900       Stephen Szabo Salon                    15317   \n",
       "2 -112.115310     Western Motor Vehicle                    85017   \n",
       "3 -111.964725          Sports Authority                    85282   \n",
       "4  -81.475690  Brick House Tavern + Tap                    44221   \n",
       "\n",
       "   review_count  stars state  \n",
       "0            22    4.0    AZ  \n",
       "1            11    3.0    PA  \n",
       "2            18    1.5    AZ  \n",
       "3             9    3.0    AZ  \n",
       "4           116    3.5    OH  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df = pd.read_json(\"../dataset/checkin_10k.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7KPBkxAOEtb3QeIL9PEErg</td>\n",
       "      <td>{'Thursday': {'21:00': 4, '1:00': 1, '4:00': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kREVIrSBbtqBhIYkTccQUg</td>\n",
       "      <td>{'Monday': {'13:00': 1}, 'Thursday': {'20:00':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tJRDll5yqpZwehenzE2cSg</td>\n",
       "      <td>{'Monday': {'12:00': 1, '1:00': 1}, 'Friday': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r1p7RAMzCV_6NPF0dNoR3g</td>\n",
       "      <td>{'Thursday': {'23:00': 1}, 'Saturday': {'21:00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mDdqgfrvROGAumcQdZ3HIg</td>\n",
       "      <td>{'Monday': {'12:00': 1, '21:00': 1}, 'Wednesda...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                                               time\n",
       "0  7KPBkxAOEtb3QeIL9PEErg  {'Thursday': {'21:00': 4, '1:00': 1, '4:00': 1...\n",
       "1  kREVIrSBbtqBhIYkTccQUg  {'Monday': {'13:00': 1}, 'Thursday': {'20:00':...\n",
       "2  tJRDll5yqpZwehenzE2cSg  {'Monday': {'12:00': 1, '1:00': 1}, 'Friday': ...\n",
       "3  r1p7RAMzCV_6NPF0dNoR3g  {'Thursday': {'23:00': 1}, 'Saturday': {'21:00...\n",
       "4  mDdqgfrvROGAumcQdZ3HIg  {'Monday': {'12:00': 1, '21:00': 1}, 'Wednesda..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos_df = pd.read_json(\"../dataset/photos_10k.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>caption</th>\n",
       "      <th>label</th>\n",
       "      <th>photo_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OnAzbTDn79W6CFZIriqLrA</td>\n",
       "      <td></td>\n",
       "      <td>inside</td>\n",
       "      <td>soK1szeyan202jnsGhUDmA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OnAzbTDn79W6CFZIriqLrA</td>\n",
       "      <td></td>\n",
       "      <td>inside</td>\n",
       "      <td>dU7AyRB_fHOZkflodEyN5A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OnAzbTDn79W6CFZIriqLrA</td>\n",
       "      <td></td>\n",
       "      <td>outside</td>\n",
       "      <td>6T1qlbBdKkXA1cDNqMjg2g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OnAzbTDn79W6CFZIriqLrA</td>\n",
       "      <td>Bakery area</td>\n",
       "      <td>inside</td>\n",
       "      <td>lHhMNhCA7rAZmi-MMfF3ZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XaeCGHZzsMwvFcHYq3q9sA</td>\n",
       "      <td></td>\n",
       "      <td>food</td>\n",
       "      <td>oHSCeyoK9oLIGaCZq-wRJw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id      caption    label                photo_id\n",
       "0  OnAzbTDn79W6CFZIriqLrA                inside  soK1szeyan202jnsGhUDmA\n",
       "1  OnAzbTDn79W6CFZIriqLrA                inside  dU7AyRB_fHOZkflodEyN5A\n",
       "2  OnAzbTDn79W6CFZIriqLrA               outside  6T1qlbBdKkXA1cDNqMjg2g\n",
       "3  OnAzbTDn79W6CFZIriqLrA  Bakery area   inside  lHhMNhCA7rAZmi-MMfF3ZA\n",
       "4  XaeCGHZzsMwvFcHYq3q9sA                  food  oHSCeyoK9oLIGaCZq-wRJw"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip_df = pd.read_json(\"../dataset/tip_10k.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>likes</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tJRDll5yqpZwehenzE2cSg</td>\n",
       "      <td>2012-07-15</td>\n",
       "      <td>0</td>\n",
       "      <td>Get here early enough to have dinner.</td>\n",
       "      <td>zcTZk7OG8ovAmh_fenH21g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jH19V2I9fIslnNhDzPmdkA</td>\n",
       "      <td>2015-08-12</td>\n",
       "      <td>0</td>\n",
       "      <td>Great breakfast large portions and friendly wa...</td>\n",
       "      <td>ZcLKXikTHYOnYt5VYRO5sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dAa0hB2yrnHzVmsCkN4YvQ</td>\n",
       "      <td>2014-06-20</td>\n",
       "      <td>0</td>\n",
       "      <td>Nice place. Great staff.  A fixture in the tow...</td>\n",
       "      <td>oaYhjqBbh18ZhU0bpyzSuw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dAa0hB2yrnHzVmsCkN4YvQ</td>\n",
       "      <td>2016-10-12</td>\n",
       "      <td>0</td>\n",
       "      <td>Happy hour 5-7 Monday - Friday</td>\n",
       "      <td>ulQ8Nyj7jCUR8M83SUMoRQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESzO3Av0b1_TzKOiqzbQYQ</td>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>0</td>\n",
       "      <td>Parking is a premium, keep circling, you will ...</td>\n",
       "      <td>ulQ8Nyj7jCUR8M83SUMoRQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id       date  likes  \\\n",
       "0  tJRDll5yqpZwehenzE2cSg 2012-07-15      0   \n",
       "1  jH19V2I9fIslnNhDzPmdkA 2015-08-12      0   \n",
       "2  dAa0hB2yrnHzVmsCkN4YvQ 2014-06-20      0   \n",
       "3  dAa0hB2yrnHzVmsCkN4YvQ 2016-10-12      0   \n",
       "4  ESzO3Av0b1_TzKOiqzbQYQ 2017-01-28      0   \n",
       "\n",
       "                                                text                 user_id  \n",
       "0              Get here early enough to have dinner.  zcTZk7OG8ovAmh_fenH21g  \n",
       "1  Great breakfast large portions and friendly wa...  ZcLKXikTHYOnYt5VYRO5sg  \n",
       "2  Nice place. Great staff.  A fixture in the tow...  oaYhjqBbh18ZhU0bpyzSuw  \n",
       "3                     Happy hour 5-7 Monday - Friday  ulQ8Nyj7jCUR8M83SUMoRQ  \n",
       "4  Parking is a premium, keep circling, you will ...  ulQ8Nyj7jCUR8M83SUMoRQ  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tip_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Count Vectorizer\n",
      "(10000, 24872)\n"
     ]
    }
   ],
   "source": [
    "n_features = 100000\n",
    "\n",
    "text = reviews_df[\"text\"]\n",
    "\n",
    "print(\"Fitting Count Vectorizer\")\n",
    "# vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "#                                 max_features=n_features,\n",
    "#                                 stop_words='english')\n",
    "# word_vector = vectorizer.fit_transform(text)\n",
    "\n",
    "# No setting of hyper-parameters\n",
    "vectorizer = CountVectorizer()\n",
    "word_vector = vectorizer.fit_transform(text)\n",
    "\n",
    "print(np.shape(word_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At ces trade show and looking for lunch. I show up at 2:03 and the host jokingly says we are closed. We laughed. But he meant it. Last year my burger ordered medium came out almost raw. I am never going back\n",
      "1\n",
      "  (0, 17650)\t1\n",
      "  (0, 3376)\t1\n",
      "  (0, 13684)\t1\n",
      "  (0, 12582)\t1\n",
      "  (0, 4549)\t1\n",
      "  (0, 19037)\t1\n",
      "  (0, 11962)\t1\n",
      "  (0, 22483)\t1\n",
      "  (0, 3953)\t1\n",
      "  (0, 10897)\t1\n",
      "  (0, 13729)\t1\n",
      "  (0, 24528)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 12556)\t1\n",
      "  (0, 13164)\t1\n",
      "  (0, 15363)\t1\n",
      "  (0, 13056)\t1\n",
      "  (0, 19747)\t2\n",
      "  (0, 1101)\t1\n",
      "  (0, 10472)\t1\n",
      "  (0, 1133)\t1\n",
      "  (0, 3582)\t1\n",
      "  (0, 15453)\t1\n",
      "  (0, 14751)\t1\n",
      "  (0, 2016)\t1\n",
      "  (0, 1762)\t2\n",
      "  (0, 9793)\t1\n",
      "  (0, 23190)\t1\n",
      "  (0, 23929)\t2\n",
      "  (0, 1555)\t1\n",
      "  (0, 1239)\t2\n",
      "  (0, 8885)\t1\n",
      "  (0, 3440)\t1\n",
      "  (0, 22022)\t1\n",
      "  (0, 11748)\t1\n",
      "  (0, 14510)\t1\n"
     ]
    }
   ],
   "source": [
    "#Print example text, stars, and embeddings\n",
    "\n",
    "print(reviews_df[\"text\"][102])\n",
    "print(reviews_df[\"stars\"][102])\n",
    "print(word_vector[102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB Training and Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_user_reviews = reviews_df[\"text\"][0:6000]\n",
    "# x_dev_user_reviews = reviews_df[\"text\"][6001:8000]\n",
    "# x_test_user_reviews = reviews_df[\"text\"][8001:10000]\n",
    "\n",
    "\n",
    "# x_train_user_reviews = word_vector[0:6000]\n",
    "# x_dev_user_reviews = word_vector[6001:8000]\n",
    "x_train_user_reviews = word_vector[0:8000]\n",
    "x_test_user_reviews = word_vector[8001:10000]\n",
    "\n",
    "# print(\"x_train_user_reviews\", x_train_user_reviews)\n",
    "# print(\"shape x_train_user_reviews\", np.shape(x_train_user_reviews))\n",
    "\n",
    "\n",
    "\n",
    "# y_train_user_stars = reviews_df[\"stars\"][0:6000]\n",
    "# y_dev_user_stars = reviews_df[\"stars\"][6001:8000]\n",
    "y_train_user_stars = reviews_df[\"stars\"][0:8000]\n",
    "y_test_user_stars = reviews_df[\"stars\"][8001:10000]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_file = x_train_user_reviews\n",
    "label_file = y_train_user_stars\n",
    "training_data = x_train_user_reviews\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> 133             self.config.input_dim = self.training_data.shape[2]\n",
    "#     134             self.config.step_size = self.training_data.shape[1]\n",
    "#     135             self.config.label_dim = self.training_label.shape[1]\n",
    "\n",
    "# # print(training_data.shape[2])\n",
    "# print(training_data.shape[1])\n",
    "# print(np.shape(training_data))\n",
    "# print(len(training_data))\n",
    "# print(\"hi\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 55.93%\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "\n",
    "nb.fit(x_train_user_reviews, y_train_user_stars)\n",
    "\n",
    "y_pred = nb.predict(x_test_user_reviews)\n",
    "\n",
    "acc = accuracy_score(y_pred, y_test_user_stars)\n",
    "print(\"Accuracy on test set: {:.02%}\".format(acc))\n",
    "# pred_proba = nb.predict_proba(y_pred)\n",
    "# log_loss_metric = log_loss(y_test_user_stars, pred_proba)\n",
    "# print(\"Log-loss on test set: {:.02%}\".format(log_loss_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# Print example prediction\n",
    "\n",
    "print(y_pred[400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create New Slices of Review JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reviews_path = \"../../full_dataset/review.json\"\n",
    "# full_df = pd.read_json(\"../../full_dataset/review.json\", lines=True)\n",
    "# full_df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_100k = full_df[0:100000]\n",
    "# df_100k.to_json('../../full_dataset/df_100k.json', orient='records', lines=True)\n",
    "# df_100k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "\n",
    "# !pip install keras\n",
    "# !pip install pandas_ml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'boto' has no attribute 'plugin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-832ecb2a5cc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_ml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfusionMatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msimple_preprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparsing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/parsing/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m  \u001b[0;31m# noqa:F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m from .preprocessing import (remove_stopwords, strip_punctuation, strip_punctuation2,  # noqa:F401\n\u001b[0m\u001b[1;32m      5\u001b[0m                             \u001b[0mstrip_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_short\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_numeric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                             \u001b[0mstrip_non_alphanum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrip_multiple_whitespaces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/parsing/preprocessing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparsing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msmart_open\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/smart_open/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msmart_open_lib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mboto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murlsplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mboto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mssl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/boto/s3/key.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhashlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mboto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mboto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencodebytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/boto/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1214\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstorage_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m \u001b[0mboto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_plugins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'boto' has no attribute 'plugin'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Embedding, Dropout, Dense, LSTM\n",
    "from keras.callbacks import CSVLogger, History, ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Model\n",
    "from keras.models import model_from_json\n",
    "from keras.engine import Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, accuracy_score, precision_recall_fscore_support\n",
    "from pandas_ml import ConfusionMatrix\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "class YelpLSTM(object):\n",
    "    def __init__(self, parms):\n",
    "        self._parms = parms\n",
    "#         self._tokenizer = Tokenizer(nb_words=self._parms['vocabulary_size'])\n",
    "        self._tokenizer = Tokenizer(num_words=self._parms['vocabulary_size'])\n",
    "\n",
    "        self._reviews = None\n",
    "        self._balanced = None\n",
    "#         self._glove = None\n",
    "        self._embedding_matrix = None\n",
    "        self._model = None\n",
    "        self._verbose = True\n",
    "        self._predicted_classes = None\n",
    "        self._predicted_proba = None\n",
    "        self._eval_actual = None\n",
    "        self._eval_predicted_proba = None\n",
    "        self._eval_predicted_classes = None\n",
    "        self._logs = None\n",
    "        self._tpr = None\n",
    "        self._fpr = None\n",
    "        self._thresholds = None\n",
    "        self._auc = None\n",
    "        self._target_range = None\n",
    "        \n",
    "    def console(self, message):\n",
    "        if self._verbose:\n",
    "            print(message)\n",
    "            \n",
    "    def update_parms(self, parms):\n",
    "        if parms['vocabulary_size'] != self._parms['vocabulary_size']:\n",
    "            self._tokenizer = Tokenizer(nb_words=parms['vocabulary_size'])\n",
    "        self._parms = parms\n",
    "\n",
    "    def load_reviews(self, reviews_path):\n",
    "        self.console('Loading reviews...')\n",
    "        \n",
    "        self._reviews = pd.read_json(reviews_path, lines=True)\n",
    "\n",
    "        self.console('%d reviews loaded.' % len(self._reviews))\n",
    "        \n",
    "#     def load_glove(self, glove_folder):\n",
    "    # Changing to only load single file\n",
    "#     def load_glove(self, gloveFile):\n",
    "#         self.console('Loading GloVe embeddings...')\n",
    "#         glove = {}\n",
    "#         count = 0\n",
    "# #         with open(os.path.join(glove_folder, 'glove.6B.' + str(self._parms['embedding_dim']) + 'd.txt'), 'r') as f:\n",
    "\n",
    "#         with open(gloveFile, 'r') as f:\n",
    "#             while True:\n",
    "#                 line = f.readline()\n",
    "#                 if not line:\n",
    "#                     break\n",
    "#                 line = line.split(' ')\n",
    "#                 word = line[0]\n",
    "#                 vector = np.asarray(line[1:], dtype='float32')\n",
    "#                 glove[word] = vector\n",
    "#         self._glove = glove\n",
    "#         self.console('%d embeddings loaded.' % len(self._glove))\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    # Gensim Word2Vec model\n",
    "    vector_size = 300\n",
    "    window_size = 10\n",
    "\n",
    "    # Create Word2Vec\n",
    "    self.word2vec = Word2Vec(sentences=tokenized_corpus,\n",
    "                        size=vector_size, \n",
    "                        window=window_size, \n",
    "                        negative=20,\n",
    "                        iter=50,\n",
    "                        seed=1000,\n",
    "                        workers=multiprocessing.cpu_count())\n",
    "\n",
    "    self.X_vecs = self.word2vec.wv\n",
    "\n",
    "\n",
    "        \n",
    "     \n",
    "        \n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def training(self):\n",
    "        return self._X_train, self._y_train\n",
    "    \n",
    "    @property\n",
    "    def test(self):\n",
    "        return self._X_test, self._y_test\n",
    "    \n",
    "    @property\n",
    "    def best_model(self):\n",
    "        return self._model\n",
    "    \n",
    "    @property\n",
    "    def predicted_classes(self):\n",
    "        return self._predicted_classes\n",
    "    \n",
    "    @property\n",
    "    def predicted_proba(self):\n",
    "        return self._predicted_proba\n",
    "    \n",
    "    @property\n",
    "    def tokenizer(self):\n",
    "        return self._tokenizer\n",
    "    \n",
    "    @property\n",
    "    def logs(self):\n",
    "        return self._logs\n",
    "        \n",
    "    @property\n",
    "    def confusion_matrix(self):\n",
    "        return self._cm\n",
    "    \n",
    "    @property\n",
    "    def prfs(self):\n",
    "        return self._prfs\n",
    "    \n",
    "    @property\n",
    "    def prfs_weighted(self):\n",
    "        return self._prfs_weighted\n",
    "    \n",
    "    @property\n",
    "    def corr_coeff(self):\n",
    "        return self._corr_coeff\n",
    "    \n",
    "    @property\n",
    "    def fpr(self):\n",
    "        return self._fpr\n",
    "    \n",
    "    @property\n",
    "    def tpr(self):\n",
    "        return self._tpr\n",
    "    \n",
    "    @property\n",
    "    def thresholds(self):\n",
    "        return self._thresholds\n",
    "    \n",
    "    @property\n",
    "    def auc(self):\n",
    "        return self._auc\n",
    "    \n",
    "    @property\n",
    "    def eval_actual(self):\n",
    "        return self._eval_actual\n",
    "    \n",
    "    @property\n",
    "    def eval_predicted_classes(self):\n",
    "        return self._eval_predicted_classes\n",
    "            \n",
    "    def _balance_dataset(self):\n",
    "        categories = []\n",
    "        samples = []\n",
    "                \n",
    "        self._target_range = range(2)\n",
    "        \n",
    "        if self._parms['target']['feature'] == 'stars':\n",
    "            prefix = ''\n",
    "            self._target_range = range(1,6)\n",
    "            \n",
    "        else:\n",
    "            prefix = 'is_'\n",
    "            self._reviews['is_' + self._parms['target']['feature']] = self._reviews[self._parms['target']['feature']].apply(lambda v: v > self._parms['target']['threshold']).astype(int)            \n",
    "        for i in self._target_range:\n",
    "            categories.append(self._reviews[self._reviews[prefix + self._parms['target']['feature']] == i])\n",
    "        \n",
    "        sizes = list(map(lambda s: len(s), categories))\n",
    "        \n",
    "        nb_samples = min(self._parms['samples'], np.min(sizes))\n",
    "        self.console('Using %s samples per category' % str(nb_samples))\n",
    "        \n",
    "        for category in categories:\n",
    "            samples.append(category.sample(n=nb_samples, random_state=32))\n",
    "        self._balanced = pd.concat(samples)\n",
    "       \n",
    "    def _build_datasets(self):\n",
    "        self._tokenizer.fit_on_texts(self._balanced.text.values)\n",
    "        \n",
    "        sequences = self._tokenizer.texts_to_sequences(self._balanced.text)\n",
    "        padded_seq = pad_sequences(sequences, maxlen=self._parms['seq_size'])\n",
    "        \n",
    "        if self._parms['target']['feature'] == 'stars':\n",
    "            target = to_categorical(self._balanced[self._parms['target']['feature']])\n",
    "        else:\n",
    "            target = self._balanced['is_' + self._parms['target']['feature']].values\n",
    "\n",
    "        # Original\n",
    "#         self._X_train, self._X_test, self._y_train, self._y_test = train_test_split(padded_seq, target, test_size=0.2, random_state=42)\n",
    "        # Updates to randomization to replicate shared restaurant_reviews_final.JSON\n",
    "        self._X_train, self._X_test, self._y_train, self._y_test = train_test_split(padded_seq, target, test_size=0.2, random_state=123)\n",
    "            \n",
    "    def _build_embeddings(self):\n",
    "        tokenized_words = map(lambda t: t[0], sorted(self._tokenizer.word_index.items(), key=lambda t: t[1])[:self._parms['vocabulary_size']])\n",
    "\n",
    "        embedding_matrix = np.zeros((self._parms['vocabulary_size'], self._parms['embedding_dim']))\n",
    "        for idx, word in enumerate(tokenized_words):\n",
    "            try:\n",
    "#                 embedding_matrix[idx] = self._glove[word]\n",
    "                embedding_matrix[idx] = self.X_vecs[word]\n",
    "            except:\n",
    "                pass\n",
    "        self._embedding_matrix = embedding_matrix\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Embedding(input_dim=self._parms['vocabulary_size'],\n",
    "                            output_dim=self._parms['embedding_dim'],\n",
    "                            input_length=self._parms['seq_size'],\n",
    "                            weights=[self._embedding_matrix],\n",
    "                            trainable=False))\n",
    "\n",
    "        model.add(LSTM(self._parms['memory_neurons']))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        activation = 'sigmoid'\n",
    "        loss = 'binary_crossentropy'        \n",
    "        \n",
    "        outputs = 1\n",
    "        \n",
    "        if len(self._y_train.shape) > 1:\n",
    "            activation = 'softmax'\n",
    "            loss = 'categorical_crossentropy'\n",
    "            outputs = self._y_train.shape[1]\n",
    "            \n",
    "        model.add(Dense(outputs, activation=activation))        \n",
    "        \n",
    "        model.compile(loss=loss, optimizer='nadam', metrics=['accuracy'])    \n",
    "    \n",
    "        self._model = model\n",
    "        self.console(self._model.summary())\n",
    "\n",
    "    def fit(self, model_name, folder='./', verbose=True):\n",
    "        self._verbose = verbose\n",
    "        \n",
    "        assert self._reviews is not None, 'Reviews file was not loaded'\n",
    "        assert len(self._reviews) > 0, 'Reviews file is empty'\n",
    "#         assert self._glove is not None, 'GloVe file was not loaded'\n",
    "#         assert len(self._glove) > 0, 'GloVe file is empty'\n",
    "        \n",
    "        self.console('Balancing dataset...')\n",
    "        self._balance_dataset()\n",
    "        self.console('Building training and test datasets...')\n",
    "        self._build_datasets()\n",
    "#         self.console('Building word embeddings from GloVe...')\n",
    "        self.console('Building word embeddings from Word2Vec...')\n",
    "        self._build_embeddings()\n",
    "        self.console('Building model...')\n",
    "        self._build_model()\n",
    "        self.console('Fitting model...')\n",
    "        \n",
    "        parms_desc = model_name + '_%ddim_%dvoc_%dseq' % (self._parms['embedding_dim'],\n",
    "                                                          self._parms['vocabulary_size'],\n",
    "                                                          self._parms['seq_size'])      \n",
    "        \n",
    "        hist = History()        \n",
    "        \n",
    "        logger = CSVLogger(os.path.join(folder, parms_desc) + '_training_logs.csv')     \n",
    "        \n",
    "        checks = ModelCheckpoint(os.path.join(folder, parms_desc) + '_model-{epoch:02d}_{val_acc:.2f}',\n",
    "                                 monitor='val_acc',\n",
    "                                 verbose=int(self._verbose),\n",
    "                                 save_best_only=True,\n",
    "                                 mode='max')\n",
    "        early_stopping = EarlyStopping(monitor='val_acc', patience=2)\n",
    "        \n",
    "        self._model.fit(self._X_train\n",
    "                        , self._y_train\n",
    "#                        , nb_epoch=self._parms['nb_epochs']\n",
    "                        , epochs=self._parms['epochs']\n",
    "                        , batch_size=self._parms['batch_size']\n",
    "                        , validation_data=(self._X_test, self._y_test)\n",
    "                        , callbacks=[checks, hist, logger, early_stopping]\n",
    "                        )\n",
    "        \n",
    "        self._logs = pd.read_csv(os.path.join(folder, parms_desc) + '_training_logs.csv')\n",
    "        best_epoch = self._logs['val_acc'].argmax()\n",
    "    \n",
    "        best_val_acc = '{:.2f}'.format(self._logs['val_acc'].iloc[best_epoch])\n",
    "        \n",
    "        best_model = (os.path.join(folder, parms_desc) + '_model-%02d_%s') % (best_epoch + 1, best_val_acc)\n",
    "        \n",
    "        with open(os.path.join(folder, parms_desc + '_tokenizer'), 'wb') as tok:\n",
    "            pickle.dump(self._tokenizer, tok)\n",
    "        \n",
    "        self.console('Calculating predictions for the best model...')\n",
    "        self._model = load_model(best_model)       \n",
    "        \n",
    "        self._predicted_proba = self.predict_proba()\n",
    "        if len(self._y_train.shape) > 1:\n",
    "            self._predicted_classes = np.argmax(self._predicted_proba, axis=1)\n",
    "            \n",
    "        else:\n",
    "            self._predicted_classes = (self._predicted_proba > 0.5).astype(int)\n",
    "        \n",
    "        self.console('Calculating metrics for the best model...')\n",
    "        self.evaluate()\n",
    "        self.console('Finished!')      \n",
    "        \n",
    "        # serialize model to JSON\n",
    "        model_json = self._model.to_json()\n",
    "        with open(\"model.json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "        # serialize weights to HDF5\n",
    "        self._model.save_weights(\"model.h5\")\n",
    "        print(\"Saved model to disk\")      \n",
    "        \n",
    "        return self._model\n",
    "\n",
    "    def load(self, tokenizer, model):\n",
    "        error_msg = ''\n",
    "        try:\n",
    "            self._model = load_model(model)\n",
    "        except:\n",
    "            error_msg = 'Error loading model!'\n",
    "            \n",
    "        try:\n",
    "            with open(tokenizer, 'rb') as tok:\n",
    "                self._tokenizer = pickle.load(tok)\n",
    "        except:\n",
    "            error_msg = 'Error loading tokenizer!'\n",
    "            \n",
    "        return (error_msg == ''), error_msg\n",
    "    \n",
    "    def make_prediction(self, sentence):\n",
    "        sequence = self._tokenizer.texts_to_sequences([sentence])\n",
    "        padded_seq = pad_sequences(sequence, maxlen=self._parms['seq_size'])\n",
    "        return self.predict_classes(padded_seq)[0]\n",
    "    \n",
    "    def predict_classes(self, X=None, threshold=0.5):\n",
    "        if len(self._y_train.shape) > 1:\n",
    "            predictions = np.argmax(self.predict_proba(X), axis=1)\n",
    "        else:\n",
    "            predictions = (self.predict_proba(X) > threshold).astype(int)\n",
    "            \n",
    "        return predictions\n",
    "        \n",
    "    def predict_proba(self, X=None):\n",
    "        if X is None:\n",
    "            X = self._X_test\n",
    "        predictions = self._model.predict_proba(X)\n",
    "        return predictions\n",
    "    \n",
    "    def evaluate(self, actual=None, predicted_proba=None, threshold=0.5):\n",
    "        if actual is None:\n",
    "            eval_actual = self._y_test[:]\n",
    "        else:\n",
    "            eval_actual = actual[:]\n",
    "            \n",
    "        if predicted_proba is None:\n",
    "            eval_predicted_proba = self._predicted_proba[:]\n",
    "        else:\n",
    "            eval_predicted_proba = predicted_proba[:]\n",
    "            \n",
    "        if len(eval_actual.shape) == 1:\n",
    "            binary = True\n",
    "            eval_predicted_classes = (eval_predicted_proba > threshold).astype(int).ravel()\n",
    "            eval_predicted_proba = eval_predicted_proba.ravel()\n",
    "        else:\n",
    "            binary = False\n",
    "            eval_predicted_classes = eval_predicted_proba.argmax(axis=1)\n",
    "            eval_actual = eval_actual.argmax(axis=1)\n",
    "        \n",
    "        self._eval_actual = eval_actual\n",
    "        self._eval_predicted_proba = eval_predicted_proba\n",
    "        self._eval_predicted_classes = eval_predicted_classes\n",
    "    \n",
    "        self._cm = ConfusionMatrix(self._eval_actual, self._eval_predicted_classes)\n",
    "        \n",
    "        prfs = precision_recall_fscore_support(y_true=self._eval_actual, y_pred=self._eval_predicted_classes)\n",
    "        prfs = pd.DataFrame.from_dict(dict(zip(['precision', 'recall', 'fscore', 'support'], prfs)))\n",
    "        prfs_weighted = precision_recall_fscore_support(y_true=self._eval_actual, y_pred=self._eval_predicted_classes, average = 'weighted')\n",
    "#         prfs_weighted = pd.DataFrame.from_dict(dict(zip(['precision', 'recall', 'fscore', 'support'], prfs_weighted)))\n",
    "        corr_coeff = matthews_corrcoef(y_true=self._eval_actual, y_pred=self._eval_predicted_classes)                \n",
    "        \n",
    "#         prfs.set_index([self._target_range], inplace=True)\n",
    "        \n",
    "        self._prfs = prfs\n",
    "        self._prfs_weighted = prfs_weighted\n",
    "        self._corr_coeff = corr_coeff\n",
    "        \n",
    "        if binary:\n",
    "            self._fpr, self._tpr, self._thresholds = roc_curve(self._eval_actual, self._eval_predicted_proba)\n",
    "            self._auc = auc(self._fpr, self._tpr)\n",
    "        else:\n",
    "            self._fpr, self._tpr, self._thresholds, self._auc = None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parms = {\n",
    "#          'embedding_dim': 100,\n",
    "         'embedding_dim': 300,\n",
    "        \n",
    "         'vocabulary_size': 10000,\n",
    "#          'vocabulary_size': 100000,\n",
    "         'seq_size': 400,\n",
    "\n",
    "#          'epochs': 30,\n",
    "#          'epochs': 2,\n",
    "         'epochs': 1,\n",
    "         \n",
    "         'batch_size': 128,\n",
    "         'memory_neurons': 100,\n",
    "         'target': {\n",
    "             'feature': 'stars'\n",
    "             , 'threshold': None\n",
    "             },\n",
    "#          'samples': 62500\n",
    "         'samples': 1000000\n",
    "         }\n",
    "\n",
    "lstm = YelpLSTM(parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "print(\"Start time: \", start_time)\n",
    "\n",
    "reviews_path = \"../dataset/review_10k.json\"\n",
    "\n",
    "# reviews_path = \"../dataset/restaurant_reviews_10k.json\"\n",
    "\n",
    "# reviews_path = \"../../full_dataset/review.json\"\n",
    "\n",
    "# reviews_path = \"../../full_dataset/df_100k.json\"\n",
    "\n",
    "# reviews_path = \"../../full_dataset/restaurant_reviews.json\"\n",
    "\n",
    "# reviews_path = \"../../full_dataset/restaurant_reviews_final.json\"\n",
    "\n",
    "lstm.load_reviews(reviews_path)\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(\"End time: \", end_time)\n",
    "\n",
    "time_taken = end_time - start_time\n",
    "print(\"Time taken: \", time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Small GloVe file\n",
    "# # gloveFile = \"../../glove/glove.6B.100d.txt\"\n",
    "\n",
    "# # Primary GloVe file\n",
    "# gloveFile = \"../../glove/glove.6B.300d.txt\"\n",
    "\n",
    "# # Large GloVe file\n",
    "# # gloveFile = \"../../glove/glove.42B.300d.txt\"\n",
    "\n",
    "# start_time = datetime.datetime.now()\n",
    "# print(\"Start time: \", start_time)\n",
    "\n",
    "# lstm.load_glove(gloveFile)\n",
    "\n",
    "# end_time = datetime.datetime.now()\n",
    "# print(\"End time: \", end_time)\n",
    "\n",
    "# time_taken = end_time - start_time\n",
    "# print(\"Time taken: \", time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "print(\"Start time: \", start_time)\n",
    "\n",
    "model = lstm.fit(model_name='stars_100neurons', folder='./models/stars')\n",
    "# model = lstm.fit(model_name='stars_100neurons', folder='./')\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(\"End time: \", end_time)\n",
    "\n",
    "time_taken = end_time - start_time\n",
    "print(\"Time taken: \", time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load json and create model\n",
    "# json_file = open('model.json', 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# loaded_model = model_from_json(loaded_model_json)\n",
    "# # load weights into new model\n",
    "# loaded_model.load_weights(\"model.h5\")\n",
    "# print(\"Loaded model from disk\")\n",
    " \n",
    "# # evaluate loaded model on test data\n",
    "# # loaded_model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "# # score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "# # print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm._eval_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm.eval_predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.confusion_matrix.plot(normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.prfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.prfs_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.corr_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_example = 916765\n",
    "rand_tag_num = current_example\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_example = 865234\n",
    "rand_tag_num = current_example\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_example = 757343\n",
    "rand_tag_num = current_example\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_example = 392282\n",
    "rand_tag_num = current_example\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_df = pd.read_json(\"../../full_dataset/restaurant_reviews_final.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len_df = len(reviews_df[\"text\"])\n",
    "# print(\"len_df\", len_df)\n",
    "# predict_array = np.empty([len_df])\n",
    "# print(\"shape of predict_array:\", len(predict_array))\n",
    "\n",
    "# i = 0\n",
    "\n",
    "# # num_to_process = len_df\n",
    "# num_to_process = 10000\n",
    "\n",
    "\n",
    "# while i < num_to_process:\n",
    "#     predict_array[i] = lstm.make_prediction(reviews_df[\"text\"][i])\n",
    "#     i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reviews_df[\"text\"][511248])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][511248])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][511248]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reviews_df[\"text\"][811248])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][811248])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][811248]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(reviews_df[\"text\"][911249])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][911249])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][911249]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 392282\n",
    "\n",
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 757343\n",
    "\n",
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#865234\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#865234\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#865234\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#865234\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#865234\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#865234\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#865234\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#865234\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

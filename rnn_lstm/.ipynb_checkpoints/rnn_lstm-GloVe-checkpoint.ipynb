{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, json, time, unittest, datetime, shutil\n",
    "import itertools, collections\n",
    "import random\n",
    "from importlib import reload\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The data below is only on the 10k datasets for now. This will be updated to leverage the full datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Test - Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pd.read_json(\"../dataset/user_10k.json\", lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_stars</th>\n",
       "      <th>compliment_cool</th>\n",
       "      <th>compliment_cute</th>\n",
       "      <th>compliment_funny</th>\n",
       "      <th>compliment_hot</th>\n",
       "      <th>compliment_list</th>\n",
       "      <th>compliment_more</th>\n",
       "      <th>compliment_note</th>\n",
       "      <th>compliment_photos</th>\n",
       "      <th>compliment_plain</th>\n",
       "      <th>...</th>\n",
       "      <th>cool</th>\n",
       "      <th>elite</th>\n",
       "      <th>fans</th>\n",
       "      <th>friends</th>\n",
       "      <th>funny</th>\n",
       "      <th>name</th>\n",
       "      <th>review_count</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>yelping_since</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[cvVMmlU1ouS3I5fhutaryQ, nj6UZ8tdGo8YJ9lUMTVWN...</td>\n",
       "      <td>0</td>\n",
       "      <td>Johnny</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>oMy_rEb0UBEmMlu-zcxnoQ</td>\n",
       "      <td>2014-11-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0njfJmB-7n84DlIgUByCNw, rFn3Xe3RqHxRSxWOU19Gp...</td>\n",
       "      <td>0</td>\n",
       "      <td>Chris</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>JJ-aSuM4pCFPdkfoZ34q0Q</td>\n",
       "      <td>2013-09-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>Tiffy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>uUzsFQn_6cXDh6rPNGbIFA</td>\n",
       "      <td>2017-03-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>Mark</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>mBneaEEH5EMyxaVyqS-72A</td>\n",
       "      <td>2015-03-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>Evelyn</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>W5mJGs-dcDWRGEhAzUYtoA</td>\n",
       "      <td>2016-09-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   average_stars  compliment_cool  compliment_cute  compliment_funny  \\\n",
       "0           4.67                0                0                 0   \n",
       "1           3.70                0                0                 0   \n",
       "2           2.00                0                0                 0   \n",
       "3           4.67                0                0                 0   \n",
       "4           4.67                0                0                 0   \n",
       "\n",
       "   compliment_hot  compliment_list  compliment_more  compliment_note  \\\n",
       "0               0                0                0                0   \n",
       "1               0                0                0                0   \n",
       "2               0                0                0                0   \n",
       "3               0                0                0                0   \n",
       "4               0                0                0                0   \n",
       "\n",
       "   compliment_photos  compliment_plain      ...        cool  elite  fans  \\\n",
       "0                  0                 1      ...           0     []     0   \n",
       "1                  0                 0      ...           0     []     0   \n",
       "2                  0                 0      ...           0     []     0   \n",
       "3                  0                 0      ...           0     []     0   \n",
       "4                  0                 0      ...           0     []     0   \n",
       "\n",
       "                                             friends  funny    name  \\\n",
       "0  [cvVMmlU1ouS3I5fhutaryQ, nj6UZ8tdGo8YJ9lUMTVWN...      0  Johnny   \n",
       "1  [0njfJmB-7n84DlIgUByCNw, rFn3Xe3RqHxRSxWOU19Gp...      0   Chris   \n",
       "2                                                 []      0   Tiffy   \n",
       "3                                                 []      0    Mark   \n",
       "4                                                 []      0  Evelyn   \n",
       "\n",
       "   review_count useful                 user_id  yelping_since  \n",
       "0             8      0  oMy_rEb0UBEmMlu-zcxnoQ     2014-11-03  \n",
       "1            10      0  JJ-aSuM4pCFPdkfoZ34q0Q     2013-09-24  \n",
       "2             1      0  uUzsFQn_6cXDh6rPNGbIFA     2017-03-02  \n",
       "3             6      0  mBneaEEH5EMyxaVyqS-72A     2015-03-13  \n",
       "4             3      0  W5mJGs-dcDWRGEhAzUYtoA     2016-09-08  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All types of reviews - 10K dataset\n",
    "# reviews_df = pd.read_json(\"../dataset/review_10k.json\", lines=True)\n",
    "\n",
    "# Just restaurant reviews - 10K dataset\n",
    "reviews_df = pd.read_json(\"../dataset/restaurant_reviews_10k.json\", lines=True)\n",
    "\n",
    "# All types of reviews\n",
    "# reviews_df = pd.read_json(\"../../../final_project/full_dataset/review.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>This is one of my top 3 places to get BBQ pork...</td>\n",
       "      <td>2</td>\n",
       "      <td>FEg8v92qx3kK4Hu4TF28Fg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>This restaurant is famous for their BBQ dishes...</td>\n",
       "      <td>0</td>\n",
       "      <td>HPtjvIrhzAUkKsiVkeT4MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-10-23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Roasted pork is one of my favorite things... A...</td>\n",
       "      <td>1</td>\n",
       "      <td>MpvqV7lQcl15rflTBEUhXA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-07-30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>I walked by the restaurant more than 5 years a...</td>\n",
       "      <td>1</td>\n",
       "      <td>x-Gbs8sVid3yhJIoHD6Gfw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--6MefnULPED_I942VcFNA</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-02-07</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>I came here to order a roast duck over rice to...</td>\n",
       "      <td>0</td>\n",
       "      <td>7Dykd1HolQx8mKPYhYDYSg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool       date  funny  stars  \\\n",
       "0  --6MefnULPED_I942VcFNA     0 2017-08-17      0      4   \n",
       "1  --6MefnULPED_I942VcFNA     0 2017-05-31      0      3   \n",
       "2  --6MefnULPED_I942VcFNA     0 2016-10-23      0      2   \n",
       "3  --6MefnULPED_I942VcFNA     0 2017-07-30      0      2   \n",
       "4  --6MefnULPED_I942VcFNA     0 2017-02-07      1      2   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  This is one of my top 3 places to get BBQ pork...       2   \n",
       "1  This restaurant is famous for their BBQ dishes...       0   \n",
       "2  Roasted pork is one of my favorite things... A...       1   \n",
       "3  I walked by the restaurant more than 5 years a...       1   \n",
       "4  I came here to order a roast duck over rice to...       0   \n",
       "\n",
       "                  user_id  \n",
       "0  FEg8v92qx3kK4Hu4TF28Fg  \n",
       "1  HPtjvIrhzAUkKsiVkeT4MA  \n",
       "2  MpvqV7lQcl15rflTBEUhXA  \n",
       "3  x-Gbs8sVid3yhJIoHD6Gfw  \n",
       "4  7Dykd1HolQx8mKPYhYDYSg  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cool</th>\n",
       "      <th>funny</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.535000</td>\n",
       "      <td>0.458000</td>\n",
       "      <td>3.76540</td>\n",
       "      <td>1.037900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.866849</td>\n",
       "      <td>1.656958</td>\n",
       "      <td>1.31937</td>\n",
       "      <td>2.324307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               cool         funny        stars        useful\n",
       "count  10000.000000  10000.000000  10000.00000  10000.000000\n",
       "mean       0.535000      0.458000      3.76540      1.037900\n",
       "std        1.866849      1.656958      1.31937      2.324307\n",
       "min        0.000000      0.000000      1.00000      0.000000\n",
       "25%        0.000000      0.000000      3.00000      0.000000\n",
       "50%        0.000000      0.000000      4.00000      0.000000\n",
       "75%        0.000000      0.000000      5.00000      1.000000\n",
       "max       68.000000     52.000000      5.00000     72.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df = pd.read_json(\"../dataset/business_10k.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>attributes</th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>hours</th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4855 E Warner Rd, Ste B9</td>\n",
       "      <td>{'AcceptsInsurance': True, 'ByAppointmentOnly'...</td>\n",
       "      <td>FYWN1wneV18bWNgQjJ2GNg</td>\n",
       "      <td>[Dentists, General Dentistry, Health &amp; Medical...</td>\n",
       "      <td>Ahwatukee</td>\n",
       "      <td>{'Friday': '7:30-17:00', 'Tuesday': '7:30-17:0...</td>\n",
       "      <td>1</td>\n",
       "      <td>33.330690</td>\n",
       "      <td>-111.978599</td>\n",
       "      <td>Dental by Design</td>\n",
       "      <td></td>\n",
       "      <td>85044</td>\n",
       "      <td>22</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3101 Washington Rd</td>\n",
       "      <td>{'BusinessParking': {'garage': False, 'street'...</td>\n",
       "      <td>He-G7vWjzVUysIKrfNbPUQ</td>\n",
       "      <td>[Hair Stylists, Hair Salons, Men's Hair Salons...</td>\n",
       "      <td>McMurray</td>\n",
       "      <td>{'Monday': '9:00-20:00', 'Tuesday': '9:00-20:0...</td>\n",
       "      <td>1</td>\n",
       "      <td>40.291685</td>\n",
       "      <td>-80.104900</td>\n",
       "      <td>Stephen Szabo Salon</td>\n",
       "      <td></td>\n",
       "      <td>15317</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6025 N 27th Ave, Ste 1</td>\n",
       "      <td>{}</td>\n",
       "      <td>KQPW8lFf1y5BT2MxiSZ3QA</td>\n",
       "      <td>[Departments of Motor Vehicles, Public Service...</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>33.524903</td>\n",
       "      <td>-112.115310</td>\n",
       "      <td>Western Motor Vehicle</td>\n",
       "      <td></td>\n",
       "      <td>85017</td>\n",
       "      <td>18</td>\n",
       "      <td>1.5</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5000 Arizona Mills Cr, Ste 435</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': True, 'Restaura...</td>\n",
       "      <td>8DShNS-LuFqpEWIp0HxijA</td>\n",
       "      <td>[Sporting Goods, Shopping]</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>{'Monday': '10:00-21:00', 'Tuesday': '10:00-21...</td>\n",
       "      <td>0</td>\n",
       "      <td>33.383147</td>\n",
       "      <td>-111.964725</td>\n",
       "      <td>Sports Authority</td>\n",
       "      <td></td>\n",
       "      <td>85282</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>581 Howe Ave</td>\n",
       "      <td>{'Alcohol': 'full_bar', 'HasTV': True, 'NoiseL...</td>\n",
       "      <td>PfOCPjBrlQAnz__NXj9h_w</td>\n",
       "      <td>[American (New), Nightlife, Bars, Sandwiches, ...</td>\n",
       "      <td>Cuyahoga Falls</td>\n",
       "      <td>{'Monday': '11:00-1:00', 'Tuesday': '11:00-1:0...</td>\n",
       "      <td>1</td>\n",
       "      <td>41.119535</td>\n",
       "      <td>-81.475690</td>\n",
       "      <td>Brick House Tavern + Tap</td>\n",
       "      <td></td>\n",
       "      <td>44221</td>\n",
       "      <td>116</td>\n",
       "      <td>3.5</td>\n",
       "      <td>OH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          address  \\\n",
       "0        4855 E Warner Rd, Ste B9   \n",
       "1              3101 Washington Rd   \n",
       "2          6025 N 27th Ave, Ste 1   \n",
       "3  5000 Arizona Mills Cr, Ste 435   \n",
       "4                    581 Howe Ave   \n",
       "\n",
       "                                          attributes             business_id  \\\n",
       "0  {'AcceptsInsurance': True, 'ByAppointmentOnly'...  FYWN1wneV18bWNgQjJ2GNg   \n",
       "1  {'BusinessParking': {'garage': False, 'street'...  He-G7vWjzVUysIKrfNbPUQ   \n",
       "2                                                 {}  KQPW8lFf1y5BT2MxiSZ3QA   \n",
       "3  {'BusinessAcceptsCreditCards': True, 'Restaura...  8DShNS-LuFqpEWIp0HxijA   \n",
       "4  {'Alcohol': 'full_bar', 'HasTV': True, 'NoiseL...  PfOCPjBrlQAnz__NXj9h_w   \n",
       "\n",
       "                                          categories            city  \\\n",
       "0  [Dentists, General Dentistry, Health & Medical...       Ahwatukee   \n",
       "1  [Hair Stylists, Hair Salons, Men's Hair Salons...        McMurray   \n",
       "2  [Departments of Motor Vehicles, Public Service...         Phoenix   \n",
       "3                         [Sporting Goods, Shopping]           Tempe   \n",
       "4  [American (New), Nightlife, Bars, Sandwiches, ...  Cuyahoga Falls   \n",
       "\n",
       "                                               hours  is_open   latitude  \\\n",
       "0  {'Friday': '7:30-17:00', 'Tuesday': '7:30-17:0...        1  33.330690   \n",
       "1  {'Monday': '9:00-20:00', 'Tuesday': '9:00-20:0...        1  40.291685   \n",
       "2                                                 {}        1  33.524903   \n",
       "3  {'Monday': '10:00-21:00', 'Tuesday': '10:00-21...        0  33.383147   \n",
       "4  {'Monday': '11:00-1:00', 'Tuesday': '11:00-1:0...        1  41.119535   \n",
       "\n",
       "    longitude                      name neighborhood postal_code  \\\n",
       "0 -111.978599          Dental by Design                    85044   \n",
       "1  -80.104900       Stephen Szabo Salon                    15317   \n",
       "2 -112.115310     Western Motor Vehicle                    85017   \n",
       "3 -111.964725          Sports Authority                    85282   \n",
       "4  -81.475690  Brick House Tavern + Tap                    44221   \n",
       "\n",
       "   review_count  stars state  \n",
       "0            22    4.0    AZ  \n",
       "1            11    3.0    PA  \n",
       "2            18    1.5    AZ  \n",
       "3             9    3.0    AZ  \n",
       "4           116    3.5    OH  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df = pd.read_json(\"../dataset/checkin_10k.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7KPBkxAOEtb3QeIL9PEErg</td>\n",
       "      <td>{'Thursday': {'21:00': 4, '1:00': 1, '4:00': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kREVIrSBbtqBhIYkTccQUg</td>\n",
       "      <td>{'Monday': {'13:00': 1}, 'Thursday': {'20:00':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tJRDll5yqpZwehenzE2cSg</td>\n",
       "      <td>{'Monday': {'12:00': 1, '1:00': 1}, 'Friday': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r1p7RAMzCV_6NPF0dNoR3g</td>\n",
       "      <td>{'Thursday': {'23:00': 1}, 'Saturday': {'21:00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mDdqgfrvROGAumcQdZ3HIg</td>\n",
       "      <td>{'Monday': {'12:00': 1, '21:00': 1}, 'Wednesda...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                                               time\n",
       "0  7KPBkxAOEtb3QeIL9PEErg  {'Thursday': {'21:00': 4, '1:00': 1, '4:00': 1...\n",
       "1  kREVIrSBbtqBhIYkTccQUg  {'Monday': {'13:00': 1}, 'Thursday': {'20:00':...\n",
       "2  tJRDll5yqpZwehenzE2cSg  {'Monday': {'12:00': 1, '1:00': 1}, 'Friday': ...\n",
       "3  r1p7RAMzCV_6NPF0dNoR3g  {'Thursday': {'23:00': 1}, 'Saturday': {'21:00...\n",
       "4  mDdqgfrvROGAumcQdZ3HIg  {'Monday': {'12:00': 1, '21:00': 1}, 'Wednesda..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos_df = pd.read_json(\"../dataset/photos_10k.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>caption</th>\n",
       "      <th>label</th>\n",
       "      <th>photo_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OnAzbTDn79W6CFZIriqLrA</td>\n",
       "      <td></td>\n",
       "      <td>inside</td>\n",
       "      <td>soK1szeyan202jnsGhUDmA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OnAzbTDn79W6CFZIriqLrA</td>\n",
       "      <td></td>\n",
       "      <td>inside</td>\n",
       "      <td>dU7AyRB_fHOZkflodEyN5A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OnAzbTDn79W6CFZIriqLrA</td>\n",
       "      <td></td>\n",
       "      <td>outside</td>\n",
       "      <td>6T1qlbBdKkXA1cDNqMjg2g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OnAzbTDn79W6CFZIriqLrA</td>\n",
       "      <td>Bakery area</td>\n",
       "      <td>inside</td>\n",
       "      <td>lHhMNhCA7rAZmi-MMfF3ZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XaeCGHZzsMwvFcHYq3q9sA</td>\n",
       "      <td></td>\n",
       "      <td>food</td>\n",
       "      <td>oHSCeyoK9oLIGaCZq-wRJw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id      caption    label                photo_id\n",
       "0  OnAzbTDn79W6CFZIriqLrA                inside  soK1szeyan202jnsGhUDmA\n",
       "1  OnAzbTDn79W6CFZIriqLrA                inside  dU7AyRB_fHOZkflodEyN5A\n",
       "2  OnAzbTDn79W6CFZIriqLrA               outside  6T1qlbBdKkXA1cDNqMjg2g\n",
       "3  OnAzbTDn79W6CFZIriqLrA  Bakery area   inside  lHhMNhCA7rAZmi-MMfF3ZA\n",
       "4  XaeCGHZzsMwvFcHYq3q9sA                  food  oHSCeyoK9oLIGaCZq-wRJw"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip_df = pd.read_json(\"../dataset/tip_10k.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>likes</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tJRDll5yqpZwehenzE2cSg</td>\n",
       "      <td>2012-07-15</td>\n",
       "      <td>0</td>\n",
       "      <td>Get here early enough to have dinner.</td>\n",
       "      <td>zcTZk7OG8ovAmh_fenH21g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jH19V2I9fIslnNhDzPmdkA</td>\n",
       "      <td>2015-08-12</td>\n",
       "      <td>0</td>\n",
       "      <td>Great breakfast large portions and friendly wa...</td>\n",
       "      <td>ZcLKXikTHYOnYt5VYRO5sg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dAa0hB2yrnHzVmsCkN4YvQ</td>\n",
       "      <td>2014-06-20</td>\n",
       "      <td>0</td>\n",
       "      <td>Nice place. Great staff.  A fixture in the tow...</td>\n",
       "      <td>oaYhjqBbh18ZhU0bpyzSuw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dAa0hB2yrnHzVmsCkN4YvQ</td>\n",
       "      <td>2016-10-12</td>\n",
       "      <td>0</td>\n",
       "      <td>Happy hour 5-7 Monday - Friday</td>\n",
       "      <td>ulQ8Nyj7jCUR8M83SUMoRQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESzO3Av0b1_TzKOiqzbQYQ</td>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>0</td>\n",
       "      <td>Parking is a premium, keep circling, you will ...</td>\n",
       "      <td>ulQ8Nyj7jCUR8M83SUMoRQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id       date  likes  \\\n",
       "0  tJRDll5yqpZwehenzE2cSg 2012-07-15      0   \n",
       "1  jH19V2I9fIslnNhDzPmdkA 2015-08-12      0   \n",
       "2  dAa0hB2yrnHzVmsCkN4YvQ 2014-06-20      0   \n",
       "3  dAa0hB2yrnHzVmsCkN4YvQ 2016-10-12      0   \n",
       "4  ESzO3Av0b1_TzKOiqzbQYQ 2017-01-28      0   \n",
       "\n",
       "                                                text                 user_id  \n",
       "0              Get here early enough to have dinner.  zcTZk7OG8ovAmh_fenH21g  \n",
       "1  Great breakfast large portions and friendly wa...  ZcLKXikTHYOnYt5VYRO5sg  \n",
       "2  Nice place. Great staff.  A fixture in the tow...  oaYhjqBbh18ZhU0bpyzSuw  \n",
       "3                     Happy hour 5-7 Monday - Friday  ulQ8Nyj7jCUR8M83SUMoRQ  \n",
       "4  Parking is a premium, keep circling, you will ...  ulQ8Nyj7jCUR8M83SUMoRQ  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tip_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Count Vectorizer\n",
      "(10000, 24872)\n"
     ]
    }
   ],
   "source": [
    "n_features = 100000\n",
    "\n",
    "text = reviews_df[\"text\"]\n",
    "\n",
    "print(\"Fitting Count Vectorizer\")\n",
    "# vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "#                                 max_features=n_features,\n",
    "#                                 stop_words='english')\n",
    "# word_vector = vectorizer.fit_transform(text)\n",
    "\n",
    "# No setting of hyper-parameters\n",
    "vectorizer = CountVectorizer()\n",
    "word_vector = vectorizer.fit_transform(text)\n",
    "\n",
    "print(np.shape(word_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB Training and Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_user_reviews = reviews_df[\"text\"][0:6000]\n",
    "# x_dev_user_reviews = reviews_df[\"text\"][6001:8000]\n",
    "# x_test_user_reviews = reviews_df[\"text\"][8001:10000]\n",
    "\n",
    "# x_train_user_reviews = word_vector[0:6000]\n",
    "# x_dev_user_reviews = word_vector[6001:8000]\n",
    "x_train_user_reviews = word_vector[0:8000]\n",
    "x_test_user_reviews = word_vector[8001:10000]\n",
    "\n",
    "# print(\"x_train_user_reviews\", x_train_user_reviews)\n",
    "# print(\"shape x_train_user_reviews\", np.shape(x_train_user_reviews))\n",
    "\n",
    "# y_train_user_stars = reviews_df[\"stars\"][0:6000]\n",
    "# y_dev_user_stars = reviews_df[\"stars\"][6001:8000]\n",
    "y_train_user_stars = reviews_df[\"stars\"][0:8000]\n",
    "y_test_user_stars = reviews_df[\"stars\"][8001:10000]\n",
    "\n",
    "train_file = x_train_user_reviews\n",
    "label_file = y_train_user_stars\n",
    "training_data = x_train_user_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 55.93%\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "\n",
    "nb.fit(x_train_user_reviews, y_train_user_stars)\n",
    "\n",
    "y_pred = nb.predict(x_test_user_reviews)\n",
    "\n",
    "acc = accuracy_score(y_pred, y_test_user_stars)\n",
    "print(\"Accuracy on test set: {:.02%}\".format(acc))\n",
    "# pred_proba = nb.predict_proba(y_pred)\n",
    "# log_loss_metric = log_loss(y_test_user_stars, pred_proba)\n",
    "# print(\"Log-loss on test set: {:.02%}\".format(log_loss_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# Print example prediction\n",
    "\n",
    "print(y_pred[400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create New Slices of Review JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reviews_path = \"../../full_dataset/review.json\"\n",
    "# full_df = pd.read_json(\"../../full_dataset/review.json\", lines=True)\n",
    "# full_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_100k = full_df[0:100000]\n",
    "# df_100k.to_json('../../full_dataset/df_100k.json', orient='records', lines=True)\n",
    "# df_100k.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "\n",
    "# !pip install keras\n",
    "# !pip install pandas_ml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Embedding, Dropout, Dense, LSTM\n",
    "from keras.callbacks import CSVLogger, History, ModelCheckpoint, EarlyStopping\n",
    "from keras.models import model_from_json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, accuracy_score, precision_recall_fscore_support\n",
    "from pandas_ml import ConfusionMatrix\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "class YelpLSTM(object):\n",
    "    def __init__(self, parms):\n",
    "        self._parms = parms\n",
    "#         self._tokenizer = Tokenizer(nb_words=self._parms['vocabulary_size'])\n",
    "        self._tokenizer = Tokenizer(num_words=self._parms['vocabulary_size'])\n",
    "\n",
    "        self._reviews = None\n",
    "        self._balanced = None\n",
    "        self._glove = None\n",
    "        self._embedding_matrix = None\n",
    "        self._model = None\n",
    "        self._verbose = True\n",
    "        self._predicted_classes = None\n",
    "        self._predicted_proba = None\n",
    "        self._eval_actual = None\n",
    "        self._eval_predicted_proba = None\n",
    "        self._eval_predicted_classes = None\n",
    "        self._logs = None\n",
    "        self._tpr = None\n",
    "        self._fpr = None\n",
    "        self._thresholds = None\n",
    "        self._auc = None\n",
    "        self._target_range = None\n",
    "        \n",
    "    def console(self, message):\n",
    "        if self._verbose:\n",
    "            print(message)\n",
    "            \n",
    "    def update_parms(self, parms):\n",
    "        if parms['vocabulary_size'] != self._parms['vocabulary_size']:\n",
    "            self._tokenizer = Tokenizer(nb_words=parms['vocabulary_size'])\n",
    "        self._parms = parms\n",
    "\n",
    "    def load_reviews(self, reviews_path):\n",
    "        self.console('Loading reviews...')\n",
    "        \n",
    "        self._reviews = pd.read_json(reviews_path, lines=True)\n",
    "\n",
    "        self.console('%d reviews loaded.' % len(self._reviews))\n",
    "        \n",
    "#     def load_glove(self, glove_folder):\n",
    "    # Changing to only load single file\n",
    "    def load_glove(self, gloveFile):\n",
    "        self.console('Loading GloVe embeddings...')\n",
    "        glove = {}\n",
    "        count = 0\n",
    "#         with open(os.path.join(glove_folder, 'glove.6B.' + str(self._parms['embedding_dim']) + 'd.txt'), 'r') as f:\n",
    "\n",
    "        with open(gloveFile, 'r') as f:\n",
    "            while True:\n",
    "                line = f.readline()\n",
    "                if not line:\n",
    "                    break\n",
    "                line = line.split(' ')\n",
    "                word = line[0]\n",
    "                vector = np.asarray(line[1:], dtype='float32')\n",
    "                glove[word] = vector\n",
    "        self._glove = glove\n",
    "        self.console('%d embeddings loaded.' % len(self._glove))\n",
    "        \n",
    "    @property\n",
    "    def training(self):\n",
    "        return self._X_train, self._y_train\n",
    "    \n",
    "    @property\n",
    "    def test(self):\n",
    "        return self._X_test, self._y_test\n",
    "    \n",
    "    @property\n",
    "    def best_model(self):\n",
    "        return self._model\n",
    "    \n",
    "    @property\n",
    "    def predicted_classes(self):\n",
    "        return self._predicted_classes\n",
    "    \n",
    "    @property\n",
    "    def predicted_proba(self):\n",
    "        return self._predicted_proba\n",
    "    \n",
    "    @property\n",
    "    def tokenizer(self):\n",
    "        return self._tokenizer\n",
    "    \n",
    "    @property\n",
    "    def logs(self):\n",
    "        return self._logs\n",
    "        \n",
    "    @property\n",
    "    def confusion_matrix(self):\n",
    "        return self._cm\n",
    "    \n",
    "    @property\n",
    "    def prfs(self):\n",
    "        return self._prfs\n",
    "    \n",
    "    @property\n",
    "    def prfs_weighted(self):\n",
    "        return self._prfs_weighted\n",
    "    \n",
    "    @property\n",
    "    def corr_coeff(self):\n",
    "        return self._corr_coeff\n",
    "    \n",
    "    @property\n",
    "    def fpr(self):\n",
    "        return self._fpr\n",
    "    \n",
    "    @property\n",
    "    def tpr(self):\n",
    "        return self._tpr\n",
    "    \n",
    "    @property\n",
    "    def thresholds(self):\n",
    "        return self._thresholds\n",
    "    \n",
    "    @property\n",
    "    def auc(self):\n",
    "        return self._auc\n",
    "    \n",
    "    @property\n",
    "    def eval_actual(self):\n",
    "        return self._eval_actual\n",
    "    \n",
    "    @property\n",
    "    def eval_predicted_classes(self):\n",
    "        return self._eval_predicted_classes\n",
    "            \n",
    "    def _balance_dataset(self):\n",
    "        categories = []\n",
    "        samples = []\n",
    "                \n",
    "        self._target_range = range(2)\n",
    "        \n",
    "        if self._parms['target']['feature'] == 'stars':\n",
    "            prefix = ''\n",
    "            self._target_range = range(1,6)\n",
    "            \n",
    "        else:\n",
    "            prefix = 'is_'\n",
    "            self._reviews['is_' + self._parms['target']['feature']] = self._reviews[self._parms['target']['feature']].apply(lambda v: v > self._parms['target']['threshold']).astype(int)            \n",
    "        for i in self._target_range:\n",
    "            categories.append(self._reviews[self._reviews[prefix + self._parms['target']['feature']] == i])\n",
    "        \n",
    "        sizes = list(map(lambda s: len(s), categories))\n",
    "        \n",
    "        nb_samples = min(self._parms['samples'], np.min(sizes))\n",
    "        self.console('Using %s samples per category' % str(nb_samples))\n",
    "        \n",
    "        for category in categories:\n",
    "            samples.append(category.sample(n=nb_samples, random_state=32))\n",
    "        self._balanced = pd.concat(samples)\n",
    "       \n",
    "    def _build_datasets(self):\n",
    "        self._tokenizer.fit_on_texts(self._balanced.text.values)\n",
    "        \n",
    "        sequences = self._tokenizer.texts_to_sequences(self._balanced.text)\n",
    "        padded_seq = pad_sequences(sequences, maxlen=self._parms['seq_size'])\n",
    "        \n",
    "        if self._parms['target']['feature'] == 'stars':\n",
    "            target = to_categorical(self._balanced[self._parms['target']['feature']])\n",
    "        else:\n",
    "            target = self._balanced['is_' + self._parms['target']['feature']].values\n",
    "\n",
    "        # Original\n",
    "#         self._X_train, self._X_test, self._y_train, self._y_test = train_test_split(padded_seq, target, test_size=0.2, random_state=42)\n",
    "        # Updates to randomization to replicate shared restaurant_reviews_final.JSON\n",
    "        self._X_train, self._X_test, self._y_train, self._y_test = train_test_split(padded_seq, target, test_size=0.2, random_state=123)\n",
    "            \n",
    "    def _build_embeddings(self):\n",
    "        tokenized_words = map(lambda t: t[0], sorted(self._tokenizer.word_index.items(), key=lambda t: t[1])[:self._parms['vocabulary_size']])\n",
    "\n",
    "        embedding_matrix = np.zeros((self._parms['vocabulary_size'], self._parms['embedding_dim']))\n",
    "        for idx, word in enumerate(tokenized_words):\n",
    "            try:\n",
    "                embedding_matrix[idx] = self._glove[word]\n",
    "            except:\n",
    "                pass\n",
    "        self._embedding_matrix = embedding_matrix\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Embedding(input_dim=self._parms['vocabulary_size'],\n",
    "                            output_dim=self._parms['embedding_dim'],\n",
    "                            input_length=self._parms['seq_size'],\n",
    "                            weights=[self._embedding_matrix],\n",
    "                            trainable=False))\n",
    "\n",
    "        model.add(LSTM(self._parms['memory_neurons']))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        activation = 'sigmoid'\n",
    "        loss = 'binary_crossentropy'        \n",
    "        \n",
    "        outputs = 1\n",
    "        \n",
    "        if len(self._y_train.shape) > 1:\n",
    "            activation = 'softmax'\n",
    "            loss = 'categorical_crossentropy'\n",
    "            outputs = self._y_train.shape[1]\n",
    "            \n",
    "        model.add(Dense(outputs, activation=activation))        \n",
    "        \n",
    "        model.compile(loss=loss, optimizer='nadam', metrics=['accuracy'])    \n",
    "    \n",
    "        self._model = model\n",
    "        self.console(self._model.summary())\n",
    "\n",
    "    def fit(self, model_name, folder='./', verbose=True):\n",
    "        self._verbose = verbose\n",
    "        \n",
    "        assert self._reviews is not None, 'Reviews file was not loaded'\n",
    "        assert len(self._reviews) > 0, 'Reviews file is empty'\n",
    "        assert self._glove is not None, 'GloVe file was not loaded'\n",
    "        assert len(self._glove) > 0, 'GloVe file is empty'\n",
    "        \n",
    "        self.console('Balancing dataset...')\n",
    "        self._balance_dataset()\n",
    "        self.console('Building training and test datasets...')\n",
    "        self._build_datasets()\n",
    "        self.console('Building word embeddings from GloVe...')\n",
    "        self._build_embeddings()\n",
    "        self.console('Building model...')\n",
    "        self._build_model()\n",
    "        self.console('Fitting model...')\n",
    "        \n",
    "        parms_desc = model_name + '_%ddim_%dvoc_%dseq' % (self._parms['embedding_dim'],\n",
    "                                                          self._parms['vocabulary_size'],\n",
    "                                                          self._parms['seq_size'])      \n",
    "        \n",
    "        hist = History()        \n",
    "        \n",
    "        logger = CSVLogger(os.path.join(folder, parms_desc) + '_training_logs.csv')     \n",
    "        \n",
    "        checks = ModelCheckpoint(os.path.join(folder, parms_desc) + '_model-{epoch:02d}_{val_acc:.2f}',\n",
    "                                 monitor='val_acc',\n",
    "                                 verbose=int(self._verbose),\n",
    "                                 save_best_only=True,\n",
    "                                 mode='max')\n",
    "        early_stopping = EarlyStopping(monitor='val_acc', patience=2)\n",
    "        \n",
    "        self._model.fit(self._X_train\n",
    "                        , self._y_train\n",
    "#                        , nb_epoch=self._parms['nb_epochs']\n",
    "                        , epochs=self._parms['epochs']\n",
    "                        , batch_size=self._parms['batch_size']\n",
    "                        , validation_data=(self._X_test, self._y_test)\n",
    "                        , callbacks=[checks, hist, logger, early_stopping]\n",
    "                        )\n",
    "        \n",
    "        self._logs = pd.read_csv(os.path.join(folder, parms_desc) + '_training_logs.csv')\n",
    "        best_epoch = self._logs['val_acc'].argmax()\n",
    "    \n",
    "        best_val_acc = '{:.2f}'.format(self._logs['val_acc'].iloc[best_epoch])\n",
    "        \n",
    "        best_model = (os.path.join(folder, parms_desc) + '_model-%02d_%s') % (best_epoch + 1, best_val_acc)\n",
    "        \n",
    "        with open(os.path.join(folder, parms_desc + '_tokenizer'), 'wb') as tok:\n",
    "            pickle.dump(self._tokenizer, tok)\n",
    "        \n",
    "        self.console('Calculating predictions for the best model...')\n",
    "        self._model = load_model(best_model)       \n",
    "        \n",
    "        self._predicted_proba = self.predict_proba()\n",
    "        if len(self._y_train.shape) > 1:\n",
    "            self._predicted_classes = np.argmax(self._predicted_proba, axis=1)\n",
    "            \n",
    "        else:\n",
    "            self._predicted_classes = (self._predicted_proba > 0.5).astype(int)\n",
    "        \n",
    "        self.console('Calculating metrics for the best model...')\n",
    "        self.evaluate()\n",
    "        self.console('Finished!')      \n",
    "        \n",
    "        # serialize model to JSON\n",
    "        model_json = self._model.to_json()\n",
    "        with open(\"model.json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "        # serialize weights to HDF5\n",
    "        self._model.save_weights(\"model.h5\")\n",
    "        print(\"Saved model to disk\")      \n",
    "        \n",
    "        return self._model\n",
    "\n",
    "    def load(self, tokenizer, model):\n",
    "        error_msg = ''\n",
    "        try:\n",
    "            self._model = load_model(model)\n",
    "        except:\n",
    "            error_msg = 'Error loading model!'\n",
    "            \n",
    "        try:\n",
    "            with open(tokenizer, 'rb') as tok:\n",
    "                self._tokenizer = pickle.load(tok)\n",
    "        except:\n",
    "            error_msg = 'Error loading tokenizer!'\n",
    "            \n",
    "        return (error_msg == ''), error_msg\n",
    "    \n",
    "    def make_prediction(self, sentence):\n",
    "        sequence = self._tokenizer.texts_to_sequences([sentence])\n",
    "        padded_seq = pad_sequences(sequence, maxlen=self._parms['seq_size'])\n",
    "        return self.predict_classes(padded_seq)[0]\n",
    "    \n",
    "    def predict_classes(self, X=None, threshold=0.5):\n",
    "        if len(self._y_train.shape) > 1:\n",
    "            predictions = np.argmax(self.predict_proba(X), axis=1)\n",
    "        else:\n",
    "            predictions = (self.predict_proba(X) > threshold).astype(int)\n",
    "            \n",
    "        return predictions\n",
    "        \n",
    "    def predict_proba(self, X=None):\n",
    "        if X is None:\n",
    "            X = self._X_test\n",
    "        predictions = self._model.predict_proba(X)\n",
    "        return predictions\n",
    "    \n",
    "    def evaluate(self, actual=None, predicted_proba=None, threshold=0.5):\n",
    "        if actual is None:\n",
    "            eval_actual = self._y_test[:]\n",
    "        else:\n",
    "            eval_actual = actual[:]\n",
    "            \n",
    "        if predicted_proba is None:\n",
    "            eval_predicted_proba = self._predicted_proba[:]\n",
    "        else:\n",
    "            eval_predicted_proba = predicted_proba[:]\n",
    "            \n",
    "        if len(eval_actual.shape) == 1:\n",
    "            binary = True\n",
    "            eval_predicted_classes = (eval_predicted_proba > threshold).astype(int).ravel()\n",
    "            eval_predicted_proba = eval_predicted_proba.ravel()\n",
    "        else:\n",
    "            binary = False\n",
    "            eval_predicted_classes = eval_predicted_proba.argmax(axis=1)\n",
    "            eval_actual = eval_actual.argmax(axis=1)\n",
    "        \n",
    "        self._eval_actual = eval_actual\n",
    "        self._eval_predicted_proba = eval_predicted_proba\n",
    "        self._eval_predicted_classes = eval_predicted_classes\n",
    "    \n",
    "        self._cm = ConfusionMatrix(self._eval_actual, self._eval_predicted_classes)\n",
    "        \n",
    "        prfs = precision_recall_fscore_support(y_true=self._eval_actual, y_pred=self._eval_predicted_classes)\n",
    "        prfs = pd.DataFrame.from_dict(dict(zip(['precision', 'recall', 'fscore', 'support'], prfs)))\n",
    "        prfs_weighted = precision_recall_fscore_support(y_true=self._eval_actual, y_pred=self._eval_predicted_classes, average = 'weighted')\n",
    "#         prfs_weighted = pd.DataFrame.from_dict(dict(zip(['precision', 'recall', 'fscore', 'support'], prfs_weighted)))\n",
    "        corr_coeff = matthews_corrcoef(y_true=self._eval_actual, y_pred=self._eval_predicted_classes)                \n",
    "        \n",
    "#         prfs.set_index([self._target_range], inplace=True)\n",
    "        \n",
    "        self._prfs = prfs\n",
    "        self._prfs_weighted = prfs_weighted\n",
    "        self._corr_coeff = corr_coeff\n",
    "        \n",
    "        if binary:\n",
    "            self._fpr, self._tpr, self._thresholds = roc_curve(self._eval_actual, self._eval_predicted_proba)\n",
    "            self._auc = auc(self._fpr, self._tpr)\n",
    "        else:\n",
    "            self._fpr, self._tpr, self._thresholds, self._auc = None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "parms = {\n",
    "#          'embedding_dim': 100,\n",
    "         'embedding_dim': 300,\n",
    "        \n",
    "         'vocabulary_size': 10000,\n",
    "#          'vocabulary_size': 100000,\n",
    "         'seq_size': 400,\n",
    "\n",
    "         'epochs': 30,         \n",
    "#          'epochs': 2,\n",
    "#          'epochs': 1,\n",
    "         \n",
    "         'batch_size': 128,\n",
    "         'memory_neurons': 100,\n",
    "         'target': {\n",
    "             'feature': 'stars'\n",
    "             , 'threshold': None\n",
    "             },\n",
    "#          'samples': 62500\n",
    "         'samples': 1000000\n",
    "         }\n",
    "\n",
    "lstm = YelpLSTM(parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time:  2018-08-09 01:10:21.976300\n",
      "Loading reviews...\n",
      "1873619 reviews loaded.\n",
      "End time:  2018-08-09 01:11:09.529467\n",
      "Time taken:  0:00:47.553167\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "print(\"Start time: \", start_time)\n",
    "\n",
    "# reviews_path = \"../dataset/review_10k.json\"\n",
    "\n",
    "# reviews_path = \"../dataset/restaurant_reviews_10k.json\"\n",
    "\n",
    "# reviews_path = \"../../full_dataset/review.json\"\n",
    "\n",
    "# reviews_path = \"../../full_dataset/df_100k.json\"\n",
    "\n",
    "# reviews_path = \"../../full_dataset/restaurant_reviews.json\"\n",
    "\n",
    "reviews_path = \"../../full_dataset/restaurant_reviews_final.json\"\n",
    "\n",
    "lstm.load_reviews(reviews_path)\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(\"End time: \", end_time)\n",
    "\n",
    "time_taken = end_time - start_time\n",
    "print(\"Time taken: \", time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time:  2018-08-09 01:11:09.540475\n",
      "Loading GloVe embeddings...\n",
      "400000 embeddings loaded.\n",
      "End time:  2018-08-09 01:11:44.404142\n",
      "Time taken:  0:00:34.863667\n"
     ]
    }
   ],
   "source": [
    "# Small GloVe file\n",
    "# gloveFile = \"../../glove/glove.6B.100d.txt\"\n",
    "\n",
    "# Primary GloVe file\n",
    "gloveFile = \"../../glove/glove.6B.300d.txt\"\n",
    "\n",
    "# Large GloVe file\n",
    "# gloveFile = \"../../glove/glove.42B.300d.txt\"\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "print(\"Start time: \", start_time)\n",
    "\n",
    "lstm.load_glove(gloveFile)\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(\"End time: \", end_time)\n",
    "\n",
    "time_taken = end_time - start_time\n",
    "print(\"Time taken: \", time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time:  2018-08-09 01:11:44.415212\n",
      "Balancing dataset...\n",
      "Using 146429 samples per category\n",
      "Building training and test datasets...\n",
      "Building word embeddings from GloVe...\n",
      "Building model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 400, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 3,161,006\n",
      "Trainable params: 161,006\n",
      "Non-trainable params: 3,000,000\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fitting model...\n",
      "Train on 585716 samples, validate on 146429 samples\n",
      "Epoch 1/30\n",
      "585716/585716 [==============================] - 3204s 5ms/step - loss: 1.0277 - acc: 0.5434 - val_loss: 0.9171 - val_acc: 0.5937\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.59365, saving model to ./models/stars/stars_100neurons_300dim_10000voc_400seq_model-01_0.59\n",
      "Epoch 2/30\n",
      "585716/585716 [==============================] - 3205s 5ms/step - loss: 0.8932 - acc: 0.6039 - val_loss: 0.8767 - val_acc: 0.6115\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.59365 to 0.61154, saving model to ./models/stars/stars_100neurons_300dim_10000voc_400seq_model-02_0.61\n",
      "Epoch 3/30\n",
      "585716/585716 [==============================] - 3258s 6ms/step - loss: 0.8767 - acc: 0.6120 - val_loss: 0.8635 - val_acc: 0.6186\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.61154 to 0.61861, saving model to ./models/stars/stars_100neurons_300dim_10000voc_400seq_model-03_0.62\n",
      "Epoch 4/30\n",
      "585716/585716 [==============================] - 3271s 6ms/step - loss: 0.8457 - acc: 0.6258 - val_loss: 0.8603 - val_acc: 0.6205\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.61861 to 0.62049, saving model to ./models/stars/stars_100neurons_300dim_10000voc_400seq_model-04_0.62\n",
      "Epoch 5/30\n",
      "585716/585716 [==============================] - 3176s 5ms/step - loss: 0.8292 - acc: 0.6334 - val_loss: 0.8533 - val_acc: 0.6223\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.62049 to 0.62228, saving model to ./models/stars/stars_100neurons_300dim_10000voc_400seq_model-05_0.62\n",
      "Epoch 6/30\n",
      "585716/585716 [==============================] - 3192s 5ms/step - loss: 0.8146 - acc: 0.6401 - val_loss: 0.8483 - val_acc: 0.6251\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.62228 to 0.62509, saving model to ./models/stars/stars_100neurons_300dim_10000voc_400seq_model-06_0.63\n",
      "Epoch 7/30\n",
      "585716/585716 [==============================] - 3249s 6ms/step - loss: 0.8040 - acc: 0.6447 - val_loss: 0.8533 - val_acc: 0.6265\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.62509 to 0.62652, saving model to ./models/stars/stars_100neurons_300dim_10000voc_400seq_model-07_0.63\n",
      "Epoch 8/30\n",
      "585716/585716 [==============================] - 3244s 6ms/step - loss: 0.7950 - acc: 0.6491 - val_loss: 0.8502 - val_acc: 0.6266\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.62652 to 0.62661, saving model to ./models/stars/stars_100neurons_300dim_10000voc_400seq_model-08_0.63\n",
      "Epoch 9/30\n",
      "585716/585716 [==============================] - 3308s 6ms/step - loss: 0.7870 - acc: 0.6531 - val_loss: 0.8521 - val_acc: 0.6257\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.62661\n",
      "Epoch 10/30\n",
      "585716/585716 [==============================] - 3320s 6ms/step - loss: 0.7803 - acc: 0.6557 - val_loss: 0.8575 - val_acc: 0.6243\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.62661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexanderherring/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:273: FutureWarning: 'argmax' is deprecated. Use 'idxmax' instead. The behavior of 'argmax' will be corrected to return the positional maximum in the future. Use 'series.values.argmax' to get the position of the maximum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating predictions for the best model...\n",
      "Calculating metrics for the best model...\n",
      "Finished!\n",
      "Saved model to disk\n",
      "End time:  2018-08-09 10:22:00.579414\n",
      "Time taken:  9:10:16.164202\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "print(\"Start time: \", start_time)\n",
    "\n",
    "model = lstm.fit(model_name='stars_100neurons', folder='./models/stars')\n",
    "# model = lstm.fit(model_name='stars_100neurons', folder='./')\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(\"End time: \", end_time)\n",
    "\n",
    "time_taken = end_time - start_time\n",
    "print(\"Time taken: \", time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm._eval_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm.eval_predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7efbdb0be828>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efee87ec6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lstm.confusion_matrix.plot(normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fscore</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.742946</td>\n",
       "      <td>0.723048</td>\n",
       "      <td>0.763970</td>\n",
       "      <td>29242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.574187</td>\n",
       "      <td>0.570534</td>\n",
       "      <td>0.577887</td>\n",
       "      <td>29331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.566782</td>\n",
       "      <td>0.570872</td>\n",
       "      <td>0.562751</td>\n",
       "      <td>29171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.541359</td>\n",
       "      <td>0.549937</td>\n",
       "      <td>0.533045</td>\n",
       "      <td>29399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.704392</td>\n",
       "      <td>0.713206</td>\n",
       "      <td>0.695793</td>\n",
       "      <td>29286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fscore  precision    recall  support\n",
       "0  0.742946   0.723048  0.763970    29242\n",
       "1  0.574187   0.570534  0.577887    29331\n",
       "2  0.566782   0.570872  0.562751    29171\n",
       "3  0.541359   0.549937  0.533045    29399\n",
       "4  0.704392   0.713206  0.695793    29286"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.prfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.62545767146970765, 0.62661084894385677, 0.62586333597539789, None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.prfs_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53333385058156124"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.corr_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_example = 916765\n",
    "rand_tag_num = current_example\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_example = 865234\n",
    "rand_tag_num = current_example\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_example = 757343\n",
    "rand_tag_num = current_example\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_example = 392282\n",
    "rand_tag_num = current_example\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reviews_df[\"text\"][511248])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][511248])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][511248]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reviews_df[\"text\"][811248])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][811248])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][811248]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(reviews_df[\"text\"][911249])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][911249])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][911249]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tag_num = random.randint(1,1000000)\n",
    "print(rand_tag_num)\n",
    "\n",
    "print(reviews_df[\"text\"][rand_tag_num])\n",
    "print(\"Actual stars: \", reviews_df[\"stars\"][rand_tag_num])\n",
    "print(\"Predicted stars: \", lstm.make_prediction(reviews_df[\"text\"][rand_tag_num]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
